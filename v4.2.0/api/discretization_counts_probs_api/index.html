<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Discretization API · Associations.jl</title><meta name="title" content="Discretization API · Associations.jl"/><meta property="og:title" content="Discretization API · Associations.jl"/><meta property="twitter:title" content="Discretization API · Associations.jl"/><meta name="description" content="Documentation for Associations.jl."/><meta property="og:description" content="Documentation for Associations.jl."/><meta property="twitter:description" content="Documentation for Associations.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="https://fonts.googleapis.com/css?family=Montserrat|Source+Code+Pro&amp;display=swap" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Associations.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Associations.jl</a></li><li><span class="tocitem">Core API reference</span><ul><li><a class="tocitem" href="../../associations/">Association measures</a></li><li><a class="tocitem" href="../../independence/">Independence</a></li><li><a class="tocitem" href="../../causal_graphs/">Network/graph inference</a></li></ul></li><li><span class="tocitem">Extended API reference</span><ul><li class="is-active"><a class="tocitem" href>Discretization API</a><ul class="internal"><li><a class="tocitem" href="#Encoding-multiple-input-datasets"><span>Encoding multiple input datasets</span></a></li></ul></li><li><a class="tocitem" href="../counts_and_probabilities_api/">Multivariate counts and probabilities API</a></li><li><a class="tocitem" href="../information_single_variable_api/">Single-variable information API</a></li><li><a class="tocitem" href="../information_multivariate_api/">Multivariate information API</a></li><li><a class="tocitem" href="../cross_map_api/">Cross-map API</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../../examples/examples_associations/">Associations</a></li><li><a class="tocitem" href="../../examples/examples_independence/">Independence testing</a></li><li><a class="tocitem" href="../../examples/examples_infer_graphs/">Causal graph inference</a></li></ul></li><li><a class="tocitem" href="../../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Extended API reference</a></li><li class="is-active"><a href>Discretization API</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Discretization API</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaDynamics/Associations.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaDynamics/Associations.jl/blob/main/docs/src/api/discretization_counts_probs_api.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Discretization-API"><a class="docs-heading-anchor" href="#Discretization-API">Discretization API</a><a id="Discretization-API-1"></a><a class="docs-heading-anchor-permalink" href="#Discretization-API" title="Permalink"></a></h1><h2 id="Encoding-multiple-input-datasets"><a class="docs-heading-anchor" href="#Encoding-multiple-input-datasets">Encoding multiple input datasets</a><a id="Encoding-multiple-input-datasets-1"></a><a class="docs-heading-anchor-permalink" href="#Encoding-multiple-input-datasets" title="Permalink"></a></h2><p>A fundamental operation when computing multivariate information measures from data is <em>discretization</em>.  When discretizing, what happens is that we &quot;encode&quot; input data into an intermediate representation indexed by the positive integers. This intermediate representation is called an &quot;encoding&quot;. This is useful in several ways:</p><ul><li>Once a dataset has been encoded into integers, we can estimate <a href="../counts_and_probabilities_api/#ComplexityMeasures.Counts"><code>Counts</code></a> or <a href="../counts_and_probabilities_api/#ComplexityMeasures.Probabilities"><code>Probabilities</code></a> (<a href="../counts_and_probabilities_api/#tutorial_probabilities">tutorial</a>).</li><li>Once probabilities have been estimated, one can use these to estimate <a href="../../associations/#Associations.MultivariateInformationMeasure"><code>MultivariateInformationMeasure</code></a> (<a href="../information_multivariate_api/#tutorial_infomeasures">tutorial</a>).</li></ul><p>The following functions and types are used by Associations.jl to perform discretization of input data.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Associations.Discretization" href="#Associations.Discretization"><code>Associations.Discretization</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Discretization</code></pre><p>The supertype of all discretization schemes.</p><p><strong>Concrete implementations</strong></p><ul><li><a href="#Associations.CodifyVariables"><code>CodifyVariables</code></a></li><li><a href="#Associations.CodifyPoints"><code>CodifyPoints</code></a></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/Associations.jl/blob/27a2bb86b2f23abb0392aabf74f23743551b6cbe/src/methods/information/counts_and_probs/counts_and_probs.jl#L4-L13">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Associations.CodifyVariables" href="#Associations.CodifyVariables"><code>Associations.CodifyVariables</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CodifyVariables &lt;: Discretization
CodifyVariables(outcome_space::OutcomeSpace)</code></pre><p>The <code>CodifyVariables</code> discretization scheme quantises input data in a column-wise manner using the given <code>outcome_space</code>.</p><p><strong>Compatible outcome spaces</strong></p><ul><li><a href="#ComplexityMeasures.UniqueElements"><code>UniqueElements</code></a> (for when data are pre-discretized)</li><li><a href="#ComplexityMeasures.BubbleSortSwaps"><code>BubbleSortSwaps</code></a></li><li><a href="#ComplexityMeasures.CosineSimilarityBinning"><code>CosineSimilarityBinning</code></a></li><li><a href="#ComplexityMeasures.OrdinalPatterns"><code>OrdinalPatterns</code></a></li><li><a href="#ComplexityMeasures.Dispersion"><code>Dispersion</code></a></li></ul><p><strong>Description</strong></p><p>The main difference between <code>CodifyVariables</code> and [<code>CodifyPoints</code>] is that the former uses <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a>s for discretization. This usually means that some transformation is applied to the data before discretizing. For example, some outcome constructs a delay embedding from the input (and thus encodes sequential information) before encoding the data.</p><p>Specifically, given <code>x::AbstractStateSpaceSet...</code>, where the <code>i</code>-th dataset <code>x[i]</code>  is assumed to represent a single series of measurements, <code>CodifyVariables</code> encodes  <code>x[i]</code> by <a href="#ComplexityMeasures.codify"><code>codify</code></a>-ing into a series of integers  using an appropriate  <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a>. This is typically done by first  sequentially transforming the data and then running sliding window (the width of  the window is controlled by <code>outcome_space</code>) across the data, and then encoding the  values within each window to an integer.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using Associations
x, y = rand(100), rand(100)
d = CodifyVariables(OrdinalPatterns(m=2))
cx, cy = codify(d, x, y)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/Associations.jl/blob/27a2bb86b2f23abb0392aabf74f23743551b6cbe/src/methods/information/counts_and_probs/encoding/codify_variables.jl#L12-L51">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Associations.CodifyPoints" href="#Associations.CodifyPoints"><code>Associations.CodifyPoints</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CodifyPoints{N}
CodifyPoints(encodings::NTuple{N, Encoding})</code></pre><p><code>CodifyPoints</code> points is a <a href="#Associations.Discretization"><code>Discretization</code></a> scheme that encodes input data points <em>without</em> applying any sequential transformation to the input (as opposed to  <a href="#Associations.CodifyVariables"><code>CodifyVariables</code></a>, which may apply some transformation before encoding).</p><p><strong>Usage</strong></p><ul><li>Use with <a href="#ComplexityMeasures.codify"><code>codify</code></a> to encode/discretize input variable on a point-by-point basis.</li></ul><p><strong>Compatible encodings</strong></p><ul><li><a href="#ComplexityMeasures.GaussianCDFEncoding"><code>GaussianCDFEncoding</code></a></li><li><a href="#ComplexityMeasures.OrdinalPatternEncoding"><code>OrdinalPatternEncoding</code></a></li><li><a href="#ComplexityMeasures.RelativeMeanEncoding"><code>RelativeMeanEncoding</code></a></li><li><a href="#ComplexityMeasures.RelativeFirstDifferenceEncoding"><code>RelativeFirstDifferenceEncoding</code></a></li><li><a href="#ComplexityMeasures.UniqueElementsEncoding"><code>UniqueElementsEncoding</code></a></li><li><a href="#ComplexityMeasures.RectangularBinEncoding"><code>RectangularBinEncoding</code></a></li><li><a href="#ComplexityMeasures.CombinationEncoding"><code>CombinationEncoding</code></a></li></ul><p><strong>Description</strong></p><p>Given <code>x::AbstractStateSpaceSet...</code>, where the <code>i</code>-th dataset is assumed to represent a single series of measurements, <code>CodifyPoints</code> encodes each point <code>pₖ ∈ x[i]</code>  using some <a href="#ComplexityMeasures.Encoding"><code>Encoding</code></a>(s), <em>without</em> applying any (sequential) transformation to the <code>x[i]</code> first. This behaviour is different to <a href="#Associations.CodifyVariables"><code>CodifyVariables</code></a>, which <em>does</em> apply a transformation to <code>x[i]</code> before encoding.</p><p>If <code>length(x) == N</code> (i.e. there are <code>N</code> input dataset), then <code>encodings</code> must be a tuple of <code>N</code> <a href="#ComplexityMeasures.Encoding"><code>Encoding</code></a>. Alternatively, if <code>encodings</code> is a single <a href="#ComplexityMeasures.Encoding"><code>Encoding</code></a>, then that same encoding is applied to every <code>x[i]</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using Associations

# The same encoding on two input datasets
x = StateSpaceSet(rand(100, 3))
y = StateSpaceSet(rand(100, 3))
encoding_ord = OrdinalPatternEncoding(3)
cx, cy = codify(CodifyPoints(encoding_ord), x, y)

# Different encodings on multiple datasets
z = StateSpaceSet(rand(100, 2))
encoding_bin = RectangularBinEncoding(RectangularBinning(3), z)
d = CodifyPoints(encoding_ord, encoding_ord, encoding_bin)
cx, cy, cz = codify(d, x, y, z)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/Associations.jl/blob/27a2bb86b2f23abb0392aabf74f23743551b6cbe/src/methods/information/counts_and_probs/encoding/codify_points.jl#L8-L59">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ComplexityMeasures.codify" href="#ComplexityMeasures.codify"><code>ComplexityMeasures.codify</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">codify(o::OutcomeSpace, x::Vector) → s::Vector{Int}
codify(o::OutcomeSpace, x::AbstractStateSpaceSet{D}) → s::NTuple{D, Vector{Int}</code></pre><p>Codify <code>x</code> according to the outcome space <code>o</code>. If <code>x</code> is a <code>Vector</code>, then a <code>Vector{&lt;:Integer}</code> is returned. If <code>x</code> is a <code>StateSpaceSet{D}</code>, then symbolization is done column-wise and an <code>NTuple{D, Vector{&lt;:Integer}}</code> is returned, where <code>D = dimension(x)</code>.</p><p><strong>Description</strong></p><p>The reason this function exists is that we don&#39;t always want to <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.encode"><code>encode</code></a> the entire input <code>x</code> at once. Sometimes, it is desirable to first apply some transformation to <code>x</code> first, then apply <a href="#ComplexityMeasures.Encoding"><code>Encoding</code></a>s in a point-wise manner in the transformed space. (the <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a> dictates this transformation). This is useful for encoding timeseries data.</p><p>The length of the returned <code>s</code> depends on the <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a>. Some outcome spaces preserve the input data length (e.g. <a href="#ComplexityMeasures.UniqueElements"><code>UniqueElements</code></a>), while some outcome spaces (e.g. <a href="#ComplexityMeasures.OrdinalPatterns"><code>OrdinalPatterns</code></a>) do e.g. delay embeddings before encoding, so that <code>length(s) &lt; length(x)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/v3.6.5/src/core/encodings.jl#L49-L71">source</a></section></article><p>In summary, the two main ways of discretizing data in Associations are as follows.</p><ul><li>The <a href="#Associations.CodifyPoints"><code>CodifyPoints</code></a> discretization scheme encodes input data on a point-by-point    basis by applying some <a href="#ComplexityMeasures.Encoding"><code>Encoding</code></a> to each point.</li><li>The <a href="#Associations.CodifyVariables"><code>CodifyVariables</code></a> discretization scheme encodes input data on a column-by-column   basis by applying a sliding window to each column, and encoding the data within the sliding window according to some <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a> (<em>Internally, this uses <a href="#ComplexityMeasures.codify"><code>codify</code></a></em>).</li></ul><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p><a href="#ComplexityMeasures.Encoding"><code>Encoding</code></a>, <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a> and <a href="#ComplexityMeasures.codify"><code>codify</code></a> are all from <a href="https://github.com/JuliaDynamics/ComplexityMeasures.jl">ComplexityMeasures.jl</a>. In this package, they are used to discretize multiple input variables instead of just one input variable.</p></div></div><h3 id="Encoding-per-point/row"><a class="docs-heading-anchor" href="#Encoding-per-point/row">Encoding per point/row</a><a id="Encoding-per-point/row-1"></a><a class="docs-heading-anchor-permalink" href="#Encoding-per-point/row" title="Permalink"></a></h3><p>In some cases, it may be desireable to encode data on a row-wise basis. This  typically happens when working with pre-embedded time series or <a href="../../#StateSpaceSets.StateSpaceSet"><code>StateSpaceSet</code></a>s  (respecting the fact that time ordering is already taken care of by the  embedding procedure).  If we want to apply something like <a href="#ComplexityMeasures.OrdinalPatternEncoding"><code>OrdinalPatternEncoding</code></a> to such data, then  we must encode each <em>point</em> individually, such that vectors like <code>[1.2, 2.4, 4.5]</code> or  <code>[&quot;howdy&quot;, &quot;partner&quot;]</code> gets mapped to an integer. The <a href="#Associations.CodifyPoints"><code>CodifyPoints</code></a> discretization  intstruction ensures input data are encoded on a point-by-point basis.</p><p>A point-by-point discretization using <a href="#Associations.CodifyPoints"><code>CodifyPoints</code></a> is formally done by applying some <a href="#ComplexityMeasures.Encoding"><code>Encoding</code></a> to each input data point. You can pick between the following encodings, or combine  them in arbitrary ways using <a href="#ComplexityMeasures.CombinationEncoding"><code>CombinationEncoding</code></a>.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ComplexityMeasures.Encoding" href="#ComplexityMeasures.Encoding"><code>ComplexityMeasures.Encoding</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Encoding</code></pre><p>The supertype for all encoding schemes. Encodings always encode elements of input data into the positive integers. The encoding API is defined by the functions <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.encode"><code>encode</code></a> and <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.decode"><code>decode</code></a>. Some probability estimators utilize encodings internally.</p><p>Current available encodings are:</p><ul><li><a href="#ComplexityMeasures.OrdinalPatternEncoding"><code>OrdinalPatternEncoding</code></a>.</li><li><a href="#ComplexityMeasures.GaussianCDFEncoding"><code>GaussianCDFEncoding</code></a>.</li><li><a href="#ComplexityMeasures.RectangularBinEncoding"><code>RectangularBinEncoding</code></a>.</li><li><a href="#ComplexityMeasures.RelativeMeanEncoding"><code>RelativeMeanEncoding</code></a>.</li><li><a href="#ComplexityMeasures.RelativeFirstDifferenceEncoding"><code>RelativeFirstDifferenceEncoding</code></a>.</li><li><a href="#ComplexityMeasures.UniqueElementsEncoding"><code>UniqueElementsEncoding</code></a>.</li><li><a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.BubbleSortSwapsEncoding"><code>BubbleSortSwapsEncoding</code></a>.</li><li><a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.PairDistanceEncoding"><code>PairDistanceEncoding</code></a>.</li><li><a href="#ComplexityMeasures.CombinationEncoding"><code>CombinationEncoding</code></a>, which can combine any of the above encodings.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/v3.6.5/src/core/encodings.jl#L3-L22">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ComplexityMeasures.GaussianCDFEncoding" href="#ComplexityMeasures.GaussianCDFEncoding"><code>ComplexityMeasures.GaussianCDFEncoding</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GaussianCDFEncoding &lt;: Encoding
GaussianCDFEncoding{m}(; μ, σ, c::Int = 3)</code></pre><p>An encoding scheme that <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.encode"><code>encode</code></a>s a scalar or vector <code>χ</code> into one of the integers <code>sᵢ ∈ [1, 2, …, c]</code> based on the normal cumulative distribution function (NCDF), and <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.decode"><code>decode</code></a>s the <code>sᵢ</code> into subintervals of <code>[0, 1]</code> (with some loss of information).</p><p><strong>Initializing a <code>GaussianCDFEncoding</code></strong></p><p>The size of the input to be encoded must be known beforehand. One must therefore set <code>m = length(χ)</code>, where <code>χ</code> is the input (<code>m = 1</code> for scalars, <code>m ≥ 2</code> for vectors). To do so, one must explicitly give <code>m</code> as a type parameter: e.g. <code>encoding = GaussianCDFEncoding{3}(; μ = 0.0, σ = 0.1)</code> to encode 3-element vectors, or <code>encoding = GaussianCDFEncoding{1}(; μ = 0.0, σ = 0.1)</code> to encode scalars.</p><p><strong>Description</strong></p><p><strong>Encoding/decoding scalars</strong></p><p><code>GaussianCDFEncoding</code> first maps an input scalar <span>$χ$</span> to a new real number <span>$y_ \in [0, 1]$</span> by using the normal cumulative distribution function (CDF) with the given mean <code>μ</code> and standard deviation <code>σ</code>, according to the map</p><p class="math-container">\[x \to y : y = \dfrac{1}{ \sigma
    \sqrt{2 \pi}} \int_{-\infty}^{x} e^{(-(x - \mu)^2)/(2 \sigma^2)} dx.\]</p><p>Next, the interval <code>[0, 1]</code> is equidistantly binned and enumerated <span>$1, 2, \ldots, c$</span>,  and <span>$y$</span> is linearly mapped to one of these integers using the linear map  <span>$y \to z : z = \text{floor}(y(c-1)) + 1$</span>.</p><p>Because of the floor operation, some information is lost, so when used with <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.decode"><code>decode</code></a>, each decoded <code>sᵢ</code> is mapped to a <em>subinterval</em> of <code>[0, 1]</code>. This subinterval is returned as a length-<code>1</code> <code>Vector{SVector}</code>.</p><p>Notice that the decoding step does not yield an element of any outcome space of the estimators that use <code>GaussianCDFEncoding</code> internally, such as <a href="#ComplexityMeasures.Dispersion"><code>Dispersion</code></a>. That is because these estimators additionally delay embed the encoded data.</p><p><strong>Encoding/decoding vectors</strong></p><p>If <code>GaussianCDFEncoding</code> is used with a vector <code>χ</code>, then each element of <code>χ</code> is encoded separately, resulting in a <code>length(χ)</code> sequence of integers which may be treated as a <code>CartesianIndex</code>. The encoded symbol <code>s ∈ [1, 2, …, c]</code> is then just the linear index corresponding to this cartesian index (similar to how <a href="#ComplexityMeasures.CombinationEncoding"><code>CombinationEncoding</code></a> works).</p><p>When <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.decode"><code>decode</code></a>d, the integer symbol <code>s</code> is converted back into its <code>CartesianIndex</code> representation,  which is just a sequence of integers that refer to subdivisions of the <code>[0, 1]</code> interval. The relevant subintervals are then returned as a length-<code>χ</code> <code>Vector{SVector}</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using ComplexityMeasures, Statistics

julia&gt; x = [0.1, 0.4, 0.7, -2.1, 8.0];

julia&gt; μ, σ = mean(x), std(x); encoding = GaussianCDFEncoding(; μ, σ, c = 5)

julia&gt; es = encode.(Ref(encoding), x)
5-element Vector{Int64}:
 2
 2
 3
 1
 5

julia&gt; decode(encoding, 3)
2-element SVector{2, Float64} with indices SOneTo(2):
 0.4
 0.6</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/v3.6.5/src/encoding_implementations/gaussian_cdf.jl#L6-L82">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ComplexityMeasures.OrdinalPatternEncoding" href="#ComplexityMeasures.OrdinalPatternEncoding"><code>ComplexityMeasures.OrdinalPatternEncoding</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">OrdinalPatternEncoding &lt;: Encoding
OrdinalPatternEncoding{m}(lt = ComplexityMeasures.isless_rand)</code></pre><p>An encoding scheme that <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.encode"><code>encode</code></a>s length-<code>m</code> vectors into their permutation/ordinal patterns and then into the integers based on the Lehmer code. It is used by <a href="#ComplexityMeasures.OrdinalPatterns"><code>OrdinalPatterns</code></a> and similar estimators, see that for a description of the outcome space.</p><p>The ordinal/permutation pattern of a vector <code>χ</code> is simply <code>sortperm(χ)</code>, which gives the indices that would sort <code>χ</code> in ascending order.</p><p><strong>Description</strong></p><p>The Lehmer code, as implemented here, is a bijection between the set of <code>factorial(m)</code> possible permutations for a length-<code>m</code> sequence, and the integers <code>1, 2, …, factorial(m)</code>. The encoding step uses algorithm 1 in <a href="../../references/#Berger2019">Berger <em>et al.</em> (2019)</a>, which is highly optimized. The decoding step is much slower due to missing optimizations (pull requests welcomed!).</p><p><strong>Example</strong></p><pre><code class="language-julia-repl hljs">julia&gt; using ComplexityMeasures

julia&gt; χ = [4.0, 1.0, 9.0];

julia&gt; c = OrdinalPatternEncoding(3);

julia&gt; i = encode(c, χ)
3

julia&gt; decode(c, i)
3-element SVector{3, Int64} with indices SOneTo(3):
 2
 1
 3</code></pre><p>If you want to encode something that is already a permutation pattern, then you can use the non-exported <code>permutation_to_integer</code> function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/v3.6.5/src/encoding_implementations/ordinal_pattern.jl#L6-L47">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ComplexityMeasures.RelativeMeanEncoding" href="#ComplexityMeasures.RelativeMeanEncoding"><code>ComplexityMeasures.RelativeMeanEncoding</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">RelativeMeanEncoding &lt;: Encoding
RelativeMeanEncoding(minval::Real, maxval::Real; n = 2)</code></pre><p><code>RelativeMeanEncoding</code> encodes a vector based on the relative position the mean of the vector has with respect to a predefined minimum and maximum value (<code>minval</code> and <code>maxval</code>, respectively).</p><p><strong>Description</strong></p><p>This encoding is inspired by <a href="../../references/#Azami2016">Azami and Escudero (2016)</a>&#39;s algorithm for amplitude-aware permutation entropy. They use a linear combination of amplitude information and first differences information of state vectors to correct probabilities. Here, however, we explicitly encode the amplitude-part of the correction as an a integer symbol <code>Λ ∈ [1, 2, …, n]</code>. The first-difference part of the encoding is available as the <a href="#ComplexityMeasures.RelativeFirstDifferenceEncoding"><code>RelativeFirstDifferenceEncoding</code></a> encoding.</p><p><strong>Encoding/decoding</strong></p><p>When used with <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.encode"><code>encode</code></a>, an <span>$m$</span>-element state vector <span>$\bf{x} = (x_1, x_2, \ldots, x_m)$</span> is encoded as <span>$Λ = \dfrac{1}{N}\sum_{i=1}^m abs(x_i)$</span>. The value of <span>$Λ$</span> is then normalized to lie on the interval <code>[0, 1]</code>, assuming that the minimum/maximum value any single element <span>$x_i$</span> can take is <code>minval</code>/<code>maxval</code>, respectively. Finally, the interval <code>[0, 1]</code> is discretized into <code>n</code> discrete bins, enumerated by positive integers <code>1, 2, …, n</code>, and the number of the bin that the normalized <span>$Λ$</span> falls into is returned.</p><p>When used with <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.decode"><code>decode</code></a>, the left-edge of the bin that the normalized <span>$Λ$</span> fell into is returned.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/v3.6.5/src/encoding_implementations/relative_mean_encoding.jl#L3-L32">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ComplexityMeasures.RelativeFirstDifferenceEncoding" href="#ComplexityMeasures.RelativeFirstDifferenceEncoding"><code>ComplexityMeasures.RelativeFirstDifferenceEncoding</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">RelativeFirstDifferenceEncoding &lt;: Encoding
RelativeFirstDifferenceEncoding(minval::Real, maxval::Real; n = 2)</code></pre><p><code>RelativeFirstDifferenceEncoding</code> encodes a vector based on the relative position the average of the <em>first differences</em> of the vectors has with respect to a predefined minimum and maximum value (<code>minval</code> and <code>maxval</code>, respectively).</p><p><strong>Description</strong></p><p>This encoding is inspired by <a href="../../references/#Azami2016">Azami and Escudero (2016)</a>&#39;s algorithm for amplitude-aware permutation entropy. They use a linear combination of amplitude information and first differences information of state vectors to correct probabilities. Here, however, we explicitly encode the first differences part of the correction as an a integer symbol <code>Λ ∈ [1, 2, …, n]</code>. The amplitude part of the encoding is available as the <a href="#ComplexityMeasures.RelativeMeanEncoding"><code>RelativeMeanEncoding</code></a> encoding.</p><p><strong>Encoding/decoding</strong></p><p>When used with <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.encode"><code>encode</code></a>, an <span>$m$</span>-element state vector <span>$\bf{x} = (x_1, x_2, \ldots, x_m)$</span> is encoded as <span>$Λ = \dfrac{1}{m - 1}\sum_{k=2}^m |x_{k} - x_{k-1}|$</span>. The value of <span>$Λ$</span> is then normalized to lie on the interval <code>[0, 1]</code>, assuming that the minimum/maximum value any single <span>$abs(x_k - x_{k-1})$</span> can take is <code>minval</code>/<code>maxval</code>, respectively. Finally, the interval <code>[0, 1]</code> is discretized into <code>n</code> discrete bins, enumerated by positive integers <code>1, 2, …, n</code>, and the number of the bin that the normalized <span>$Λ$</span> falls into is returned. The smaller the mean first difference of the state vector is, the smaller the bin number is. The higher the mean first difference of the state vectors is, the higher the bin number is.</p><p>When used with <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.decode"><code>decode</code></a>, the left-edge of the bin that the normalized <span>$Λ$</span> fell into is returned.</p><p><strong>Performance tips</strong></p><p>If you are encoding multiple input vectors, it is more efficient to construct a <a href="#ComplexityMeasures.RelativeFirstDifferenceEncoding"><code>RelativeFirstDifferenceEncoding</code></a> instance and re-use it:</p><pre><code class="language-julia hljs">minval, maxval = 0, 1
encoding = RelativeFirstDifferenceEncoding(minval, maxval; n = 4)
pts = [rand(3) for i = 1:1000]
[encode(encoding, x) for x in pts]</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/v3.6.5/src/encoding_implementations/relative_first_difference_encoding.jl#L3-L46">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ComplexityMeasures.UniqueElementsEncoding" href="#ComplexityMeasures.UniqueElementsEncoding"><code>ComplexityMeasures.UniqueElementsEncoding</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">UniqueElementsEncoding &lt;: Encoding
UniqueElementsEncoding(x)</code></pre><p><code>UniqueElementsEncoding</code> is a generic encoding that encodes each <code>xᵢ ∈ unique(x)</code> to one of the positive integers. The <code>xᵢ</code> are encoded according to the order of their first appearance in the input data.</p><p>The constructor requires the input data <code>x</code>, since the number of possible symbols is <code>length(unique(x))</code>.</p><p><strong>Example</strong></p><pre><code class="language-julia hljs">using ComplexityMeasures
x = [&#39;a&#39;, 2, 5, 2, 5, &#39;a&#39;]
e = UniqueElementsEncoding(x)
encode.(Ref(e), x) == [1, 2, 3, 2, 3, 1] # true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/v3.6.5/src/encoding_implementations/unique_elements_encoding.jl#L5-L24">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ComplexityMeasures.RectangularBinEncoding" href="#ComplexityMeasures.RectangularBinEncoding"><code>ComplexityMeasures.RectangularBinEncoding</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">RectangularBinEncoding &lt;: Encoding
RectangularBinEncoding(binning::RectangularBinning, x)
RectangularBinEncoding(binning::FixedRectangularBinning)</code></pre><p>An encoding scheme that <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.encode"><code>encode</code></a>s points <code>χ ∈ x</code> into their histogram bins.</p><p>The first call signature simply initializes a <a href="#ComplexityMeasures.FixedRectangularBinning"><code>FixedRectangularBinning</code></a> and then calls the second call signature.</p><p>See <a href="#ComplexityMeasures.FixedRectangularBinning"><code>FixedRectangularBinning</code></a> for info on mapping points to bins.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/v3.6.5/src/encoding_implementations/rectangular_binning.jl#L101-L112">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ComplexityMeasures.CombinationEncoding" href="#ComplexityMeasures.CombinationEncoding"><code>ComplexityMeasures.CombinationEncoding</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CombinationEncoding &lt;: Encoding
CombinationEncoding(encodings)</code></pre><p>A <code>CombinationEncoding</code> takes multiple <a href="#ComplexityMeasures.Encoding"><code>Encoding</code></a>s and creates a combined encoding that can be used to encode inputs that are compatible with the given <code>encodings</code>.</p><p><strong>Encoding/decoding</strong></p><p>When used with <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.encode"><code>encode</code></a>, each <a href="#ComplexityMeasures.Encoding"><code>Encoding</code></a> in <code>encodings</code> returns integers in the set <code>1, 2, …, n_e</code>, where <code>n_e</code> is the total number of outcomes for a particular encoding. For <code>k</code> different encodings, we can thus construct the cartesian coordinate <code>(c₁, c₂, …, cₖ)</code> (<code>cᵢ ∈ 1, 2, …, n_i</code>), which can uniquely be identified by an integer. We can thus identify each unique <em>combined</em> encoding with a single integer.</p><p>When used with <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.decode"><code>decode</code></a>, the integer symbol is converted to its corresponding cartesian coordinate, which is used to retrieve the decoded symbols for each of the encodings, and a tuple of the decoded symbols are returned.</p><p>The total number of outcomes is <code>prod(total_outcomes(e) for e in encodings)</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using ComplexityMeasures

# We want to encode the vector `x`.
x = [0.9, 0.2, 0.3]

# To do so, we will use a combination of first-difference encoding, amplitude encoding,
# and ordinal pattern encoding.

encodings = (
    RelativeFirstDifferenceEncoding(0, 1; n = 2),
    RelativeMeanEncoding(0, 1; n = 5),
    OrdinalPatternEncoding(3) # x is a three-element vector
    )
c = CombinationEncoding(encodings)

# Encode `x` as integer
ω = encode(c, x)

# Decode symbol (into a vector of decodings, one for each encodings `e ∈ encodings`).
# In this particular case, the first two element will be left-bin edges, and
# the last element will be the decoded ordinal pattern (indices that would sort `x`).
d = decode(c, ω)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/v3.6.5/src/encoding_implementations/combination_encoding.jl#L3-L52">source</a></section></article><h4 id="tutorial_codify_points"><a class="docs-heading-anchor" href="#tutorial_codify_points">Examples: encoding <em>rows</em> (one <em>point</em> at a time)</a><a id="tutorial_codify_points-1"></a><a class="docs-heading-anchor-permalink" href="#tutorial_codify_points" title="Permalink"></a></h4><p>We&#39;ll here use the <a href="#ComplexityMeasures.OrdinalPatternEncoding"><code>OrdinalPatternEncoding</code></a> with differing parameter <code>m</code> to encode  multiple <a href="../../#StateSpaceSets.StateSpaceSet"><code>StateSpaceSet</code></a> of differing dimensions.</p><pre><code class="language-julia hljs">using Associations
using StateSpaceSets
using Random; rng = Xoshiro(1234)

# The first variable is 2-dimensional and has 50 points
x = StateSpaceSet(rand(rng, 50, 2))
# The second variable is 3-dimensional and has 50 points
y = StateSpaceSet(rand(rng, 50, 3))
# The third variable is 4-dimensional and has 50 points
z = StateSpaceSet(rand(rng, 50, 4))

# One encoding scheme per input variable
# encode `x` using `ox` on a point-by-point basis (Vector{SVector{4}} → Vector{Int})
# encode `y` using `oy` on a point-by-point basis (Vector{SVector{3}} → Vector{Int})
# encode `z` using `oz` on a point-by-point basis (Vector{SVector{2}} → Vector{Int})
ox = OrdinalPatternEncoding(2)
oy = OrdinalPatternEncoding(3)
oz = OrdinalPatternEncoding(4)

# This given three column vectors of integers.
cx, cy, cz = codify(CodifyPoints(ox, oy, oz), x, y, z)

[cx cy cz]</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">50×3 Matrix{Int64}:
 2  1   9
 1  4   5
 2  6   2
 1  3  22
 1  1  23
 1  1  17
 2  2   2
 2  6   7
 2  4  20
 1  3  22
 ⋮     
 2  3  12
 1  6  19
 2  1  24
 1  4   5
 2  2   2
 2  6  11
 1  6  18
 1  3  21
 2  1   2</code></pre><p>Notice that the 2-dimensional <code>x</code> has been encoded into integer values <code>1</code> or <code>2</code>, because there are <code>2!</code> possible ordinal patterns for dimension <code>m = 2</code>. The 3-dimensional <code>y</code> has  been encoded into integers in the range <code>1</code> to <code>3! = 6</code>, while the 4-dimensional <code>z</code> is  encoded into an even larger range of integers, because the number of possible ordinal patterns is <code>4! = 24</code> for 4-dimensional embedding vectors.</p><h3 id="Encoding-per-variable/column"><a class="docs-heading-anchor" href="#Encoding-per-variable/column">Encoding per variable/column</a><a id="Encoding-per-variable/column-1"></a><a class="docs-heading-anchor-permalink" href="#Encoding-per-variable/column" title="Permalink"></a></h3><p>Sometimes, it may be desireable to encode input data one variable/column at a time. This typically happens when the input are either a single or multiple timeseries.</p><p>To encode columns, we move a sliding window across each input variable/column and  encode points within that window. Formally, such a sliding-window discretization  is done by using the <a href="#Associations.CodifyVariables"><code>CodifyVariables</code></a> discretization scheme, which takes as input some <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a> that dictates how each window is encoded, and  also dictates the width of the encoding windows. </p><p>For column/variable-wise encoding, you can pick between the following outcome spaces.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ComplexityMeasures.OutcomeSpace" href="#ComplexityMeasures.OutcomeSpace"><code>ComplexityMeasures.OutcomeSpace</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">OutcomeSpace</code></pre><p>The supertype for all outcome space implementation.</p><p><strong>Description</strong></p><p>In ComplexityMeasures.jl, an outcome space defines a set of possible outcomes <span>$\Omega = \{\omega_1, \omega_2, \ldots, \omega_L \}$</span> (some form of discretization). In the literature, the outcome space is often also called an &quot;alphabet&quot;, while each outcome is called a &quot;symbol&quot; or an &quot;event&quot;.</p><p>An outcome space also defines a set of rules for mapping input data to to each outcome <span>$\omega_i$</span>, a processes called <em>encoding</em> or <em>symbolizing</em> or <em>discretizing</em> in the literature (see <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#encodings">encodings</a>). Some <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a>s first apply a transformation, e.g. a delay embedding, to the data before discretizing/encoding, while other <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a>s discretize/encode the data directly.</p><p><strong>Implementations</strong></p><table><tr><th style="text-align: left">Outcome space</th><th style="text-align: left">Principle</th><th style="text-align: left">Input data</th><th style="text-align: left">Counting-compatible</th></tr><tr><td style="text-align: left"><a href="#ComplexityMeasures.UniqueElements"><code>UniqueElements</code></a></td><td style="text-align: left">Count of unique elements</td><td style="text-align: left"><code>Any</code></td><td style="text-align: left">✔</td></tr><tr><td style="text-align: left"><a href="#ComplexityMeasures.ValueBinning"><code>ValueBinning</code></a></td><td style="text-align: left">Binning (histogram)</td><td style="text-align: left"><code>Vector</code>, <code>StateSpaceSet</code></td><td style="text-align: left">✔</td></tr><tr><td style="text-align: left"><a href="#ComplexityMeasures.OrdinalPatterns"><code>OrdinalPatterns</code></a></td><td style="text-align: left">Ordinal patterns</td><td style="text-align: left"><code>Vector</code>, <code>StateSpaceSet</code></td><td style="text-align: left">✔</td></tr><tr><td style="text-align: left"><a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.SpatialOrdinalPatterns"><code>SpatialOrdinalPatterns</code></a></td><td style="text-align: left">Ordinal patterns in space</td><td style="text-align: left"><code>Array</code></td><td style="text-align: left">✔</td></tr><tr><td style="text-align: left"><a href="#ComplexityMeasures.Dispersion"><code>Dispersion</code></a></td><td style="text-align: left">Dispersion patterns</td><td style="text-align: left"><code>Vector</code></td><td style="text-align: left">✔</td></tr><tr><td style="text-align: left"><a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.SpatialDispersion"><code>SpatialDispersion</code></a></td><td style="text-align: left">Dispersion patterns in space</td><td style="text-align: left"><code>Array</code></td><td style="text-align: left">✔</td></tr><tr><td style="text-align: left"><a href="#ComplexityMeasures.CosineSimilarityBinning"><code>CosineSimilarityBinning</code></a></td><td style="text-align: left">Cosine similarity</td><td style="text-align: left"><code>Vector</code></td><td style="text-align: left">✔</td></tr><tr><td style="text-align: left"><a href="#ComplexityMeasures.BubbleSortSwaps"><code>BubbleSortSwaps</code></a></td><td style="text-align: left">Swap counts when sorting</td><td style="text-align: left"><code>Vector</code></td><td style="text-align: left">✔</td></tr><tr><td style="text-align: left"><a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.SequentialPairDistances"><code>SequentialPairDistances</code></a></td><td style="text-align: left">Sequential state vector distances</td><td style="text-align: left"><code>Vector</code>, <code>StateSpaceSet</code></td><td style="text-align: left">✔</td></tr><tr><td style="text-align: left"><a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.TransferOperator"><code>TransferOperator</code></a></td><td style="text-align: left">Binning (transfer operator)</td><td style="text-align: left"><code>Vector</code>, <code>StateSpaceSet</code></td><td style="text-align: left">✖</td></tr><tr><td style="text-align: left"><a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.NaiveKernel"><code>NaiveKernel</code></a></td><td style="text-align: left">Kernel density estimation</td><td style="text-align: left"><code>StateSpaceSet</code></td><td style="text-align: left">✖</td></tr><tr><td style="text-align: left"><a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.WeightedOrdinalPatterns"><code>WeightedOrdinalPatterns</code></a></td><td style="text-align: left">Ordinal patterns</td><td style="text-align: left"><code>Vector</code>, <code>StateSpaceSet</code></td><td style="text-align: left">✖</td></tr><tr><td style="text-align: left"><a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.AmplitudeAwareOrdinalPatterns"><code>AmplitudeAwareOrdinalPatterns</code></a></td><td style="text-align: left">Ordinal patterns</td><td style="text-align: left"><code>Vector</code>, <code>StateSpaceSet</code></td><td style="text-align: left">✖</td></tr><tr><td style="text-align: left"><a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.WaveletOverlap"><code>WaveletOverlap</code></a></td><td style="text-align: left">Wavelet transform</td><td style="text-align: left"><code>Vector</code></td><td style="text-align: left">✖</td></tr><tr><td style="text-align: left"><a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.PowerSpectrum"><code>PowerSpectrum</code></a></td><td style="text-align: left">Fourier transform</td><td style="text-align: left"><code>Vector</code></td><td style="text-align: left">✖</td></tr></table><p>In the column &quot;input data&quot; it is assumed that the <code>eltype</code> of the input is <code>&lt;: Real</code>.</p><p><strong>Usage</strong></p><p>Outcome spaces are used as input to</p><ul><li><a href="../counts_and_probabilities_api/#ComplexityMeasures.probabilities-Tuple{OutcomeSpace}"><code>probabilities</code></a>/<a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.allprobabilities_and_outcomes"><code>allprobabilities_and_outcomes</code></a> for computing   probability mass functions.</li><li><a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.outcome_space"><code>outcome_space</code></a>, which returns the elements of the outcome space.</li><li><a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.total_outcomes"><code>total_outcomes</code></a>, which returns the cardinality of the outcome space.</li><li><a href="../counts_and_probabilities_api/#ComplexityMeasures.counts-Tuple{OutcomeSpace}"><code>counts</code></a>/<a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.counts_and_outcomes"><code>counts_and_outcomes</code></a>/<a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.allcounts_and_outcomes"><code>allcounts_and_outcomes</code></a>, for    obtaining raw counts instead of probabilities (only for counting-compatible outcome   spaces).</li></ul><p><strong>Counting-compatible vs. non-counting compatible outcome spaces</strong></p><p>There are two main types of outcome spaces.</p><ul><li>Counting-compatible outcome spaces have a well-defined   way of counting how often each point in the (encoded) input data is mapped to a   particular outcome <span>$\omega_i$</span>. These outcome spaces use   <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.encode"><code>encode</code></a> to discretize the input data. Examples are   <a href="#ComplexityMeasures.OrdinalPatterns"><code>OrdinalPatterns</code></a> (which encodes input data into ordinal patterns) or   <a href="#ComplexityMeasures.ValueBinning"><code>ValueBinning</code></a> (which discretizes points onto a regular grid).   The table below lists which outcome spaces are counting compatible.</li><li>Non-counting compatible outcome spaces have no well-defined way of counting explicitly   how often each point in the input data is mapped to a particular outcome <span>$\omega_i$</span>.   Instead, these outcome spaces returns a vector of pre-normalized &quot;relative counts&quot;, one   for each outcome <span>$\omega_i$</span>. Examples are <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.WaveletOverlap"><code>WaveletOverlap</code></a> or   <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.PowerSpectrum"><code>PowerSpectrum</code></a>.</li></ul><p>Counting-compatible outcome spaces can be used with <em>any</em> <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.ProbabilitiesEstimator"><code>ProbabilitiesEstimator</code></a> to convert counts into probability mass functions. Non-counting-compatible outcome spaces can only be used with the maximum likelihood (<a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.RelativeAmount"><code>RelativeAmount</code></a>) probabilities estimator, which estimates probabilities precisely by the relative frequency of each outcome (formally speaking, the <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.RelativeAmount"><code>RelativeAmount</code></a> estimator also requires counts, but for the sake of code consistency, we allow it to be used with relative frequencies as well).</p><p>The function <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.is_counting_based"><code>is_counting_based</code></a> can be used to check whether an outcome space is based on counting.</p><p><strong>Deducing the outcome space (from data)</strong></p><p>Some outcome space models can deduce <span>$\Omega$</span> without knowledge of the input, such as <a href="#ComplexityMeasures.OrdinalPatterns"><code>OrdinalPatterns</code></a>. Other outcome spaces require knowledge of the input data for concretely specifying <span>$\Omega$</span>, such as <a href="#ComplexityMeasures.ValueBinning"><code>ValueBinning</code></a> with <a href="#ComplexityMeasures.RectangularBinning"><code>RectangularBinning</code></a>. If <code>o</code> is some outcome space model and <code>x</code> some input data, then <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.outcome_space"><code>outcome_space</code></a><code>(o, x)</code> returns the possible outcomes <span>$\Omega$</span>. To get the cardinality of <span>$\Omega$</span>, use <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.total_outcomes"><code>total_outcomes</code></a>.</p><p><strong>Implementation details</strong></p><p>The element type of <span>$\Omega$</span> varies between outcome space models, but it is guaranteed to be <em>hashable</em> and <em>sortable</em>. This allows for conveniently tracking the counts of a specific event across experimental realizations, by using the outcome as a dictionary key and the counts as the value for that key (or, alternatively, the key remains the outcome and one has a vector of probabilities, one for each experimental realization).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/v3.6.5/src/core/outcome_spaces.jl#L6-L104">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ComplexityMeasures.UniqueElements" href="#ComplexityMeasures.UniqueElements"><code>ComplexityMeasures.UniqueElements</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">UniqueElements()</code></pre><p>An <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a> based on straight-forward counting of distinct elements in a univariate time series or multivariate dataset. This is the same as giving no estimator to <a href="../counts_and_probabilities_api/#ComplexityMeasures.probabilities-Tuple{OutcomeSpace}"><code>probabilities</code></a>.</p><p><strong>Outcome space</strong></p><p>The outcome space is the unique sorted values of the input. Hence, input <code>x</code> is needed for a well-defined <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.outcome_space"><code>outcome_space</code></a>.</p><p><strong>Implements</strong></p><ul><li><a href="#ComplexityMeasures.codify"><code>codify</code></a>. Used for encoding inputs where ordering matters (e.g. time series).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/v3.6.5/src/outcome_spaces/unique_elements.jl#L3-L18">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ComplexityMeasures.CosineSimilarityBinning" href="#ComplexityMeasures.CosineSimilarityBinning"><code>ComplexityMeasures.CosineSimilarityBinning</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CosineSimilarityBinning(; m::Int, τ::Int, nbins::Int)</code></pre><p>A <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a> based on the cosine similarity (<a href="../../references/#Wang2020">Wang <em>et al.</em>, 2020</a>).</p><p>It can be used with <a href="../information_single_variable_api/#ComplexityMeasures.information"><code>information</code></a> to compute the &quot;diversity entropy&quot; of an input timeseries (<a href="../../references/#Wang2020">Wang <em>et al.</em>, 2020</a>).</p><p>The implementation here allows for <code>τ != 1</code>, which was not considered in the original paper.</p><p><strong>Description</strong></p><p>CosineSimilarityBinning probabilities are computed as follows.</p><ol><li>From the input time series <code>x</code>, using embedding lag <code>τ</code> and embedding dimension <code>m</code>,  construct the embedding  <span>$Y = \{\bf x_i \} = \{(x_{i}, x_{i+\tau}, x_{i+2\tau}, \ldots, x_{i+m\tau - 1}\}_{i = 1}^{N-mτ}$</span>.</li><li>Compute <span>$D = \{d(\bf x_t, \bf x_{t+1}) \}_{t=1}^{N-mτ-1}$</span>,  where <span>$d(\cdot, \cdot)$</span> is the cosine similarity between two <code>m</code>-dimensional  vectors in the embedding.</li><li>Divide the interval <code>[-1, 1]</code> into <code>nbins</code> equally sized subintervals (including the value <code>+1</code>).</li><li>Construct a histogram of cosine similarities <span>$d \in D$</span> over those subintervals.</li><li>Sum-normalize the histogram to obtain probabilities.</li></ol><p><strong>Outcome space</strong></p><p>The outcome space for <code>CosineSimilarityBinning</code> is the bins of the <code>[-1, 1]</code> interval, and the return configuration is the same as in <a href="#ComplexityMeasures.ValueBinning"><code>ValueBinning</code></a> (left bin edge).</p><p><strong>Implements</strong></p><ul><li><a href="#ComplexityMeasures.codify"><code>codify</code></a>. Used for encoding inputs where ordering matters (e.g. time series).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/v3.6.5/src/outcome_spaces/cosine_similarity_binning.jl#L5-L38">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ComplexityMeasures.Dispersion" href="#ComplexityMeasures.Dispersion"><code>ComplexityMeasures.Dispersion</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Dispersion(; c = 5, m = 2, τ = 1, check_unique = true)</code></pre><p>An <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a> based on dispersion patterns, originally used by <a href="../../references/#Rostaghi2016">Rostaghi and Azami (2016)</a> to compute the &quot;dispersion entropy&quot;, which characterizes the complexity and irregularity of a time series.</p><p>Recommended parameter values (<a href="../../references/#Li2018">Li <em>et al.</em>, 2019</a>) are <code>m ∈ [2, 3]</code>, <code>τ = 1</code> for the embedding, and <code>c ∈ [3, 4, …, 8]</code> categories for the Gaussian symbol mapping.</p><p><strong>Description</strong></p><p>Assume we have a univariate time series <span>$X = \{x_i\}_{i=1}^N$</span>. First, this time series is encoded into a symbol timeseries <span>$S$</span> using the Gaussian encoding <a href="#ComplexityMeasures.GaussianCDFEncoding"><code>GaussianCDFEncoding</code></a> with empirical mean <code>μ</code> and empirical standard deviation <code>σ</code> (both determined from <span>$X$</span>), and <code>c</code> as given to <code>Dispersion</code>.</p><p>Then, <span>$S$</span> is embedded into an <span>$m$</span>-dimensional time series, using an embedding lag of <span>$\tau$</span>, which yields a total of <span>$N - (m - 1)\tau$</span> delay vectors <span>$z_i$</span>, or &quot;dispersion patterns&quot;. Since each element of <span>$z_i$</span> can take on <code>c</code> different values, and each delay vector has <code>m</code> entries, there are <code>c^m</code> possible dispersion patterns. This number is used for normalization when computing dispersion entropy.</p><p>The returned probabilities are simply the frequencies of the unique dispersion patterns present in <span>$S$</span> (i.e., the <a href="#ComplexityMeasures.UniqueElements"><code>UniqueElements</code></a> of <span>$S$</span>).</p><p><strong>Outcome space</strong></p><p>The outcome space for <code>Dispersion</code> is the unique delay vectors whose elements are the the symbols (integers) encoded by the Gaussian CDF, i.e., the unique elements of <span>$S$</span>.</p><p><strong>Data requirements and parameters</strong></p><p>The input must have more than one unique element for the Gaussian mapping to be well-defined. <a href="../../references/#Li2018">Li <em>et al.</em> (2019)</a> recommends that <code>x</code> has at least 1000 data points.</p><p>If <code>check_unique == true</code> (default), then it is checked that the input has more than one unique value. If <code>check_unique == false</code> and the input only has one unique element, then a <code>InexactError</code> is thrown when trying to compute probabilities.</p><div class="admonition is-info"><header class="admonition-header">Why &#39;dispersion patterns&#39;?</header><div class="admonition-body"><p>Each embedding vector is called a &quot;dispersion pattern&quot;. Why? Let&#39;s consider the case when <span>$m = 5$</span> and <span>$c = 3$</span>, and use some very imprecise terminology for illustration:</p><p>When <span>$c = 3$</span>, values clustering far below mean are in one group, values clustered around the mean are in one group, and values clustering far above the mean are in a third group. Then the embedding vector <span>$[2, 2, 2, 2, 2]$</span> consists of values that are close together (close to the mean), so it represents a set of numbers that are not very spread out (less dispersed). The embedding vector <span>$[1, 1, 2, 3, 3]$</span>, however, represents numbers that are much more spread out (more dispersed), because the categories representing &quot;outliers&quot; both above and below the mean are represented, not only values close to the mean.</p></div></div><p>For a version of this estimator that can be used on high-dimensional arrays, see <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.SpatialDispersion"><code>SpatialDispersion</code></a>.</p><p><strong>Implements</strong></p><ul><li><a href="#ComplexityMeasures.codify"><code>codify</code></a>. Used for encoding inputs where ordering matters (e.g. time series).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/v3.6.5/src/outcome_spaces/dispersion.jl#L5-L64">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ComplexityMeasures.OrdinalPatterns" href="#ComplexityMeasures.OrdinalPatterns"><code>ComplexityMeasures.OrdinalPatterns</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">OrdinalPatterns &lt;: OutcomeSpace
OrdinalPatterns{m}(τ = 1, lt::Function = ComplexityMeasures.isless_rand)</code></pre><p>An <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a> based on lengh-<code>m</code> ordinal permutation patterns, originally introduced in <a href="../../references/#BandtPompe2002">Bandt and Pompe (2002)</a>&#39;s paper on permutation entropy. Note that <code>m</code> is given as a type parameter, so that when it is a literal integer there are performance accelerations.</p><p>When passed to <a href="../counts_and_probabilities_api/#ComplexityMeasures.probabilities-Tuple{OutcomeSpace}"><code>probabilities</code></a> the output depends on the input data type:</p><ul><li><strong>Univariate data</strong>. If applied to a univariate timeseries (<code>AbstractVector</code>), then the timeseries   is first embedded using embedding delay <code>τ</code> and dimension <code>m</code>, resulting in embedding   vectors <span>$\{ \bf{x}_i \}_{i=1}^{N-(m-1)\tau}$</span>. Then, for each <span>$\bf{x}_i$</span>,   we find its permutation pattern <span>$\pi_{i}$</span>. Probabilities are then   estimated as the frequencies of the encoded permutation symbols   by using <a href="#ComplexityMeasures.UniqueElements"><code>UniqueElements</code></a>. When giving the resulting probabilities to   <a href="../information_single_variable_api/#ComplexityMeasures.information"><code>information</code></a>, the original permutation entropy is computed (<a href="../../references/#BandtPompe2002">Bandt and Pompe, 2002</a>).</li><li><strong>Multivariate data</strong>. If applied to a an <code>D</code>-dimensional <code>StateSpaceSet</code>,   then no embedding is constructed, <code>m</code> must be equal to <code>D</code> and <code>τ</code> is ignored.   Each vector <span>$\bf{x}_i$</span> of the dataset is mapped   directly to its permutation pattern <span>$\pi_{i}$</span> by comparing the   relative magnitudes of the elements of <span>$\bf{x}_i$</span>.   Like above, probabilities are estimated as the frequencies of the permutation symbols.   The resulting probabilities can be used to compute multivariate permutation   entropy (<a href="../../references/#He2016">He <em>et al.</em>, 2016</a>), although here we don&#39;t perform any further subdivision   of the permutation patterns (as in Figure 3 of <a href="../../references/#He2016">He <em>et al.</em> (2016)</a>).</li></ul><p>Internally, <a href="#ComplexityMeasures.OrdinalPatterns"><code>OrdinalPatterns</code></a> uses the <a href="#ComplexityMeasures.OrdinalPatternEncoding"><code>OrdinalPatternEncoding</code></a> to represent ordinal patterns as integers for efficient computations.</p><p>See <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.WeightedOrdinalPatterns"><code>WeightedOrdinalPatterns</code></a> and <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.AmplitudeAwareOrdinalPatterns"><code>AmplitudeAwareOrdinalPatterns</code></a> for estimators that not only consider ordinal (sorting) patterns, but also incorporate information about within-state-vector amplitudes. For a version of this estimator that can be used on spatial data, see <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.SpatialOrdinalPatterns"><code>SpatialOrdinalPatterns</code></a>.</p><div class="admonition is-info"><header class="admonition-header">Handling equal values in ordinal patterns</header><div class="admonition-body"><p>In <a href="../../references/#BandtPompe2002">Bandt and Pompe (2002)</a>, equal values are ordered after their order of appearance, but this can lead to erroneous temporal correlations, especially for data with low amplitude resolution (<a href="../../references/#Zunino2017">Zunino <em>et al.</em>, 2017</a>). Here, by default, if two values are equal, then one of the is randomly assigned as &quot;the largest&quot;, using <code>lt = ComplexityMeasures.isless_rand</code>. To get the behaviour from <a href="../../references/#BandtPompe2002">Bandt and Pompe (2002)</a>, use <code>lt = Base.isless</code>.</p></div></div><p><strong>Outcome space</strong></p><p>The outcome space <code>Ω</code> for <code>OrdinalPatterns</code> is the set of length-<code>m</code> ordinal patterns (i.e. permutations) that can be formed by the integers <code>1, 2, …, m</code>. There are <code>factorial(m)</code> such patterns.</p><p>For example, the outcome <code>[2, 3, 1]</code> corresponds to the ordinal pattern of having the smallest value in the second position, the next smallest value in the third position, and the next smallest, i.e. the largest value in the first position. See also <a href="#ComplexityMeasures.OrdinalPatternEncoding"><code>OrdinalPatternEncoding</code></a>.</p><p><strong>In-place symbolization</strong></p><p><code>OrdinalPatterns</code> also implements the in-place <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.probabilities%21"><code>probabilities!</code></a> for <code>StateSpaceSet</code> input (or embedded vector input) for reducing allocations in looping scenarios. The length of the pre-allocated symbol vector must be the length of the dataset. For example</p><pre><code class="language-julia hljs">using ComplexityMeasures
m, N = 2, 100
est = OrdinalPatterns{m}(τ)
x = StateSpaceSet(rand(N, m)) # some input dataset
πs_ts = zeros(Int, N) # length must match length of `x`
p = probabilities!(πs_ts, est, x)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/v3.6.5/src/outcome_spaces/ordinal_patterns.jl#L24-L96">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ComplexityMeasures.BubbleSortSwaps" href="#ComplexityMeasures.BubbleSortSwaps"><code>ComplexityMeasures.BubbleSortSwaps</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">BubbleSortSwaps &lt;: CountBasedOutcomeSpace
BubbleSortSwaps(; m = 3, τ = 1)</code></pre><p>The <code>BubbleSortSwaps</code> outcome space is based on <a href="../../references/#Manis2017">Manis <em>et al.</em> (2017)</a>&#39;s  paper on &quot;bubble entropy&quot;. </p><p><strong>Description</strong></p><p><code>BubbleSortSwaps</code> does the following:</p><ul><li>Embeds the input data using embedding dimension <code>m</code> and  embedding lag <code>τ</code></li><li>For each state vector in the embedding, counting how many swaps are necessary for   the bubble sort algorithm to sort state vectors.</li></ul><p>For <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.counts_and_outcomes"><code>counts_and_outcomes</code></a>, we then define a distribution over the number of  necessary swaps. This distribution can then be used to estimate probabilities using  <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.probabilities_and_outcomes"><code>probabilities_and_outcomes</code></a>, which again can be used to estimate any  <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/information_measures/#ComplexityMeasures.InformationMeasure"><code>InformationMeasure</code></a>. An example of how to compute the &quot;Shannon bubble entropy&quot; is given below.</p><p><strong>Outcome space</strong></p><p>The <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.outcome_space"><code>outcome_space</code></a> for <code>BubbleSortSwaps</code> are the integers <code>0:N</code>, where <code>N = (m * (m - 1)) / 2 + 1</code> (the worst-case number of swaps). Hence, the number of <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.total_outcomes"><code>total_outcomes</code></a> is <code>N + 1</code>.</p><p><strong>Implements</strong></p><ul><li><a href="#ComplexityMeasures.codify"><code>codify</code></a>. Returns the number of swaps required for each embedded state vector.</li></ul><p><strong>Examples</strong></p><p>With the <code>BubbleSortSwaps</code> outcome space, we can easily compute a &quot;bubble entropy&quot; inspired by (<a href="../../references/#Manis2017">Manis <em>et al.</em>, 2017</a>). Note: this is not actually a new entropy - it is just  a new way of discretizing the input data. To reproduce the bubble entropy complexity measure from (<a href="../../references/#Manis2017">Manis <em>et al.</em>, 2017</a>), see <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/complexity/#ComplexityMeasures.BubbleEntropy"><code>BubbleEntropy</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using ComplexityMeasures
x = rand(100000)
o = BubbleSortSwaps(; m = 5) # 5-dimensional embedding vectors
information(Shannon(; base = 2), o, x)

# We can also compute any other &quot;bubble quantity&quot;, for example the 
# &quot;Tsallis bubble extropy&quot;, with arbitrary probabilities estimators:
information(TsallisExtropy(), BayesianRegularization(), o, x)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/v3.6.5/src/outcome_spaces/bubble_sort_swaps.jl#L3-L53">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ComplexityMeasures.ValueBinning" href="#ComplexityMeasures.ValueBinning"><code>ComplexityMeasures.ValueBinning</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ValueBinning(b::AbstractBinning) &lt;: OutcomeSpace</code></pre><p>An <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a> based on binning the values of the data as dictated by the binning scheme <code>b</code> and formally computing their histogram, i.e., the frequencies of points in the bins. An alias to this is <code>VisitationFrequency</code>. Available binnings are subtypes of <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.AbstractBinning"><code>AbstractBinning</code></a>.</p><p>The <code>ValueBinning</code> estimator has a linearithmic time complexity (<code>n log(n)</code> for <code>n = length(x)</code>) and a linear space complexity (<code>l</code> for <code>l = dimension(x)</code>). This allows computation of probabilities (histograms) of high-dimensional datasets and with small box sizes <code>ε</code> without memory overflow and with maximum performance. For performance reasons, the probabilities returned never contain 0s and are arbitrarily ordered.</p><pre><code class="nohighlight hljs">ValueBinning(ϵ::Union{Real,Vector})</code></pre><p>A convenience method that accepts same input as <a href="#ComplexityMeasures.RectangularBinning"><code>RectangularBinning</code></a> and initializes this binning directly.</p><p><strong>Outcomes</strong></p><p>The outcome space for <code>ValueBinning</code> is the unique bins constructed from <code>b</code>. Each bin is identified by its left (lowest-value) corner, because bins are always left-closed-right-open intervals <code>[a, b)</code>. The bins are in data units, not integer (cartesian indices units), and are returned as <code>SVector</code>s, i.e., same type as input data.</p><p>For convenience, <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.outcome_space"><code>outcome_space</code></a> returns the outcomes in the same array format as the underlying binning (e.g., <code>Matrix</code> for 2D input).</p><p>For <a href="#ComplexityMeasures.FixedRectangularBinning"><code>FixedRectangularBinning</code></a> the <a href="https://juliadynamics.github.io/DynamicalSystemsDocs.jl/complexitymeasures/stable/probabilities/#ComplexityMeasures.outcome_space"><code>outcome_space</code></a> is well-defined from the binning, but for <a href="#ComplexityMeasures.RectangularBinning"><code>RectangularBinning</code></a> input <code>x</code> is needed as well.</p><p><strong>Implements</strong></p><ul><li><a href="#ComplexityMeasures.codify"><code>codify</code></a>. Used for encoding inputs where ordering matters (e.g. time series).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/v3.6.5/src/outcome_spaces/value_binning.jl#L4-L42">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ComplexityMeasures.RectangularBinning" href="#ComplexityMeasures.RectangularBinning"><code>ComplexityMeasures.RectangularBinning</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">RectangularBinning(ϵ, precise = false) &lt;: AbstractBinning</code></pre><p>Rectangular box partition of state space using the scheme <code>ϵ</code>, deducing the histogram extent and bin width from the input data.</p><p><code>RectangularBinning</code> is a convenience struct. It is re-cast into <a href="#ComplexityMeasures.FixedRectangularBinning"><code>FixedRectangularBinning</code></a> once the data are provided, so see that docstring for info on the bin calculation and the meaning of <code>precise</code>.</p><p>Binning instructions are deduced from the type of <code>ϵ</code> as follows:</p><ol><li><code>ϵ::Int</code> divides each coordinate axis into <code>ϵ</code> equal-length intervals  that cover all data.</li><li><code>ϵ::Float64</code> divides each coordinate axis into intervals of fixed size <code>ϵ</code>, starting  from the axis minima until the data is completely covered by boxes.</li><li><code>ϵ::Vector{Int}</code> divides the i-th coordinate axis into <code>ϵ[i]</code> equal-length  intervals that cover all data.</li><li><code>ϵ::Vector{Float64}</code> divides the i-th coordinate axis into intervals of fixed size  <code>ϵ[i]</code>, starting from the axis minima until the data is completely covered by boxes.</li></ol><p><code>RectangularBinning</code> ensures all input data are covered by extending the created ranges if need be.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/v3.6.5/src/encoding_implementations/rectangular_binning.jl#L18-L42">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ComplexityMeasures.FixedRectangularBinning" href="#ComplexityMeasures.FixedRectangularBinning"><code>ComplexityMeasures.FixedRectangularBinning</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">FixedRectangularBinning &lt;: AbstractBinning
FixedRectangularBinning(ranges::Tuple{&lt;:AbstractRange...}, precise = false)</code></pre><p>Rectangular box partition of state space where the partition along each dimension is explicitly given by each range <code>ranges</code>, which is a tuple of <code>AbstractRange</code> subtypes. Typically, each range is the output of the <code>range</code> Base function, e.g., <code>ranges = (0:0.1:1, range(0, 1; length = 101), range(2.1, 3.2; step = 0.33))</code>. All ranges must be sorted.</p><p>The optional second argument <code>precise</code> dictates whether Julia Base&#39;s <code>TwicePrecision</code> is used for when searching where a point falls into the range. Useful for edge cases of points being almost exactly on the bin edges, but it is exactly four times as slow, so by default it is <code>false</code>.</p><p>Points falling outside the partition do not contribute to probabilities. Bins are always left-closed-right-open: <code>[a, b)</code>. <strong>This means that the last value of each of the ranges dictates the last right-closing value.</strong> This value does <em>not</em> belong to the histogram! E.g., if given a range <code>r = range(0, 1; length = 11)</code>, with <code>r[end] = 1</code>, the value <code>1</code> is outside the partition and would not attribute any increase of the probability corresponding to the last bin (here <code>[0.9, 1)</code>)!</p><p><strong>Equivalently, the size of the histogram is <code>histsize = map(r -&gt; length(r)-1, ranges)</code>!</strong></p><p><code>FixedRectangularBinning</code> leads to a well-defined outcome space without knowledge of input data, see <a href="#ComplexityMeasures.ValueBinning"><code>ValueBinning</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/v3.6.5/src/encoding_implementations/rectangular_binning.jl#L49-L78">source</a></section></article><h4 id="Example:-encoding-*columns*-(one-variable-at-a-time)"><a class="docs-heading-anchor" href="#Example:-encoding-*columns*-(one-variable-at-a-time)">Example: encoding <em>columns</em> (one variable at a time)</a><a id="Example:-encoding-*columns*-(one-variable-at-a-time)-1"></a><a class="docs-heading-anchor-permalink" href="#Example:-encoding-*columns*-(one-variable-at-a-time)" title="Permalink"></a></h4><p>Some <a href="#ComplexityMeasures.OutcomeSpace"><code>OutcomeSpace</code></a>s dictate a sliding window which has the width of one element when used with <a href="#Associations.CodifyVariables"><code>CodifyVariables</code></a>. <a href="#ComplexityMeasures.ValueBinning"><code>ValueBinning</code></a> is such an outcome space.</p><pre><code class="language-julia hljs">using Associations
using Random; rng = Xoshiro(1234)

x = rand(rng, 100)
o = ValueBinning(3)
cx = codify(CodifyVariables(o), x)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">100-element Vector{Int64}:
 2
 2
 3
 1
 2
 2
 3
 3
 3
 3
 ⋮
 1
 3
 1
 3
 2
 1
 3
 2
 3</code></pre><p>We can verify that <a href="#ComplexityMeasures.ValueBinning"><code>ValueBinning</code></a> preserves the cardinality of the input dataset.</p><pre><code class="language-julia hljs">length(x) == length(cx)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">true</code></pre><p>Other outcome spaces such as <a href="#ComplexityMeasures.Dispersion"><code>Dispersion</code></a> or <a href="#ComplexityMeasures.OrdinalPatterns"><code>OrdinalPatterns</code></a> do not  preserve the cardinality of the input dataset when used with <a href="#Associations.CodifyVariables"><code>CodifyVariables</code></a>. This is  because when they are applied in a sliding window, they compress sliding windows consisting of  potentially multiple points into single integers. This means that some points at the  end of each input variable are lost. For example, with <a href="#ComplexityMeasures.OrdinalPatterns"><code>OrdinalPatterns</code></a>, the number  of encoded points decrease with the embedding parameter <code>m</code>.</p><pre><code class="language-julia hljs">using Associations
using Random; rng = Xoshiro(1234)

x = rand(rng, 100)
o = OrdinalPatterns(m = 3)
cx = codify(CodifyVariables(o), x)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">98-element Vector{Int64}:
 3
 5
 4
 1
 1
 1
 5
 6
 6
 6
 ⋮
 5
 3
 5
 4
 2
 6
 3
 2
 4</code></pre><p>We can simultaneously encode multiple variable/columns of a <a href="../../#StateSpaceSets.StateSpaceSet"><code>StateSpaceSet</code></a> using  the same outcome space, as long as the operation will result in the <em>same</em> number of encoded  data points for each column.</p><pre><code class="language-julia hljs">using Associations
using Random; rng = Xoshiro(1234)

x = rand(rng, 100)
y = rand(rng, 100)
o = OrdinalPatterns(m = 3)
# Alternatively provide a tuple of input time series: codify(CodifyVariables(o), (x, y))
cx, cy = codify(CodifyVariables(o), StateSpaceSet(x, y))

[cx cy]</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">98×2 Matrix{Int64}:
 3  1
 5  5
 4  6
 1  4
 1  2
 1  3
 5  1
 6  5
 6  4
 6  1
 ⋮  
 5  5
 3  4
 5  1
 4  5
 2  3
 6  2
 3  4
 2  5
 4  4</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../causal_graphs/">« Network/graph inference</a><a class="docs-footer-nextpage" href="../counts_and_probabilities_api/">Multivariate counts and probabilities API »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.5.0 on <span class="colophon-date" title="Sunday 4 August 2024 11:06">Sunday 4 August 2024</span>. Using Julia version 1.10.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body><div data-docstringscollapsed="true"></div></html>
