<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Transfer entropy API ¬∑ CausalityTools.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="https://fonts.googleapis.com/css?family=Montserrat|Source+Code+Pro&amp;display=swap" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img class="docs-light-only" src="../../assets/logo.png" alt="CausalityTools.jl logo"/><img class="docs-dark-only" src="../../assets/logo-dark.png" alt="CausalityTools.jl logo"/></a><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Overview</a></li><li><a class="tocitem" href="../../measures/">Association measures</a></li><li><a class="tocitem" href="../../independence/">Independence testing</a></li><li><a class="tocitem" href="../../causal_graphs/">Causal graphs</a></li><li><a class="tocitem" href="../">APIs and estimators</a></li><li><a class="tocitem" href="../../examples/">Examples</a></li><li><a class="tocitem" href="../../coupled_systems/">Predefined systems</a></li><li><a class="tocitem" href="../../experimental/">Experimental</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Transfer entropy API</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Transfer entropy API</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaDynamics/CausalityTools.jl/blob/master/docs/src/api/api_transferentropy.md" title="Edit on GitHub"><span class="docs-icon fab">ÔÇõ</span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Transfer-entropy-API"><a class="docs-heading-anchor" href="#Transfer-entropy-API">Transfer entropy API</a><a id="Transfer-entropy-API-1"></a><a class="docs-heading-anchor-permalink" href="#Transfer-entropy-API" title="Permalink"></a></h1><p>The transfer entropy API is made up of the following functions and types.</p><ul><li><a href="#CausalityTools.TransferEntropy"><code>TransferEntropy</code></a>, and its subtypes.</li><li><a href="#CausalityTools.transferentropy"><code>transferentropy</code></a>.</li><li><a href="#CausalityTools.TransferEntropyEstimator"><code>TransferEntropyEstimator</code></a>, and its subtypes.</li></ul><article class="docstring"><header><a class="docstring-binding" id="CausalityTools.transferentropy" href="#CausalityTools.transferentropy"><code>CausalityTools.transferentropy</code></a> ‚Äî <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">transferentropy([measure::TEShannon], est, s, t, [c])
transferentropy(measure::TERenyiJizba, est, s, t, [c])</code></pre><p>Estimate the transfer entropy <span>$TE^*(S \to T)$</span> or <span>$TE^*(S \to T | C)$</span> if <code>c</code> is given, using the provided estimator <code>est</code>, where <span>$*$</span> indicates the given <code>measure</code>. If <code>measure</code> is not given, then <code>TEShannon(; base = 2)</code> is the default.</p><p><strong>Arguments</strong></p><ul><li><strong><code>measure</code></strong>: The transfer entropy measure, e.g. <a href="../../measures/#CausalityTools.TEShannon"><code>TEShannon</code></a> or   <a href="api/@ref"><code>TERenyi</code></a>, which dictates which formula is computed.   Embedding parameters are stored in <code>measure.embedding</code>, and   is represented by an <a href="#CausalityTools.EmbeddingTE"><code>EmbeddingTE</code></a> instance. If calling <code>transferentropy</code>   without giving <code>measure</code>, then the embedding is optimized by finding   suitable delay embedding parameters using the <a href="https://juliadynamics.github.io/DynamicalSystems.jl/dev/embedding/traditional/">&quot;traditional&quot;</a>   approach from DynamicalSystems.jl.</li><li><strong><code>s</code></strong>: The source timeseries.</li><li><strong><code>t</code></strong>: The target timeseries.</li><li><strong><code>c</code></strong>: Optional. A conditional timeseries.</li></ul><p><strong>Description</strong></p><p>The Shannon transfer entropy is defined as <span>$TE^S(S \to T | C) := I^S(T^+; S^- | T^-, C^-)$</span>, where <span>$I^S(T^+; S^- | T^-, C^-)$</span> is <a href="../../measures/#CausalityTools.CMIShannon"><code>CMIShannon</code></a>, and marginals for the CMI are constructed as described in <a href="#CausalityTools.EmbeddingTE"><code>EmbeddingTE</code></a>. The definition is analogous for <a href="../../measures/#CausalityTools.TERenyiJizba"><code>TERenyiJizba</code></a>.</p><p>If <code>s</code>, <code>t</code>, and <code>c</code> are univariate timeseries, then the the marginal embedding variables <span>$T^+$</span> (target future), <span>$T^-$</span> (target present/past), <span>$S^-$</span> (source present/past) and <span>$C^-$</span> (present/past of conditioning variables) are constructed by first jointly embedding  <code>s</code>, <code>t</code> and <code>c</code> with relevant delay embedding parameters, then subsetting relevant columns of the embedding.</p><p>Since estimates of <span>$TE^*(S \to T)$</span> and <span>$TE^*(S \to T | C)$</span> are just a special cases of conditional mutual information where input data are marginals of a particular form of <a href="https://juliadynamics.github.io/DynamicalSystems.jl/dev/embedding/reconstruction/">delay embedding</a>, <em>any</em> combination of variables, e.g. <span>$S = (A, B)$</span>, <span>$T = (C, D)$</span>, <span>$C = (D, E, F)$</span> are valid inputs (given as <code>StateSpaceSet</code>s). In practice, however, <code>s</code>, <code>t</code> and <code>c</code> are most often timeseries, and if  <code>s</code>, <code>t</code> and <code>c</code> are <a href="../../#StateSpaceSets.StateSpaceSet"><code>StateSpaceSet</code></a>s, it is assumed that the data are pre-embedded and the embedding step is skipped.</p><p><strong>Compatible estimators</strong></p><p><code>transferentropy</code> is just a simple wrapper around <a href="../api_condmutualinfo/#CausalityTools.condmutualinfo"><code>condmutualinfo</code></a> that constructs an appropriate delay embedding from the input data before CMI is estimated. Consequently, any estimator that can be used for <a href="../api_condmutualinfo/#CausalityTools.ConditionalMutualInformation"><code>ConditionalMutualInformation</code></a> is, in principle, also a valid transfer entropy estimator. <a href="#CausalityTools.TransferEntropyEstimator"><code>TransferEntropyEstimator</code></a>s are the exception - they compute transfer entropy directly.</p><table><tr><th style="text-align: right">Estimator</th><th style="text-align: right">Type</th><th style="text-align: right">Principle</th><th style="text-align: center"><a href="../../measures/#CausalityTools.TEShannon"><code>TEShannon</code></a></th><th style="text-align: center"><a href="../../measures/#CausalityTools.TERenyiJizba"><code>TERenyiJizba</code></a></th></tr><tr><td style="text-align: right"><a href="../api_probabilities/#ComplexityMeasures.CountOccurrences"><code>CountOccurrences</code></a></td><td style="text-align: right"><a href="../api_probabilities/#ComplexityMeasures.ProbabilitiesEstimator"><code>ProbabilitiesEstimator</code></a></td><td style="text-align: right">Frequencies</td><td style="text-align: center">‚úì</td><td style="text-align: center">‚úì</td></tr><tr><td style="text-align: right"><a href="../api_probabilities/#ComplexityMeasures.ValueHistogram"><code>ValueHistogram</code></a></td><td style="text-align: right"><a href="../api_probabilities/#ComplexityMeasures.ProbabilitiesEstimator"><code>ProbabilitiesEstimator</code></a></td><td style="text-align: right">Binning (histogram)</td><td style="text-align: center">‚úì</td><td style="text-align: center">‚úì</td></tr><tr><td style="text-align: right"><a href="../api_probabilities/#ComplexityMeasures.Dispersion"><code>Dispersion</code></a></td><td style="text-align: right"><a href="../api_probabilities/#ComplexityMeasures.ProbabilitiesEstimator"><code>ProbabilitiesEstimator</code></a></td><td style="text-align: right">Dispersion patterns</td><td style="text-align: center">‚úì</td><td style="text-align: center">‚úñ</td></tr><tr><td style="text-align: right"><a href="../api_entropies/#ComplexityMeasures.Kraskov"><code>Kraskov</code></a></td><td style="text-align: right"><a href="../api_entropies/#ComplexityMeasures.DifferentialEntropyEstimator"><code>DifferentialEntropyEstimator</code></a></td><td style="text-align: right">Nearest neighbors</td><td style="text-align: center">‚úì</td><td style="text-align: center">‚úñ</td></tr><tr><td style="text-align: right"><a href="../api_entropies/#ComplexityMeasures.Zhu"><code>Zhu</code></a></td><td style="text-align: right"><a href="../api_entropies/#ComplexityMeasures.DifferentialEntropyEstimator"><code>DifferentialEntropyEstimator</code></a></td><td style="text-align: right">Nearest neighbors</td><td style="text-align: center">‚úì</td><td style="text-align: center">‚úñ</td></tr><tr><td style="text-align: right"><a href="../api_entropies/#ComplexityMeasures.ZhuSingh"><code>ZhuSingh</code></a></td><td style="text-align: right"><a href="../api_entropies/#ComplexityMeasures.DifferentialEntropyEstimator"><code>DifferentialEntropyEstimator</code></a></td><td style="text-align: right">Nearest neighbors</td><td style="text-align: center">‚úì</td><td style="text-align: center">‚úñ</td></tr><tr><td style="text-align: right"><a href="../api_entropies/#ComplexityMeasures.Gao"><code>Gao</code></a></td><td style="text-align: right"><a href="../api_entropies/#ComplexityMeasures.DifferentialEntropyEstimator"><code>DifferentialEntropyEstimator</code></a></td><td style="text-align: right">Nearest neighbors</td><td style="text-align: center">‚úì</td><td style="text-align: center">‚úñ</td></tr><tr><td style="text-align: right"><a href="../api_entropies/#ComplexityMeasures.Goria"><code>Goria</code></a></td><td style="text-align: right"><a href="../api_entropies/#ComplexityMeasures.DifferentialEntropyEstimator"><code>DifferentialEntropyEstimator</code></a></td><td style="text-align: right">Nearest neighbors</td><td style="text-align: center">‚úì</td><td style="text-align: center">‚úñ</td></tr><tr><td style="text-align: right"><a href="../api_entropies/#ComplexityMeasures.Lord"><code>Lord</code></a></td><td style="text-align: right"><a href="../api_entropies/#ComplexityMeasures.DifferentialEntropyEstimator"><code>DifferentialEntropyEstimator</code></a></td><td style="text-align: right">Nearest neighbors</td><td style="text-align: center">‚úì</td><td style="text-align: center">‚úñ</td></tr><tr><td style="text-align: right"><a href="api/@ref"><code>LeonenkoProzantoSavani</code></a></td><td style="text-align: right"><a href="../api_entropies/#ComplexityMeasures.DifferentialEntropyEstimator"><code>DifferentialEntropyEstimator</code></a></td><td style="text-align: right">Nearest neighbors</td><td style="text-align: center">‚úì</td><td style="text-align: center">‚úì</td></tr><tr><td style="text-align: right"><a href="api/@ref"><code>GaussanMI</code></a></td><td style="text-align: right"><a href="../api_mutualinfo/#CausalityTools.MutualInformationEstimator"><code>MutualInformationEstimator</code></a></td><td style="text-align: right">Parametric</td><td style="text-align: center">‚úì</td><td style="text-align: center">‚úñ</td></tr><tr><td style="text-align: right"><a href="api/@ref"><code>KSG1</code></a></td><td style="text-align: right"><a href="../api_mutualinfo/#CausalityTools.MutualInformationEstimator"><code>MutualInformationEstimator</code></a></td><td style="text-align: right">Continuous</td><td style="text-align: center">‚úì</td><td style="text-align: center">‚úñ</td></tr><tr><td style="text-align: right"><a href="api/@ref"><code>KSG2</code></a></td><td style="text-align: right"><a href="../api_mutualinfo/#CausalityTools.MutualInformationEstimator"><code>MutualInformationEstimator</code></a></td><td style="text-align: right">Continuous</td><td style="text-align: center">‚úì</td><td style="text-align: center">‚úñ</td></tr><tr><td style="text-align: right"><a href="../api_mutualinfo/#CausalityTools.GaoKannanOhViswanath"><code>GaoKannanOhViswanath</code></a></td><td style="text-align: right"><a href="../api_mutualinfo/#CausalityTools.MutualInformationEstimator"><code>MutualInformationEstimator</code></a></td><td style="text-align: right">Mixed</td><td style="text-align: center">‚úì</td><td style="text-align: center">‚úñ</td></tr><tr><td style="text-align: right"><a href="../api_mutualinfo/#CausalityTools.GaoOhViswanath"><code>GaoOhViswanath</code></a></td><td style="text-align: right"><a href="../api_mutualinfo/#CausalityTools.MutualInformationEstimator"><code>MutualInformationEstimator</code></a></td><td style="text-align: right">Continuous</td><td style="text-align: center">‚úì</td><td style="text-align: center">‚úñ</td></tr><tr><td style="text-align: right"><a href="../api_condmutualinfo/#CausalityTools.FPVP"><code>FPVP</code></a></td><td style="text-align: right"><a href="../api_condmutualinfo/#CausalityTools.ConditionalMutualInformationEstimator"><code>ConditionalMutualInformationEstimator</code></a></td><td style="text-align: right">Nearest neighbors</td><td style="text-align: center">‚úì</td><td style="text-align: center">‚úñ</td></tr><tr><td style="text-align: right"><a href="../api_condmutualinfo/#CausalityTools.MesnerShalisi"><code>MesnerShalisi</code></a></td><td style="text-align: right"><a href="../api_condmutualinfo/#CausalityTools.ConditionalMutualInformationEstimator"><code>ConditionalMutualInformationEstimator</code></a></td><td style="text-align: right">Nearest neighbors</td><td style="text-align: center">‚úì</td><td style="text-align: center">‚úñ</td></tr><tr><td style="text-align: right"><a href="../api_condmutualinfo/#CausalityTools.Rahimzamani"><code>Rahimzamani</code></a></td><td style="text-align: right"><a href="../api_condmutualinfo/#CausalityTools.ConditionalMutualInformationEstimator"><code>ConditionalMutualInformationEstimator</code></a></td><td style="text-align: right">Nearest neighbors</td><td style="text-align: center">‚úì</td><td style="text-align: center">‚úñ</td></tr><tr><td style="text-align: right"><a href="#CausalityTools.Zhu1"><code>Zhu1</code></a></td><td style="text-align: right"><a href="#CausalityTools.TransferEntropyEstimator"><code>TransferEntropyEstimator</code></a></td><td style="text-align: right">Nearest neighbors</td><td style="text-align: center">‚úì</td><td style="text-align: center">‚úñ</td></tr><tr><td style="text-align: right"><a href="#CausalityTools.Lindner"><code>Lindner</code></a></td><td style="text-align: right"><a href="#CausalityTools.TransferEntropyEstimator"><code>TransferEntropyEstimator</code></a></td><td style="text-align: right">Nearest neighbors</td><td style="text-align: center">‚úì</td><td style="text-align: center">‚úñ</td></tr><tr><td style="text-align: right"><a href="#CausalityTools.Hilbert"><code>Hilbert</code></a></td><td style="text-align: right"><a href="#CausalityTools.TransferEntropyEstimator"><code>TransferEntropyEstimator</code></a></td><td style="text-align: right">Hilbert transform</td><td style="text-align: center">‚úì</td><td style="text-align: center">‚úñ</td></tr><tr><td style="text-align: right"><a href="#CausalityTools.SymbolicTransferEntropy"><code>SymbolicTransferEntropy</code></a></td><td style="text-align: right"><a href="#CausalityTools.TransferEntropyEstimator"><code>TransferEntropyEstimator</code></a></td><td style="text-align: right">Hilbert transform</td><td style="text-align: center">‚úì</td><td style="text-align: center">‚úñ</td></tr></table></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/CausalityTools.jl/blob/cffca65dc488b9b49333ae88d4fc90e2ee34b428/src/methods/infomeasures/transferentropy/transferentropy.jl#L25-L102">source</a></section></article><h2 id="Definitions"><a class="docs-heading-anchor" href="#Definitions">Definitions</a><a id="Definitions-1"></a><a class="docs-heading-anchor-permalink" href="#Definitions" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="CausalityTools.TransferEntropy" href="#CausalityTools.TransferEntropy"><code>CausalityTools.TransferEntropy</code></a> ‚Äî <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">TransferEntropy &lt;: AssociationMeasure</code></pre><p>The supertype of all transfer entropy measures. Concrete subtypes are</p><ul><li><a href="../../measures/#CausalityTools.TEShannon"><code>TEShannon</code></a></li><li><a href="../../measures/#CausalityTools.TERenyiJizba"><code>TERenyiJizba</code></a></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/CausalityTools.jl/blob/cffca65dc488b9b49333ae88d4fc90e2ee34b428/src/methods/infomeasures/transferentropy/transferentropy.jl#L11-L17">source</a></section></article><h2 id="[TransferEntropyEstimator](@ref)s"><a class="docs-heading-anchor" href="#[TransferEntropyEstimator](@ref)s"><a href="#CausalityTools.TransferEntropyEstimator"><code>TransferEntropyEstimator</code></a>s</a><a id="[TransferEntropyEstimator](@ref)s-1"></a><a class="docs-heading-anchor-permalink" href="#[TransferEntropyEstimator](@ref)s" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="CausalityTools.TransferEntropyEstimator" href="#CausalityTools.TransferEntropyEstimator"><code>CausalityTools.TransferEntropyEstimator</code></a> ‚Äî <span class="docstring-category">Type</span></header><section><div><p>The supertype of all dedicated transfer entropy estimators.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/CausalityTools.jl/blob/cffca65dc488b9b49333ae88d4fc90e2ee34b428/src/methods/infomeasures/transferentropy/transferentropy.jl#L20-L22">source</a></section></article><h3 id="[Zhu1](@ref)"><a class="docs-heading-anchor" href="#[Zhu1](@ref)"><a href="#CausalityTools.Zhu1"><code>Zhu1</code></a></a><a id="[Zhu1](@ref)-1"></a><a class="docs-heading-anchor-permalink" href="#[Zhu1](@ref)" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="CausalityTools.Zhu1" href="#CausalityTools.Zhu1"><code>CausalityTools.Zhu1</code></a> ‚Äî <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Zhu1 &lt;: TransferEntropyEstimator
Zhu1(k = 1, w = 0, base = MathConstants.e)</code></pre><p>The <code>Zhu1</code> transfer entropy estimator (Zhu et al., 2015)<sup class="footnote-reference"><a id="citeref-Zhu2015" href="#footnote-Zhu2015">[Zhu2015]</a></sup>.</p><p>Assumes that the input data have been normalized as described in (Zhu et al., 2015).</p><p>This estimator approximates probabilities within hyperrectangles surrounding each point <code>x·µ¢ ‚àà x</code> using using <code>k</code> nearest neighbor searches. However, it also considers the number of neighbors falling on the borders of these hyperrectangles. This estimator is an extension to the entropy estimator in Singh et al. (2003).</p><p><code>w</code> is the Theiler window, which determines if temporal neighbors are excluded during neighbor searches (defaults to <code>0</code>, meaning that only the point itself is excluded when searching for neighbours).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/CausalityTools.jl/blob/cffca65dc488b9b49333ae88d4fc90e2ee34b428/src/methods/infomeasures/transferentropy/estimators/Zhu1.jl#L10-L35">source</a></section></article><h3 id="[Lindner](@ref)"><a class="docs-heading-anchor" href="#[Lindner](@ref)"><a href="#CausalityTools.Lindner"><code>Lindner</code></a></a><a id="[Lindner](@ref)-1"></a><a class="docs-heading-anchor-permalink" href="#[Lindner](@ref)" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="CausalityTools.Lindner" href="#CausalityTools.Lindner"><code>CausalityTools.Lindner</code></a> ‚Äî <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Lindner &lt;: TransferEntropyEstimator
Lindner(k = 1, w = 0, base = 2)</code></pre><p>The <code>Lindner</code> transfer entropy estimator (Lindner et al., 2011)<sup class="footnote-reference"><a id="citeref-Lindner2011" href="#footnote-Lindner2011">[Lindner2011]</a></sup>, which is also used in the Trentool MATLAB toolbox, and is based on nearest neighbor searches.</p><p><code>w</code> is the Theiler window, which determines if temporal neighbors are excluded during neighbor searches (defaults to <code>0</code>, meaning that only the point itself is excluded when searching for neighbours).</p><p><strong>Description</strong></p><p>For a given points in the joint embedding space <code>j·µ¢</code>, this estimator first computes the distance <code>d·µ¢</code> from <code>j·µ¢</code> to its <code>k</code>-th nearest neighbor. Then, for each point <code>m‚Çñ[i]</code> in the <code>k</code>-th marginal space, it counts the number of points within radius <code>d·µ¢</code>.</p><p>The transfer entropy is then computed as</p><p class="math-container">\[TE(X \to Y) =
\psi(k) + \dfrac{1}{N} \sum_{i}^n
\left[
    \sum_{k=1}^3 \left( \psi(m_k[i] + 1) \right)
\right],\]</p><p>where the index <code>k</code> references the three marginal subspaces <code>T</code>, <code>TTf</code> and <code>ST</code> for which neighbor searches are performed.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/CausalityTools.jl/blob/cffca65dc488b9b49333ae88d4fc90e2ee34b428/src/methods/infomeasures/transferentropy/estimators/Lindner.jl#L7-L41">source</a></section></article><h2 id="Convenience"><a class="docs-heading-anchor" href="#Convenience">Convenience</a><a id="Convenience-1"></a><a class="docs-heading-anchor-permalink" href="#Convenience" title="Permalink"></a></h2><h3 id="[SymbolicTransferEntropy](@ref)"><a class="docs-heading-anchor" href="#[SymbolicTransferEntropy](@ref)"><a href="#CausalityTools.SymbolicTransferEntropy"><code>SymbolicTransferEntropy</code></a></a><a id="[SymbolicTransferEntropy](@ref)-1"></a><a class="docs-heading-anchor-permalink" href="#[SymbolicTransferEntropy](@ref)" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="CausalityTools.SymbolicTransferEntropy" href="#CausalityTools.SymbolicTransferEntropy"><code>CausalityTools.SymbolicTransferEntropy</code></a> ‚Äî <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">SymbolicTransferEntropy &lt;: TransferEntropyEstimator
SymbolicTransferEntropy(; m = 3, œÑ = 1, lt = ComplexityMeasures.isless_rand</code></pre><p>A convenience estimator for symbolic transfer entropy (Stanieck &amp; Lenertz, 2008)<sup class="footnote-reference"><a id="citeref-Stanieck2008" href="#footnote-Stanieck2008">[Stanieck2008]</a></sup>.</p><p><strong>Description</strong></p><p><a href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.100.158101">Symbolic transfer entropy</a> consists of two simple steps. First, the input time series are embedded with embedding lag <code>m</code> and delay <code>œÑ</code>. The ordinal patterns of the embedding vectors are then encoded using <a href="../api_probabilities/#ComplexityMeasures.SymbolicPermutation"><code>SymbolicPermutation</code></a> with <a href="../api_contingency_table/#CausalityTools.marginal_encodings"><code>marginal_encodings</code></a>. This transforms the input time series into integer time series using <a href="../api_probabilities/#ComplexityMeasures.OrdinalPatternEncoding"><code>OrdinalPatternEncoding</code></a>.</p><p>Transfer entropy is then estimated as usual on the encoded timeseries with <a href="#CausalityTools.transferentropy"><code>transferentropy</code></a> and the <a href="../api_probabilities/#ComplexityMeasures.CountOccurrences"><code>CountOccurrences</code></a> naive frequency estimator.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/CausalityTools.jl/blob/cffca65dc488b9b49333ae88d4fc90e2ee34b428/src/methods/infomeasures/transferentropy/convenience/SymbolicTransferEntropy.jl#L3-L24">source</a></section></article><h3 id="[Hilbert](@ref)"><a class="docs-heading-anchor" href="#[Hilbert](@ref)"><a href="#CausalityTools.Hilbert"><code>Hilbert</code></a></a><a id="[Hilbert](@ref)-1"></a><a class="docs-heading-anchor-permalink" href="#[Hilbert](@ref)" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="CausalityTools.Hilbert" href="#CausalityTools.Hilbert"><code>CausalityTools.Hilbert</code></a> ‚Äî <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Hilbert(est;
    source::InstantaneousSignalProperty = Phase(),
    target::InstantaneousSignalProperty = Phase(),
    cond::InstantaneousSignalProperty = Phase())
) &lt;: TransferDifferentialEntropyEstimator</code></pre><p>Compute transfer entropy on instantaneous phases/amplitudes of relevant signals, which are obtained by first applying the Hilbert transform to each signal, then extracting the phases/amplitudes of the resulting complex numbers<sup class="footnote-reference"><a id="citeref-Palus2014" href="#footnote-Palus2014">[Palus2014]</a></sup>. Original time series are thus transformed to instantaneous phase/amplitude time series. Transfer entropy is then estimated using the provided <code>est</code> on those phases/amplitudes (use e.g. <a href="api/@ref"><code>VisitationFrequency</code></a>, or <a href="../api_probabilities/#ComplexityMeasures.SymbolicPermutation"><code>SymbolicPermutation</code></a>).</p><div class="admonition is-info"><header class="admonition-header">Info</header><div class="admonition-body"><p>Details on estimation of the transfer entropy (conditional mutual information) following the phase/amplitude extraction step is not given in Palus (2014). Here, after instantaneous phases/amplitudes have been obtained, these are treated as regular time series, from which transfer entropy is then computed as usual.</p></div></div><p>See also: <a href="#CausalityTools.Phase"><code>Phase</code></a>, <a href="#CausalityTools.Amplitude"><code>Amplitude</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/CausalityTools.jl/blob/cffca65dc488b9b49333ae88d4fc90e2ee34b428/src/methods/infomeasures/transferentropy/convenience/Hilbert.jl#L20-L43">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalityTools.Phase" href="#CausalityTools.Phase"><code>CausalityTools.Phase</code></a> ‚Äî <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Phase &lt;: InstantaneousSignalProperty</code></pre><p>Indicates that the instantaneous phases of a signal should be used. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/CausalityTools.jl/blob/cffca65dc488b9b49333ae88d4fc90e2ee34b428/src/methods/infomeasures/transferentropy/convenience/Hilbert.jl#L14-L17">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalityTools.Amplitude" href="#CausalityTools.Amplitude"><code>CausalityTools.Amplitude</code></a> ‚Äî <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Amplitude &lt;: InstantaneousSignalProperty</code></pre><p>Indicates that the instantaneous amplitudes of a signal should be used. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/CausalityTools.jl/blob/cffca65dc488b9b49333ae88d4fc90e2ee34b428/src/methods/infomeasures/transferentropy/convenience/Hilbert.jl#L8-L11">source</a></section></article><h2 id="Utilities"><a class="docs-heading-anchor" href="#Utilities">Utilities</a><a id="Utilities-1"></a><a class="docs-heading-anchor-permalink" href="#Utilities" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="CausalityTools.optimize_marginals_te" href="#CausalityTools.optimize_marginals_te"><code>CausalityTools.optimize_marginals_te</code></a> ‚Äî <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">optimize_marginals_te([scheme = OptimiseTraditional()], s, t, [c]) ‚Üí EmbeddingTE</code></pre><p>Optimize marginal embeddings for transfer entropy computation from source time series <code>s</code> to target time series <code>t</code>, conditioned on <code>c</code> if <code>c</code> is given, using the provided optimization <code>scheme</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/CausalityTools.jl/blob/cffca65dc488b9b49333ae88d4fc90e2ee34b428/src/methods/infomeasures/transferentropy/optimization/traditional_optimal_embedding.jl#L22-L28">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalityTools.EmbeddingTE" href="#CausalityTools.EmbeddingTE"><code>CausalityTools.EmbeddingTE</code></a> ‚Äî <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">EmbeddingTE(; dS = 1, dT = 1, dTf = 1, dC = 1, œÑS = -1, œÑT = -1, Œ∑Tf = 1, œÑC = -1)
EmbeddingTE(opt::OptimiseTraditional, s, t, [c])</code></pre><p><code>EmbeddingTE</code> provide embedding parameters for transfer entropy analysis using either <a href="../../measures/#CausalityTools.TEShannon"><code>TEShannon</code></a>, <a href="api/@ref"><code>TERenyi</code></a>, or in general any subtype of <a href="#CausalityTools.TransferEntropy"><code>TransferEntropy</code></a>, which in turns dictates the embedding used with <a href="#CausalityTools.transferentropy"><code>transferentropy</code></a>.</p><p>The second method finds parameters using the <a href="https://juliadynamics.github.io/DynamicalSystems.jl/dev/embedding/traditional/">&quot;traditional&quot;</a> optimised embedding techniques from DynamicalSystems.jl</p><p><strong>Convention for generalized delay reconstruction</strong></p><p>We use the following convention. Let <span>$s(i)$</span> be time series for the source variable, <span>$t(i)$</span> be the time series for the target variable and <span>$c(i)$</span> the time series for the conditional variable. To compute transfer entropy, we need the following marginals:</p><p class="math-container">\[\begin{aligned}
T^{+} &amp;= \{t(i+\eta^1), t(i+\eta^2), \ldots, (t(i+\eta^{d_{T^{+}}}) \} \\
T^{-} &amp;= \{ (t(i+\tau^0_{T}), t(i+\tau^1_{T}), t(i+\tau^2_{T}), \ldots, t(t + \tau^{d_{T} - 1}_{T})) \} \\
S^{-} &amp;= \{ (s(i+\tau^0_{S}), s(i+\tau^1_{S}), s(i+\tau^2_{S}), \ldots, s(t + \tau^{d_{S} - 1}_{S})) \} \\
C^{-} &amp;= \{ (c(i+\tau^0_{C}), c(i+\tau^1_{C}), c(i+\tau^2_{C}), \ldots, c(t + \tau^{d_{C} - 1}_{C})) \}
\end{aligned}\]</p><p>Depending on the application, the delay reconstruction lags <span>$\tau^k_{T} \leq 0$</span>, <span>$\tau^k_{S} \leq 0$</span>, and <span>$\tau^k_{C} \leq 0$</span> may be equally spaced, or non-equally spaced. The same applied to the prediction lag(s), but typically only a only a single predictions lag <span>$\eta^k$</span> is used (so that <span>$d_{T^{+}} = 1$</span>).</p><p>For transfer entropy, traditionally at least one <span>$\tau^k_{T}$</span>, one <span>$\tau^k_{S}$</span> and one <span>$\tau^k_{C}$</span> equals zero. This way, the <span>$T^{-}$</span>, <span>$S^{-}$</span> and <span>$C^{-}$</span> marginals always contains present/past states, while the <span>$\mathcal T$</span> marginal contain future states relative to the other marginals. However, this is not a strict requirement, and modern approaches that searches for optimal embeddings can return embeddings without the intantaneous lag.</p><p>Combined, we get the generalized delay reconstruction <span>$\mathbb{E} = (T^{+}_{(d_{T^{+}})}, T^{-}_{(d_{T})}, S^{-}_{(d_{S})}, C^{-}_{(d_{C})})$</span>. Transfer entropy is then computed as</p><p class="math-container">\[\begin{aligned}
TE_{S \rightarrow T | C} = \int_{\mathbb{E}} P(T^{+}, T^-, S^-, C^-)
\log_{b}{\left(\frac{P(T^{+} | T^-, S^-, C^-)}{P(T^{+} | T^-, C^-)}\right)},
\end{aligned}\]</p><p>or, if conditionals are not relevant,</p><p class="math-container">\[\begin{aligned}
TE_{S \rightarrow T} = \int_{\mathbb{E}} P(T^{+}, T^-, S^-)
\log_{b}{\left(\frac{P(T^{+} | T^-, S^-)}{P(T^{+} | T^-)}\right)},
\end{aligned}\]</p><p>Here,</p><ul><li><span>$T^{+}$</span> denotes the <span>$d_{T^{+}}$</span>-dimensional set of vectors furnishing the future   states of <span>$T$</span> (almost always equal to 1 in practical applications),</li><li><span>$T^{-}$</span> denotes the <span>$d_{T}$</span>-dimensional set of vectors furnishing the past and   present states of <span>$T$</span>,</li><li><span>$S^{-}$</span> denotes the <span>$d_{S}$</span>-dimensional set of vectors furnishing the past and   present of <span>$S$</span>, and</li><li><span>$C^{-}$</span> denotes the <span>$d_{C}$</span>-dimensional set of vectors furnishing the past and   present of <span>$C$</span>.</li></ul><p><strong>Keyword arguments</strong></p><ul><li><code>dS</code>, <code>dT</code>, <code>dC</code>, <code>dTf</code> (<code>f</code> for <em>future</em>) are the dimensions of the <span>$S^{-}$</span>,   <span>$T^{-}$</span>, <span>$C^{-}$</span> and <span>$T^{+}$</span> marginals. The parameters <code>dS</code>, <code>dT</code>, <code>dC</code> and <code>dTf</code>   must each be a <em>positive</em> integer number.</li><li><code>œÑS</code>, <code>œÑT</code>, <code>œÑC</code> are the embedding lags for <span>$S^{-}$</span>, <span>$T^{-}$</span>, <span>$C^{-}$</span>.   Each parameter are integers <code>‚àà ùí©‚Å∞‚Åª</code>, or a vector of integers <code>‚àà ùí©‚Å∞‚Åª</code>, so   that <span>$S^{-}$</span>, <span>$T^{-}$</span>, <span>$C^{-}$</span> always represents present/past values.   If e.g. <code>œÑT</code> is an integer, then for the <span>$T^-$</span> marginal is constructed using   lags <span>$\tau_{T} = \{0, \tau, 2\tau, \ldots, (d_{T}- 1)\tau_T \}$</span>.   If is a vector, e.g. <code>œÑŒ§ = [-1, -5, -7]</code>, then the dimension <code>dT</code> must match the lags,   and precisely those lags are used: <span>$\tau_{T} = \{-1, -5, -7 \}$</span>.</li><li>The prediction lag(s) <code>Œ∑Tf</code> is a positive integer. Combined with the requirement   that the other delay parameters are zero or negative, this ensures that we&#39;re   always predicting from past/present to future. In typical applications,   <code>Œ∑Tf = 1</code> is used for transfer entropy.</li></ul><p><strong>Examples</strong></p><p>Say we wanted to compute the Shannon transfer entropy <span>$TE^S(S \to T) = I^S(T^+; S^- | T^-)$</span>. Using some modern procedure for determining optimal embedding parameters using <a href="https://juliadynamics.github.io/DynamicalSystems.jl/dev/embedding/unified/">methods from DynamicalSystems.jl</a>, we find that the optimal embedding of <span>$T^{-}$</span> is three-dimensional and is given by the lags <code>[0, -5, -8]</code>. Using the same procedure, we find that the optimal embedding of <span>$S^{-}$</span> is two-dimensional with lags <span>$[-1, -8]$</span>. We want to predicting a univariate version of the target variable one time step into the future (<code>Œ∑Tf = 1</code>). The total embedding is then the set of embedding vectors</p><p><span>$E_{TE} = \{ (T(i+1), S(i-1), S(i-8), T(i), T(i-5), T(i-8)) \}$</span>. Translating this to code, we get:</p><pre><code class="language-julia-repl hljs">using CausalityTools
julia&gt; EmbeddingTE(dT=3, œÑT=[0, -5, -8], dS=2, œÑS=[-1, -4], Œ∑Tf=1)

# output
EmbeddingTE(dS=2, dT=3, dC=1, dTf=1, œÑS=[-1, -4], œÑT=[0, -5, -8], œÑC=-1, Œ∑Tf=1)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/CausalityTools.jl/blob/cffca65dc488b9b49333ae88d4fc90e2ee34b428/src/methods/infomeasures/transferentropy/embedding.jl#L3-L114">source</a></section></article><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-Zhu2015"><a class="tag is-link" href="#citeref-Zhu2015">Zhu2015</a>Zhu, J., Bellanger, J. J., Shu, H., &amp; Le Bouquin Jeann√®s, R. (2015). Contribution to transfer entropy estimation via the k-nearest-neighbors approach. Entropy, 17(6), 4173-4201.</li><li class="footnote" id="footnote-Singh2003"><a class="tag is-link" href="#citeref-Singh2003">Singh2003</a>Singh, H., Misra, N., Hnizdo, V., Fedorowicz, A., &amp; Demchuk, E. (2003). Nearest neighbor estimates of entropy. American journal of mathematical and management sciences, 23(3-4), 301-321.</li><li class="footnote" id="footnote-Lindner2011"><a class="tag is-link" href="#citeref-Lindner2011">Lindner2011</a>Lindner, M., Vicente, R., Priesemann, V., &amp; Wibral, M. (2011). TRENTOOL: A Matlab open source toolbox to analyse information flow in time series data with transfer entropy. BMC neuroscience, 12(1), 1-22.</li><li class="footnote" id="footnote-Stanieck2008"><a class="tag is-link" href="#citeref-Stanieck2008">Stanieck2008</a>Staniek, M., &amp; Lehnertz, K. (2008). Symbolic transfer entropy. Physical review letters, 100(15), 158101.</li><li class="footnote" id="footnote-Palus2014"><a class="tag is-link" href="#citeref-Palus2014">Palus2014</a>Palu≈°, M. (2014). Cross-scale interactions and information transfer. Entropy, 16(10), 5263-5289.</li></ul></section></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Sunday 12 March 2023 00:24">Sunday 12 March 2023</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
