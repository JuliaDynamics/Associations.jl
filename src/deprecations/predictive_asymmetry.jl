export predictive_asymmetry

function causalbalance(lags, tes)
    posinds = findall(lags .> 0)
    neginds = findall(lags .< 0)
    sum(tes[posinds]) - sum(tes[neginds])
end

function verified_prediction_lags(lag::Int)
    # If only one Î· is provided (either positive or negative), just make a prediction
    # for that lag.
    Î·s = [-abs(lag), abs(lag)]
end

function verified_prediction_lags(lags)
    Î·s = sort(lags[lags .!= 0])

    if length(Î·s) % 2 != 0
        throw(ArgumentError("Need an even number of lags (as many negative as positive prediction lags)"))
    end

    Î·s_neg = Î·s[Î·s .< 0]
    Î·s_pos = Î·s[Î·s .> 0]

    if length(Î·s_neg) != length(Î·s_pos)
        throw(ArgumentError("There must be as many negative as positive prediction lags. Got $Î·s_neg and $Î·s_pos"))
    end

    Î·s_neg_sort = sort(abs.(Î·s_neg))
    Î·s_pos_sort = sort(Î·s_pos)
    if !(all(Î·s_neg_sort .== Î·s_pos_sort))
        throw(ArgumentError("Negative amd positive prediction lags must be symmetric. Got $Î·s_neg and $Î·s_pos"))
    end

    return Î·s
end

"""
    predictive_asymmetry(estimator::TransferEntropyEstimator, Î·s; s, t, [c],
        dTf = 1, dT = 1, dS = 1, Ï„T = -1, Ï„S = -1, [dC = 1, Ï„C = -1],
        normalize::Bool = false, f::Real = 1.0, base = 2) â†’ Vector{Float64}

Compute the predictive asymmetry[^Haaga2020] ğ”¸(`s` â†’ `t`) for source time series `s` and
target time series `t` over prediction lags `Î·s`, using the given `estimator` and embedding
parameters `dTf`, `dT`, `dS`, `Ï„T`, `Ï„S` (see also [`EmbeddingTE`](@ref))

If a conditional time series `c` is provided, compute ğ”¸(`s` â†’ `t` | `c`). Then, `dC` and
`Ï„C` controls the embedding dimension and embedding lag for the conditional variable.

## Returns

Returns a vector containing the predictive asymmetry for each value of `Î·s`.

## Normalization (hypothesis test)

If `normalize == true` (the default), then compute the normalized predictive asymmetry ğ’œ.
In this case, for each ``\\eta`` in `Î·s`, compute ğ’œ(Î·) by normalizing ğ”¸(Î·) to some fraction `f` of the
mean transfer entropy over prediction lags ``-\\eta, ..., \\eta`` (exluding lag 0).
Haaga et al. (2020)[^Haaga2020] uses a normalization with `f=1.0` as a built-in hypothesis test,
avoiding more computationally costly surrogate testing.

## Estimators

Any [estimator](@ref) that works for [`transferentropy`](@ref) will also work with
`predictive_asymmetry`. Check the online documentation for compatiable estimators.

## Examples

```julia
using CausalityTools
# Some example time series
x, y = rand(100), rand(100)
# ğ”¸(x â†’ y) over prediction lags 1:5
ğ”¸reg  = predictive_asymmetry(x, y, VisitationFrequency(RectangularBinning(5)), 1:5)
```

!!! info "Experimental!"
    This is a method that does not yet appear in a peer-reviewed scientific journal.
    Feel free to use, but consider it experimental for now. It will reappear in
    a 2.X release in new form once published in a peer-reviewed journal.

[^Haaga2020]:
    Haaga, Kristian AgasÃ¸ster, David Diego, Jo Brendryen, and Bjarte Hannisdal.
    "A simple test for causality in complex systems."
    arXiv preprint arXiv:2005.01860 (2020).
"""
function predictive_asymmetry end

function check_Î·s(Î·s)
    all(Î·s .> 0) || throw(ArgumentError("all Î·s must be >= 1, got $(Î·s)"))
    issorted(Î·s) || throw(ArgumentError("Î·s must be provided in increasing order, got $(Î·s)"))
end

const VALID_PA_ESTIMATORS = Union{
    ProbabilitiesEstimator,
    DifferentialEntropyEstimator,
    MutualInformationEstimator,
    ConditionalMutualInformationEstimator,
    TransferEntropyEstimator
    }

Base.@deprecate predictive_asymmetry(source::AbstractVector, target::AbstractVector, estimator::VALID_PA_ESTIMATORS, Î·s;
    normalize = false, f = 1.0, dğ’¯ = 1, dT = 1, dS = 1, Ï„T = -1, Ï„S = -1) predictive_asymmetry(estimator::VALID_PA_ESTIMATORS, Î·s, source, target;
        normalize = false, f = 1.0, dTf = 1, dT = 1, dS = 1, Ï„T = -1, Ï„S = -1, base = 2) false

Base.@deprecate predictive_asymmetry(source, target, cond, estimator::VALID_PA_ESTIMATORS, Î·s;
    normalize = false, f = 1.0,
    dğ’¯ = 1, dT = 1, dS = 1, dC = 1, Ï„T = -1, Ï„S = -1, Ï„C = -1) predictive_asymmetry(estimator::VALID_PA_ESTIMATORS, Î·s, source, target, cond;
    normalize = false, f = 1.0,
    dTf = 1, dT = 1, dS = 1, dC = 1, Ï„T = -1, Ï„S = -1, Ï„C = -1, base = 2) false

function predictive_asymmetry(estimator::VALID_PA_ESTIMATORS, Î·s, source, target;
        normalize = false, f::Real = 1.0,
        dTf = 1, dT = 1, dS = 1, Ï„T = -1, Ï„S = -1, base = 2)
    check_Î·s(Î·s)
    NÎ· = length(Î·s)

    te_fws = zeros(NÎ·)
    te_bws = zeros(NÎ·)
    ğ”¸s = zeros(NÎ·)

    for (i, Î·) in enumerate(Î·s)
        emb_fw = EmbeddingTE(dTf = dTf, dT = dT, dS = dS, Ï„T = Ï„T, Ï„S = Ï„S, Î·Tf = Î·)
        emb_bw = EmbeddingTE(dTf = dTf, dT = dT, dS = dS, Ï„T = Ï„T, Ï„S = Ï„S, Î·Tf = -Î·)
        te_fw = TEShannon(; base, embedding = emb_fw)
        te_bw = TEShannon(; base, embedding = emb_bw)
        te_fws[i] = transferentropy(te_fw, estimator, source, target)
        te_bws[i] = transferentropy(te_bw, estimator, source, target)

        if normalize
            ğ”¸áµ¢ = (sum(te_fws[1:i]) - sum(te_bws[1:i])) / Î·
            avg_te = (sum(te_fws[1:i]) + sum(te_bws[1:i])) / (2*Î·)
            ğ”¸s[i] = ğ”¸áµ¢ / (f*avg_te)
        else
            ğ”¸áµ¢ = (sum(te_fws[1:i]) - sum(te_bws[1:i])) / Î·
            ğ”¸s[i] = ğ”¸áµ¢
        end
    end

    return ğ”¸s
end

function predictive_asymmetry(estimator::VALID_PA_ESTIMATORS, Î·s, x::AbstractVector{<:Real}...;
        normalize = false, f::Real = 1.0,
        dTf = 1, dT = 1, dS = 1, dC = 1, Ï„T = -1, Ï„S = -1, Ï„C = -1, base = 2)
    @warn """`predictive_asymmetry` will be deprecated in CausalityTools 2.0, \
    and moved to the "Experimental" section until it appears in a peer-reviewed journal. \
    It will reappear with a new signature in a 2.X release."""
    check_Î·s(Î·s)
    NÎ· = length(Î·s)

    te_fws = zeros(NÎ·)
    te_bws = zeros(NÎ·)
    ğ”¸s = zeros(NÎ·)

    for (i, Î·) in enumerate(Î·s)
        emb_fw = EmbeddingTE(dTf = dTf, dT = dT, dS = dS, Ï„T = Ï„T, Ï„S = Ï„S, Î·Tf = Î·)
        emb_bw = EmbeddingTE(dTf = dTf, dT = dT, dS = dS, Ï„T = Ï„T, Ï„S = Ï„S, Î·Tf = -Î·)
        te_fw = TEShannon(; base, embedding = emb_fw)
        te_bw = TEShannon(; base, embedding = emb_bw)
        te_fws[i] = transferentropy(te_fw, estimator, x...)
        te_bws[i] = transferentropy(te_bw, estimator, x...)
        if normalize
            ğ”¸áµ¢ = (sum(te_fws[1:i]) - sum(te_bws[1:i])) / Î·
            avg_te = (sum(te_fws[1:i]) + sum(te_bws[1:i])) / (2*Î·)
            ğ”¸s[i] = ğ”¸áµ¢ / (f*avg_te)
        else
            ğ”¸áµ¢ = (sum(te_fws[1:i]) - sum(te_bws[1:i])) / Î·
            ğ”¸s[i] = ğ”¸áµ¢
        end
    end

    return ğ”¸s
end
