export CorrTest
export CorrTestResult

import HypothesisTests: pvalue

# Note: HypothesisTests already defines CorrelationTest.
# Until https://github.com/JuliaStats/HypothesisTests.jl/issues/290 is addressed and
# HypothesisTests.jl extends pvalue from StatsAPI.jl, we need to use a different name,
# so for now, use `CorrTest`.
"""
    CorrTest <: IndependenceTest
    CorrTest()

An independence test based correlation (for two variables) and partial
correlation (for three variables), as described in Schmidt et al. (2018)[^Schmidt2018].
Uses [`PearsonCorrelation`](@ref) and [`PartialCorrelation`](@ref) internally.

Assumes that the input data are (multivariate) normally distributed. Then
`Ï(X, Y) = 0` implies `X â«« Y ` and `Ï(X, Y | ð™) = 0` implies `X â«« Y | ð™`.

## Description

The null hypothesis is `Hâ‚€ := Ï(X, Y | ð™) = 0`. We use
the approach in Levy & Narula (1978)[^Levy1978] and compute the Z-transformation
of the observed (partial) correlation coefficient ``\\hat{\\rho}_{XY|\\bf{Z}}``:

```math
Z(\\hat{\\rho}_{XY|\\bf{Z}}) =
\\log\\dfrac{1 + \\hat{\\rho}_{XY|\\bf{Z}}}{1 - \\hat{\\rho}_{XY|\\bf{Z}}}.
```

To test the null hypothesis against the alternative hypothesis
`Hâ‚ := Ï(X, Y | ð™) > 0`, calculate

```math
\\hat{Z} = \\dfrac{1}{2}\\dfrac{Z(\\hat{\\rho}_{XY|\\bf{Z}}) - Z(0)}{\\sqrt{1/(n - d - 3)}},
```

and compute the two-sided p-value (Schmidt et al., 2018)

```math
p(X, Y | \\bf{Z}) = 2(1 - \\phi(\\sqrt{n - d - 3}Z(\\hat{\\rho}_{XY|\\bf{Z}}))),
```

where ``d`` is the dimension of ``\\bf{Z}`` and ``n`` is the number of samples.
For the pairwise case, the procedure is identical, but set ``\\bf{Z} = \\emptyset``.

## Examples

- [`CorrTest`for independence between normally distributed data](@ref examples_corrtest).

[^Levy1978]:
    Levy, K. J., & Narula, S. C. (1978). Testing hypotheses concerning partial
    correlations: Some methods and discussion. International Statistical Review/Revue Internationale de Statistique, 215-218.

[^Schmidt2018]:
    Schmidt, C., Huegle, J., & Uflacker, M. (2018, July). Order-independent
    constraint-based causal structure learning for gaussian distribution models using
    gpus. In Proceedings of the 30th International Conference on Scientific and
    Statistical Database Management (pp. 1-10).
"""
Base.@kwdef struct CorrTest{M} <: IndependenceTest{M}
    measure::M = nothing
end

"""
    CorrTestResult(pvalue, Ï, z)

A simple struct that holds the results of a [`CorrTest`](@ref) test: the (partial)
correlation coefficient `Ï`, Fisher's `z`, and `pvalue` - the two-sided
p-value for the test.
"""
struct CorrTestResult{R, Z, P}
    Ï::R
    z::Z
    pvalue::P
end
pvalue(r::CorrTestResult) = r.pvalue

function Base.show(io::IO, test::CorrTestResult)
    Î±005 = pvalue(test) < 0.05 ?
        "Î± = 0.05:  âœ“ Evidence favors dependence" :
        "Î± = 0.05:  âœ– Independence cannot be rejected"
    Î±001 = pvalue(test) < 0.01 ?
        "Î± = 0.01:  âœ“ Evidence favors dependence" :
        "Î± = 0.01:  âœ– Independence cannot be rejected"
    Î±0001 = pvalue(test) < 0.001 ?
        "Î± = 0.001: âœ“ Evidence favors dependence" :
        "Î± = 0.001: âœ– Independence cannot be rejected"

    print(io,
        """\
        `CorrTest` independence test
        ----------------------------------------------------------------------------------
        Hâ‚€: "The first two variables are independent (given the 3rd variable, if relevant)"
        Hâ‚: "The first two variables are dependent (given the 3rd variable, if relevant)"
        ----------------------------------------------------------------------------------
        Ï, (partial) correlation: $(test.Ï)
        p-value (two-sided):      $(test.pvalue)
          $Î±005
          $Î±001
          $Î±0001\
        """
        )
end

const VectorOr1D{D} = Union{AbstractVector, AbstractDataset{D}} where D
function independence(test::CorrTest, x::VectorOr1D, y::VectorOr1D, z::ArrayOrStateSpaceSet...)
    if isempty(z)
        Ï = estimate(PearsonCorrelation(), x, y)
        z = fishers_z(Ï)
        pval = pvalue(test, z, 0, length(x))
        return CorrTestResult(Ï, z, pval)
    else
        # This is already done in `estimate(::PartialCorrelation, ...)`, so may seem
        # redundant, but we need the dimension of Z, so some code duplication occurs here.
        X, Y, Z = construct_partialcor_datasets(x, y, z...)
        D = StateSpaceSet(X, Y, Z)
        cov = fastcov(D)
        precision_matrix = invert_cov(cov)
        Ï = partial_correlation_from_precision(precision_matrix, 1, 2)
        z = fishers_z(Ï)
        pval = pvalue(test, z, dimension(Z), length(x))
        return CorrTestResult(Ï, z, pval)
    end
end

"""
    pvalue(test::CorrTest, z, c::Int, n::Int)

Compute the two-sided p-value for the test of the partial correlation coefficient `pÌ‚`
being zero, where `c` is the cardinality of the conditioning set and `n` is the number of
samples.
"""
function pvalue(test::CorrTest, z, c::Int, n::Int)
    N = Normal(0, 1)
    x = sqrt(n - c - 3) * abs(z)
    return 2*(1 - cdf(N, x))
end
