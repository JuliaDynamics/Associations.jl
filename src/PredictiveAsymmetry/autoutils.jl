import TransferEntropy: process_input, embed_candidate_variables, optim_te
using DelayEmbeddings, Statistics

# Usaully, we use all lags from startlag:-\tau_max to construct variables. In some situations,
# we may want to exclude som of those variables. 
function filtered_Ï„s(Ï„s::AbstractVector{Int}, js::AbstractVector{Int}, Ï„exclude::Int)
    [Ï„ for Ï„ in Ï„s if abs(Ï„) != abs.(Ï„exclude)]
end

function filtered_js(Ï„s::AbstractVector{Int}, js::AbstractVector{Int}, Ï„exclude::Int)
    [j for (Ï„, j) in zip(Ï„s, js) if abs(Ï„) != abs.(Ï„exclude)]
end

export pa_candidate_variables

function get_delay_Ï„s(source, target; maxlag::Union{Int, Float64} = 0.05)
# Ensure all time series are of the same length.
    Ls = [length.(source); length.(target)]
    @assert all(Ls .== maximum(Ls))

    if maxlag isa Int
        delay_Ï„s = 1:maxlag
    else
        delay_Ï„s = 1:ceil(Int, maximum(Ls)*maxlag)
    end
    return delay_Ï„s
end

function get_delay_Ï„s(source, target, cond; maxlag::Union{Int, Float64} = 0.05)
    # Ensure all time series are of the same length.
        Ls = [length.(source); length.(target); length.(cond)]
        @assert all(Ls .== maximum(Ls))
    
        if maxlag isa Int
            delay_Ï„s = 1:maxlag
        else
            delay_Ï„s = 1:ceil(Int, maximum(Ls)*maxlag)
        end
        return delay_Ï„s
    end

"""
    pa_candidate_variables(
        source::Vector{AbstractVector}, 
        target::Vector{AbstractVector}, 
        [cond::Vector{AbstractVector}];
        k::Int = 1, include_instantaneous = true,
        Ï„exclude::Union{Int, Nothing} = nothing,
        maxlag::Union{Int, Float64} = 0.05
    ) â†’ ([Ï„s_source, Ï„s_target, Ï„s_cond, ks_Tâº, ks_Tâ»], [js_source, js_target, js_cond, js_Tâº, js_Tâ»])

Construct candidate variables from input time series. `source` is a vector of equal-length time series
assumed to represent the putative source process. `target` and `cond` are the same, but contains time series
of the target process and of the conditional processes, respectively. `k` is the desired prediction lag. 

If `include_instantaneous == true`, then the analysis will also consider instantaneous interactions between
the variables.

If `maxlag` is an integer, `maxlag` is taken as the maximum allowed embedding lag. If `maxlag` is a float, 
then the maximum embedding lag is taken as `maximum([length.(source); length.(target); length.(cond)])*maxlag`.
`Ï„min` is the minimum amount of variables to include in the candidate set (that is, each variable is embedded 
with lags `startlag:-1:-Ï„min`).
"""
function pa_candidate_variables(source, target, cond;
        k::Int = 1,
        include_instantaneous = true,
        method_delay = "ac_min",
        Ï„min::Int = 2,
        maxlag::Union{Int, Float64} = 0.05)
    
    @assert Ï„min > 0

    # Find the maximum allowed embedding lag for each of the candidates.
    # We need at least two variables to allow exlusion of the `Î·`-lag, 
    # so make sure we don't get only one variable from the delay method.
    delay_Ï„s = get_delay_Ï„s(source, target, cond)
    Ï„smax_source = [max(estimate_delay(s, method_delay, delay_Ï„s), Ï„min) for s in source]
    Ï„smax_target = [max(estimate_delay(t, method_delay, delay_Ï„s), Ï„min) for t in target]
    Ï„smax_cond = [max(estimate_delay(c, method_delay, delay_Ï„s), Ï„min) for c in cond]

    # Generate candidate set
    startlag = include_instantaneous ? 0 : -1

    Ï„s_source = [[startlag:-1:-Ï„...,] for Ï„ in Ï„smax_source]
    Ï„s_target = [[startlag:-1:-Ï„...,] for Ï„ in Ï„smax_target]
    Ï„s_cond = [[startlag:-1:-Ï„...,] for Ï„ in Ï„smax_cond]
    
    ks_Tâº = [k for i in 1:length(target)]
    ks_Tâ» = [-k for i in 1:length(target)]
    js_Tâº = [i for i in length(Ï„s_source)+1:length(Ï„s_source)+length(Ï„s_target)]
    js_Tâ» = [i for i in length(Ï„s_source)+1:length(Ï„s_source)+length(Ï„s_target)]

    Ï„s_Î© = [Ï„s_source..., Ï„s_target..., Ï„s_cond...]
    js_Î© = [[i for x in 1:length(Ï„s[i])] for i = 1:length(Ï„s)]

    # Variable filtering, if desired
    Ï„s_Î© = [filtered_Ï„s(Ï„sáµ¢, jsáµ¢, k) for (Ï„sáµ¢, jsáµ¢) in zip(Ï„s, js)]
    js_Î© = [filtered_js(Ï„sáµ¢, jsáµ¢, k) for (Ï„sáµ¢, jsáµ¢) in zip(Ï„s, js)]

    return [Ï„s...,], [js...,], ks_Tâº, ks_Tâ», js_Tâº, js_Tâ»
end

function pa_candidate_variables(source, target; 
        k::Int = 1, 
        include_instantaneous = true,
        method_delay = "ac_min",
        Ï„min::Int = 2,
        maxlag::Union{Int, Float64} = 0.05)
    
    # Find the maximum allowed embedding lag for each of the candidates.
    # We need at least two variables to allow exlusion of the `Î·`-lag, 
    # so make sure we don't get only one variable from the delay method.
    delay_Ï„s = get_delay_Ï„s(source, target, maxlag = maxlag)
    Ï„smax_source = [max(estimate_delay(s, method_delay, delay_Ï„s), Ï„min) for s in source]
    Ï„smax_target = [max(estimate_delay(t, method_delay, delay_Ï„s), Ï„min) for t in target]

    # Generate candidate set
    startlag = include_instantaneous ? 0 : -1
    Ï„s_source = [[startlag:-1:-Ï„...,] for Ï„ in Ï„smax_source]
    Ï„s_target = [[startlag:-1:-Ï„...,] for Ï„ in Ï„smax_target]
    
    ks_Tâº = [k for i in 1:length(target)] 
    ks_Tâ» = [-k for i in 1:length(target)]
    js_Tâº = [i for i in length(Ï„s_source)+1:length(Ï„s_source)+length(Ï„s_target)]
    js_Tâ» = [i for i in length(Ï„s_source)+1:length(Ï„s_source)+length(Ï„s_target)]

    Ï„s = [Ï„s_source..., Ï„s_target...,]
    js = [[i for x in 1:length(Ï„s[i])] for i = 1:length(Ï„s)]

    # Variable filtering, if desired
    Ï„s = [filtered_Ï„s(Ï„sáµ¢, jsáµ¢, k) for (Ï„sáµ¢, jsáµ¢) in zip(Ï„s, js)]
    js = [filtered_js(Ï„sáµ¢, jsáµ¢, k) for (Ï„sáµ¢, jsáµ¢) in zip(Ï„s, js)]
    
    return [Ï„s...,], [js...,], ks_Tâº, ks_Tâ», js_Tâº, js_Tâ»
end

function pa_embed_variables(source, target; 
        Î·::Int = 1, 
        include_instantaneous = true,
        method_delay = "mi_min",
        maxlag::Union{Int, Float64} = 0.05)
    
    Ï„s, js, ks_Tâº, ks_Tâ», js_Tâº, js_Tâ» = pa_candidate_variables(source, target, k = Î·)
    
    # TODO: This is more efficient if not using datasets. Re-do manually.
    data = Dataset([source..., target...,]...,)
    â„° = genembed(data, ((Ï„s...)...,), ((js...)...,))
    
    n_candidates = sum(length.(Ï„s[1:end-2])) # the last two are target future and past
    n_Tâº = length(Ï„s[end-1]) 
    n_Tâ» = length(Ï„s[end])

    nvars_total = length(((Ï„s...)...,))

    # Separate time series for candidate variables (Î©), target future (Tâº), and target past (Tâ»)
    idxs_candidates = 1:n_candidates
    idxs_target_future = n_candidates+1:nvars_total-n_Tâ»
    idxs_target_past = nvars_total-n_Tâ»+1:nvars_total
    Î© = [â„°[:, i] for i = idxs_candidates]
    Tâº = â„°[:, idxs_target_future]
    Tâ» = â„°[:, idxs_target_past]

    # @show Ï„s
    # @show ((Ï„s...)...,)
    # @show ((js...)...,)
    # @show n_candidates
    # @show idxs_candidates
    # @show idxs_target_future
    # @show idxs_target_past

    idxs_source = 1:length(source)
    idxs_target = length(source)+1:length(source)+length(target)
    idxs_cond = Int[]

    return Î©, Tâº, Tâ», Ï„s, js, idxs_source, idxs_target, idxs_cond
end

"""
    minimize_conditional_entropy(Tâº, ğ’®, Î©) â†’ idx

Minimize conditional entropy (CE) between the future of the target variable `Tâº`,
and (`ğ’®`, Î©áµ¢), where `Î©áµ¢ âˆˆ Î©` is the i-th remaining candidate variable.

Returns `i` such that `Î©[i]` is the variable that minimizes CE when combined with 
`ğ’®`.
"""
function minimize_conditional_entropy(Tâº, ğ’®, Î©)
    n_remaining_candidates = length(Î©)
    ces = zeros(n_remaining_candidates)

    for i = 1:n_remaining_candidates
        if k == 1 || length(ğ’®) == 0
            Cáµ¢ = Î©[i]
            CMI_Tâº_Cáµ¢ = 
                genentropy(Dataset(Tâº, Dataset(Cáµ¢)), est, q = q, base = base) - 
                genentropy(Dataset(Cáµ¢), est, q = q, base = base)
        else
            Cáµ¢ = [Î©[i], ğ’®...]
            CMI_Tâº_Cáµ¢ = 
                genentropy(Dataset(Tâº, Dataset(Cáµ¢...,)), est, q = q, base = base) - 
                genentropy(Dataset(Cáµ¢...,), est, q = q, base = base)
        end
        CMIs_between_Tâº_and_candidates[i] = CMI_Tâº_Cáµ¢
    end

    return idx = findfirst(x -> x == minimum(ces), ces)
end



function optim_pa(Î©, Tâº, Ï„s, js, idxs_source, idxs_target, idxs_cond, est; 
        uq = 0.95, nsurr = 100, q = 1, base = 2)
    
    Ï„s_comb = [(Ï„s...)...,]
    js_comb = [(js...)...,]
    
    npts = length(Tâº)
    n_candidate_variables = length(Î©)
    
    ğ’® = Vector{Vector{Float64}}(undef, 0)
    ğ’®_Ï„s = Vector{Int}(undef, 0)
    ğ’®_js = Vector{Int}(undef, 0)
    
    k = 1
    while k <= n_candidate_variables
        # Find optimal variable for this `k`        
        idx = minimize_conditional_entropy(Tâº, ğ’®, Î©)
        Câ‚– = Î©[idx]; sâ‚– = surrogenerator(Câ‚–, CircShift(collect(1:npts - 1)))

        # Test significance of this candidate by using a random permutation test
        pa_surr = zeros(nsurr)
    
        if k == 1
            cmiâ‚– = CMIs_between_Tâº_and_candidates[idx]

            for i = 1:nsurr
                surr_Câ‚– = sâ‚–() # Surrogate version of Câ‚–
                CMI_permutations[i] = mutualinfo(Tâº, surr_Câ‚–, est)
            end
        else
            # Precompute terms that do not change during surrogate loop
            H_Tâº_ğ’® = genentropy(Dataset(Tâº, Dataset(ğ’®...,)), est, q = q, base = base)
            
            # ORIGIANL TE
            H_ğ’® = genentropy(Dataset(ğ’®...), est, q = q, base = base)
            cmiâ‚– = H_Tâº_ğ’® + 
                    genentropy(Dataset([Câ‚–, ğ’®...,]...,), est, q = q, base = base) - 
                    genentropy(Dataset(Tâº, Dataset([Câ‚–, ğ’®...,]...,)), est, q = q, base = base) - 
                    H_ğ’®

            for i = 1:nsurr
                surr_Câ‚– = s() # Surrogate version of Câ‚–
                CMI_permutations[i] = H_Tâº_ğ’® + 
                    genentropy(Dataset([surr_Câ‚–, ğ’®...]...,), est, q = q, base = base) - 
                    genentropy(Dataset(Tâº, Dataset([surr_Câ‚–, ğ’®...]...,)), est, q = q, base = base) - 
                    H_ğ’®
            end
            
        end
       # If the candidate passes the significance test
        if cmiâ‚– > quantile(CMI_permutations, uq)
            # Add the candidate to list of selected candidates
            push!(ğ’®, Câ‚–)
            push!(ğ’®_Ï„s, Ï„s_comb[idx])
            push!(ğ’®_js, js_comb[idx])
            
            # Delete the candidate from the list of remaining candidates
            deleteat!(Î©, idx)
            deleteat!(Ï„s_comb, idx)
            deleteat!(js_comb, idx)

            k = k + 1
        else 
            k = n_candidate_variables + 1
        end
    end
    
    
    # No variables were selected
    if length(ğ’®) == 0
        return 0.0, Int[], Int[], idxs_source, idxs_target, idxs_cond
    end
    
    # No variables were selected from the source process
    n_source_vars_picked = count(x -> x âˆˆ idxs_source, ğ’®_js)
    if n_source_vars_picked == 0
        return 0.0, Int[], Int[], idxs_source, idxs_target, idxs_cond
    end
    
    # No variables were selected from the target or conditional processes.
    ğ’®_nonX = [ts for (ts, j) in zip(ğ’®, ğ’®_js) if j âˆ‰ idxs_source]
    if length(ğ’®_nonX) == 0
        return 0.0, Int[], Int[], idxs_source, idxs_target, idxs_cond
    end
        
    CE2 = genentropy(Dataset(Tâº, Dataset(ğ’®...,)), est, base = base, q = q) - 
        genentropy(Dataset(ğ’®...,), est, base = base, q = q)
    
    CE1 = genentropy(Dataset(Tâº, Dataset(ğ’®_nonX...,)), est, base = base, q = q) - 
        genentropy(Dataset(ğ’®_nonX...,), est, base = base, q = q)
    
    CMI = CE1 - CE2
    return CMI, ğ’®_js, ğ’®_Ï„s, idxs_source, idxs_target, idxs_cond
    
end

# TODO: verify selection in separate method?