<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>References · Associations.jl</title><meta name="title" content="References · Associations.jl"/><meta property="og:title" content="References · Associations.jl"/><meta property="twitter:title" content="References · Associations.jl"/><meta name="description" content="Documentation for Associations.jl."/><meta property="og:description" content="Documentation for Associations.jl."/><meta property="twitter:description" content="Documentation for Associations.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="https://fonts.googleapis.com/css?family=Montserrat|Source+Code+Pro&amp;display=swap" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">Associations.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Associations.jl</a></li><li><span class="tocitem">Core API reference</span><ul><li><a class="tocitem" href="../associations/">Association measures</a></li><li><a class="tocitem" href="../independence/">Independence</a></li><li><a class="tocitem" href="../causal_graphs/">Network/graph inference</a></li></ul></li><li><span class="tocitem">Extended API reference</span><ul><li><a class="tocitem" href="../api/discretization_counts_probs_api/">Discretization API</a></li><li><a class="tocitem" href="../api/counts_and_probabilities_api/">Multivariate counts and probabilities API</a></li><li><a class="tocitem" href="../api/information_single_variable_api/">Single-variable information API</a></li><li><a class="tocitem" href="../api/information_multivariate_api/">Multivariate information API</a></li><li><a class="tocitem" href="../api/cross_map_api/">Cross-map API</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../examples/examples_associations/">Associations</a></li><li><a class="tocitem" href="../examples/examples_independence/">Independence testing</a></li><li><a class="tocitem" href="../examples/examples_infer_graphs/">Causal graph inference</a></li></ul></li><li class="is-active"><a class="tocitem" href>References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>References</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>References</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaDynamics/Associations.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaDynamics/Associations.jl/blob/main/docs/src/references.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h1><div class="citation canonical"><ul><li><div id="Abe2001">Abe, S. and Rajagopal, A. K. (2001). <a href="https://doi.org/10.1016/S0378-4371(00)00476-3"><em>Nonadditive conditional entropy and its significance for local realism</em></a>. <a href="https://doi.org/10.1016/S0378-4371(00)00476-3">Physica A: Statistical Mechanics and its Applications <strong>289</strong>, 157–164</a>.</div></li><li><div id="Alizadeh2010">Alizadeh, N. H. and Arghami, N. R. (2010). <a href="http://jirss.irstat.ir/article-1-81-en.pdf"><em>A new estimator of entropy</em></a>. Journal of the Iranian Statistical Society (JIRSS).</div></li><li><div id="Amigo2018">Amigó, J. M. and Hirata, Y. (2018). <a href="https://doi.org/10.1063/1.5010779"><em>Detecting directional couplings from multivariate flows by the joint distance distribution.</em></a> <a href="https://doi.org/10.1063/1.5010779">Chaos <strong>28</strong>, 075302</a>.</div></li><li><div id="Andrzejak2003">Andrzejak, R. G.; Kraskov, A.; Stögbauer, H.; Mormann, F. and Kreuz, T. (2003). <a href="https://doi.org/10.1103/PHYSREVE.68.066202"><em>Bivariate surrogate techniques: necessity, strengths, and caveats</em></a>. <a href="https://doi.org/10.1103/PHYSREVE.68.066202">Physical review E <strong>68</strong>, 066202</a>.</div></li><li><div id="Arnhold1999">Arnhold, J.; Grassberger, P.; Lehnertz, K. and Elger, C. E. (1999). <em>A robust method for detecting interdependences: application to intracranially recorded EEG</em>. Physica D: Nonlinear Phenomena <strong>134</strong>, 419–430.</div></li><li><div id="Arora2022">Arora, A.; Meister, C. and Cotterell, R. (2022). <a href="https://arxiv.org/abs/2204.01469"><em>Estimating the Entropy of Linguistic Distributions</em></a>, arXiv, <a href="https://arxiv.org/abs/2204.01469">arXiv:2204.01469 [cs.CL]</a>.</div></li><li><div id="Azami2016">Azami, H. and Escudero, J. (2016). <a href="https://www.sciencedirect.com/science/article/pii/S0169260715301152"><em>Amplitude-aware permutation entropy: Illustration in spike detection and signal segmentation</em></a>. <a href="https://doi.org/10.1016/j.cmpb.2016.02.008">Computer Methods and Programs in Biomedicine <strong>128</strong>, 40–51</a>.</div></li><li><div id="BandtPompe2002">Bandt, C. and Pompe, B. (2002). <a href="https://link.aps.org/doi/10.1103/PhysRevLett.88.174102"><em>Permutation Entropy: A Natural Complexity Measure for Time Series</em></a>. <a href="https://doi.org/10.1103/PhysRevLett.88.174102">Phys. Rev. Lett. <strong>88</strong>, 174102</a>.</div></li><li><div id="Berger2019">Berger, S.; Kravtsiv, A.; Schneider, G. and Jordan, D. (2019). <a href="https://www.mdpi.com/1099-4300/21/10/1023"><em>Teaching Ordinal Patterns to a Computer: Efficient Encoding Algorithms Based on the Lehmer Code</em></a>. <a href="https://doi.org/10.3390/e21101023">Entropy <strong>21</strong></a>.</div></li><li><div id="Chao2003">Chao, A. and Shen, T.-J. (2003). <a href="https://doi.org/10.1023/A:1026096204727"><em>Nonparametric estimation of Shannon&#39;s index of diversity when there are unseen species in sample</em></a>. <a href="https://doi.org/10.1023/A:1026096204727">Environmental and Ecological Statistics <strong>10</strong>, 429–443</a>.</div></li><li><div id="Charzyńska2015">Charzyńska, A. and Gambin, A. (2016). <a href="https://www.mdpi.com/1099-4300/18/1/13"><em>Improvement of the k-nn Entropy Estimator with Applications in Systems Biology</em></a>. <a href="https://doi.org/10.3390/e18010013">Entropy <strong>18</strong></a>.</div></li><li><div id="Chatterjee2021">Chatterjee, S. (2021). <em>A new coefficient of correlation</em>. Journal of the American Statistical Association <strong>116</strong>, 2009–2022.</div></li><li><div id="Chicharro2009">Chicharro, D. and Andrzejak, R. G. (2009). <a href="https://doi.org/10.1103/PHYSREVE.80.026217"><em>Reliable detection of directional couplings using rank statistics</em></a>. <a href="https://doi.org/10.1103/PHYSREVE.80.026217">Physical Review E <strong>80</strong>, 026217</a>.</div></li><li><div id="Correa1995">Correa, J. C. (1995). <a href="https://doi.org/10.1080/03610929508831626"><em>A new estimator of entropy</em></a>. <a href="https://doi.org/10.1080/03610929508831626">Communications in Statistics - Theory and Methods <strong>24</strong>, 2439–2449</a>, <a href="https://arxiv.org/abs/https://doi.org/10.1080/03610929508831626">arXiv:https://doi.org/10.1080/03610929508831626</a>.</div></li><li><div id="CoverThomas1999">Cover, T. M. (1999). <em>Elements of information theory</em> (John Wiley &amp; Sons).</div></li><li><div id="Datseris2024">Datseris, G. and Haaga, K. A. (2024). <em>ComplexityMeasures. jl: scalable software to unify and accelerate entropy and complexity timeseries analysis</em>, arXiv preprint arXiv:2406.05011.</div></li><li><div id="Dette2013">Dette, H.; Siburg, K. F. and Stoimenov, P. A. (2013). <em>A Copula-Based Non-parametric Measure of Regression Dependence</em>. Scandinavian Journal of Statistics <strong>40</strong>, 21–41.</div></li><li><div id="Ebrahimi1994">Ebrahimi, N.; Pflughoeft, K. and Soofi, E. S. (1994). <a href="https://www.sciencedirect.com/science/article/pii/0167715294900469"><em>Two measures of sample entropy</em></a>. <a href="https://doi.org/10.1016/0167-7152(94)90046-9">Statistics &amp; Probability Letters <strong>20</strong>, 225–234</a>.</div></li><li><div id="vanErven2014">van Erven, T. and Harremos, P. (2014). <em>Rényi Divergence and Kullback-Leibler Divergence</em>. <a href="https://doi.org/10.1109/TIT.2014.2320500">IEEE Transactions on Information Theory <strong>60</strong>, 3797–3820</a>.</div></li><li><div id="Frenzel2007">Frenzel, S. and Pompe, B. (2007). <a href="https://link.aps.org/doi/10.1103/PhysRevLett.99.204101"><em>Partial Mutual Information for Coupling Analysis of Multivariate Time Series</em></a>. <a href="https://doi.org/10.1103/PhysRevLett.99.204101">Phys. Rev. Lett. <strong>99</strong>, 204101</a>.</div></li><li><div id="Furuichi2006">Furuichi, S. (2006). <a href="https://doi.org/10.1063/1.2165744"><em>Information theoretical properties of Tsallis entropies</em></a>. <a href="https://doi.org/10.1063/1.2165744">Journal of Mathematical Physics <strong>47</strong></a>.</div></li><li><div id="Gao2015">Gao, S.; Ver Steeg, G. and Galstyan, A. (09–12 May 2015). <a href="https://proceedings.mlr.press/v38/gao15.html"><em>Efficient Estimation of Mutual Information for Strongly Dependent Variables</em></a>. In: <em>Proceedings of the Eighteenth International Conference on Artificial Intelligence and Statistics</em>, Vol. 38 of <em>Proceedings of Machine Learning Research</em>, edited by Lebanon, G. and Vishwanathan, S. V. (PMLR, San Diego, California, USA); pp. 277–286.</div></li><li><div id="GaoKannanOhViswanath2017">Gao, W.; Kannan, S.; Oh, S. and Viswanath, P. (2017). <a href="https://proceedings.neurips.cc/paper_files/paper/2017/file/ef72d53990bc4805684c9b61fa64a102-Paper.pdf"><em>Estimating Mutual Information for Discrete-Continuous Mixtures</em></a>. In: <em>Advances in Neural Information Processing Systems</em>, Vol. 30, edited by Guyon, I.; Luxburg, U. V.; Bengio, S.; Wallach, H.; Fergus, R.; Vishwanathan, S. and Garnett, R. (Curran Associates, Inc.).</div></li><li><div id="Gao2018">Gao, W.; Oh, S. and Viswanath, P. (2018). <a href="https://doi.org/10.1109/TIT.2018.2807481"><em>Demystifying Fixed  <span>$k$</span> -Nearest Neighbor Information Estimators</em></a>. <a href="https://doi.org/10.1109/TIT.2018.2807481">IEEE Transactions on Information Theory <strong>64</strong>, 5629–5661</a>.</div></li><li><div id="Golshani2009">Golshani, L.; Pasha, E. and Yari, G. (2009). <em>Some properties of Rényi entropy and Rényi entropy rate</em>. Information Sciences <strong>179</strong>, 2426–2433.</div></li><li><div id="Goria2005">Goria, M. N.; Leonenko, N. N.; Mergel, V. V. and Inverardi, P. L. (2005). <a href="https://doi.org/10.1080/104852504200026815"><em>A new class of random vector entropy estimators and its applications in testing statistical hypotheses</em></a>. <a href="https://doi.org/10.1080/104852504200026815">Journal of Nonparametric Statistics <strong>17</strong>, 277–297</a>, <a href="https://arxiv.org/abs/https://doi.org/10.1080/104852504200026815">arXiv:https://doi.org/10.1080/104852504200026815</a>.</div></li><li><div id="Grassberger2022">Grassberger, P. (2022). <a href="https://www.mdpi.com/1099-4300/24/5/680"><em>On Generalized Schuermann Entropy Estimators</em></a>. <a href="https://doi.org/10.3390/e24050680">Entropy <strong>24</strong></a>.</div></li><li><div id="He2016">He, S.; Sun, K. and Wang, H. (2016). <a href="https://www.sciencedirect.com/science/article/pii/S0378437116302801"><em>Multivariate permutation entropy and its application for complexity analysis of chaotic systems</em></a>. <a href="https://doi.org/10.1016/j.physa.2016.06.012">Physica A: Statistical Mechanics and its Applications <strong>461</strong>, 812–823</a>.</div></li><li><div id="Horvitz1952">Horvitz, D. G. and Thompson, D. J. (1952). <a href="https://www.tandfonline.com/doi/abs/10.1080/01621459.1952.10483446"><em>A Generalization of Sampling Without Replacement from a Finite Universe</em></a>. <a href="https://doi.org/10.1080/01621459.1952.10483446">Journal of the American Statistical Association <strong>47</strong>, 663–685</a>, <a href="https://arxiv.org/abs/https://www.tandfonline.com/doi/pdf/10.1080/01621459.1952.10483446">arXiv:https://www.tandfonline.com/doi/pdf/10.1080/01621459.1952.10483446</a>.</div></li><li><div id="Jizba2012">Jizba, P.; Kleinert, H. and Shefaat, M. (2012). <a href="https://doi.org/10.3390/engproc2021005033"><em>Rényi&#39;s information transfer between financial time series</em></a>. <a href="https://doi.org/10.3390/engproc2021005033">Physica A: Statistical Mechanics and its Applications <strong>391</strong>, 2971–2989</a>.</div></li><li><div id="Kalisch2008">Kalisch, M. and Bühlmann, P. (2008). <a href="https://doi.org/10.1198/106186008X381927"><em>Robustification of the PC-Algorithm for Directed Acyclic Graphs</em></a>. <a href="https://doi.org/10.1198/106186008X381927">Journal of Computational and Graphical Statistics <strong>17</strong>, 773–789</a>, <a href="https://arxiv.org/abs/https://doi.org/10.1198/106186008X381927">arXiv:https://doi.org/10.1198/106186008X381927</a>.</div></li><li><div id="KozachenkoLeonenko1987">Kozachenko, L. F. and Leonenko, N. N. (1987). <a href="https://www.mathnet.ru/php/archive.phtml?wshow=paper&amp;jrnid=ppi&amp;paperid=797&amp;option_lang=eng"><em>Sample estimate of the entropy of a random vector</em></a>. Problemy Peredachi Informatsii <strong>23</strong>, 9–16.</div></li><li><div id="Kraskov2004">Kraskov, A.; Stögbauer, H. and Grassberger, P. (2004). <a href="https://link.aps.org/doi/10.1103/PhysRevE.69.066138"><em>Estimating mutual information</em></a>. <a href="https://doi.org/10.1103/PhysRevE.69.066138">Phys. Rev. E <strong>69</strong>, 066138</a>.</div></li><li><div id="LeonenkoProzantoSavani2008">Leonenko, N.; Pronzato, L. and Savani, V. (2008). <a href="https://doi.org/10.1214/07-AOS539"><em>A class of Rényi information estimators for multidimensional densities</em></a>. <a href="https://doi.org/10.1214/07-AOS539">The Annals of Statistics <strong>36</strong>, 2153–2182</a>.</div></li><li><div id="Levy1978">Levy, K. J. and Narula, S. C. (1978). <a href="https://doi.org/10.2307/1402814"><em>Testing hypotheses concerning partial correlations: Some methods and discussion</em></a>. <a href="https://doi.org/10.2307/1402814">International Statistical Review/Revue Internationale de Statistique, 215–218</a>.</div></li><li><div id="Li2018">Li, G.; Guan, Q. and Yang, H. (2019). <a href="https://www.mdpi.com/1099-4300/21/1/11"><em>Noise Reduction Method of Underwater Acoustic Signals Based on CEEMDAN, Effort-To-Compress Complexity, Refined Composite Multiscale Dispersion Entropy and Wavelet Threshold Denoising</em></a>. <a href="https://doi.org/10.3390/e21010011">Entropy <strong>21</strong></a>.</div></li><li><div id="Lindner2011">Lindner, M.; Vicente, R.; Priesemann, V. and Wibral, M. (2011). <a href="https://api.semanticscholar.org/CorpusID:6250448"><em>TRENTOOL: A Matlab open source toolbox to analyse information flow in time series data with transfer entropy</em></a>. BMC Neuroscience <strong>12</strong>, 119–119.</div></li><li><div id="Lord2018">Lord, W. M.; Sun, J. and Bollt, E. M. (2018). <a href="https://pubs.aip.org/aip/cha/article/28/3/033114/685022"><em>Geometric k-nearest neighbor estimation of entropy and mutual information</em></a>. <a href="https://doi.org/10.1063/1.5011683">Chaos: An Interdisciplinary Journal of Nonlinear Science <strong>28</strong></a>.</div></li><li><div id="Luo2015">Luo, M.; Kantz, H.; Lau, N.-C.; Huang, W. and Zhou, Y. (2015). <a href="https://doi.org/10.1073/pnas.1510571112"><em>Questionable dynamical evidence for causality between galactic cosmic rays and interannual variation in global temperature</em></a>. <a href="https://doi.org/10.1073/pnas.1510571112">Proceedings of the National Academy of Sciences <strong>112</strong>, E4638 - E4639</a>.</div></li><li><div id="Manis2017">Manis, G.; Aktaruzzaman, M. and Sassi, R. (2017). <em>Bubble entropy: An entropy almost free of parameters</em>. IEEE Transactions on Biomedical Engineering <strong>64</strong>, 2711–2718.</div></li><li><div id="Martin2004">Martin, S.; Morison, G.; Nailon, W. H. and Durrani, T. S. (2004). <a href="https://doi.org/10.1049/EL:20040375"><em>Fast and accurate image registration using Tsallis entropy and simultaneous perturbation stochastic approximation</em></a>. <a href="https://doi.org/10.1049/EL:20040375">Electronics Letters <strong>40</strong>, 595–597</a>.</div></li><li><div id="McCracken2014">McCracken, J. M. and Weigel, R. S. (2014). <a href="https://doi.org/10.1103/PhysRevE.90.062903"><em>Convergent cross-mapping and pairwise asymmetric inference</em></a>. <a href="https://doi.org/10.1103/PhysRevE.90.062903">Physical Review E <strong>90</strong>, 062903</a>.</div></li><li><div id="Mesner2020">Mesner, O. C. and Shalizi, C. R. (2020). <a href="https://doi.org/10.1109/TIT.2020.3024886"><em>Conditional mutual information estimation for mixed, discrete and continuous data</em></a>. <a href="https://doi.org/10.1109/TIT.2020.3024886">IEEE Transactions on Information Theory <strong>67</strong>, 464–484</a>.</div></li><li><div id="Miller1955">Miller, G. (1955). <em>Note on the bias of information estimates</em>. Information theory in psychology: Problems and methods.</div></li><li><div id="Palus2014">Paluš, M. (2014). <a href="https://www.mdpi.com/1099-4300/16/10/5263"><em>Cross-Scale Interactions and Information Transfer</em></a>. <a href="https://doi.org/10.3390/e16105263">Entropy <strong>16</strong>, 5263–5289</a>.</div></li><li><div id="Paninski2003">Paninski, L. (2003). <a href="https://ieeexplore.ieee.org/abstract/document/6790247"><em>Estimation of entropy and mutual information</em></a>. <a href="https://doi.org/10.1162/089976603321780272">Neural computation <strong>15</strong>, 1191–1253</a>.</div></li><li><div id="Papapetrou2020">Papapetrou, M. and Kugiumtzis, D. (2020). <em>Tsallis conditional mutual information in investigating long range correlation in symbol sequences</em>. Physica A: Statistical Mechanics and its Applications <strong>540</strong>, 123016.</div></li><li><div id="Poczos2012">Póczos, B. and Schneider, J. (2012). <em>Nonparametric estimation of conditional information and divergences</em>. In: <em>Artificial Intelligence and Statistics</em> (PMLR); pp. 914–923.</div></li><li><div id="Quiroga2000">Quiroga, R. Q.; Arnhold, J. and Grassberger, P. (2000). <a href="https://doi.org/10.1103/PhysRevE.61.5142"><em>Learning driver-response relationships from synchronization patterns</em></a>. <a href="https://doi.org/10.1103/PhysRevE.61.5142">Physical Review E <strong>61</strong>, 5142</a>.</div></li><li><div id="Rahimzamani2018">Rahimzamani, A.; Asnani, H.; Viswanath, P. and Kannan, S. (2018). <a href="https://proceedings.neurips.cc/paper_files/paper/2010/file/577ef1154f3240ad5b9b413aa7346a1e-Paper.pdf"><em>Estimators for multivariate information measures in general probability spaces</em></a>. Advances in Neural Information Processing Systems <strong>31</strong>.</div></li><li><div id="Ramos2017">Ramos, A. M.; Builes-Jaramillo, A.; Poveda, G.; Goswami, B.; Macau, E. E.; Kurths, J. and Marwan, N. (2017). <a href="https://link.aps.org/doi/10.1103/PhysRevE.95.052206"><em>Recurrence measure of conditional dependence and applications</em></a>. <a href="https://doi.org/10.1103/PhysRevE.95.052206">Phys. Rev. E <strong>95</strong>, 052206</a>.</div></li><li><div id="Romano2007">Romano, M. C.; Thiel, M.; Kurths, J. and Grebogi, C. (2007). <a href="https://link.aps.org/doi/10.1103/PhysRevE.76.036211"><em>Estimation of the direction of the coupling by conditional probabilities of recurrence</em></a>. <a href="https://doi.org/10.1103/PhysRevE.76.036211">Phys. Rev. E <strong>76</strong>, 036211</a>.</div></li><li><div id="Rostaghi2016">Rostaghi, M. and Azami, H. (2016). <a href="https://doi.org/10.1109/LSP.2016.2542881"><em>Dispersion entropy: A measure for time-series analysis</em></a>. <a href="https://doi.org/10.1109/LSP.2016.2542881">IEEE Signal Processing Letters <strong>23</strong>, 610–614</a>.</div></li><li><div id="Runge2018LocalPerm">Runge, J. (09–11 Apr 2018). <a href="https://proceedings.mlr.press/v84/runge18a.html"><em>Conditional independence testing based on a nearest-neighbor estimator of conditional mutual information</em></a>. In: <em>Proceedings of the Twenty-First International Conference on Artificial Intelligence and Statistics</em>, Vol. 84 of <em>Proceedings of Machine Learning Research</em>, edited by Storkey, A. and Perez-Cruz, F. (PMLR); pp. 938–947.</div></li><li><div id="Rényi1961">Rényi, A. (1961). <a href="https://projecteuclid.org/ebook/Download?urlid=bsmsp/1200512181&amp;isFullBook=false"><em>On measures of entropy and information</em></a>. In: <em>Proceedings of the Fourth Berkeley Symposium on Mathematical Statistics and Probability, Volume 1: Contributions to the Theory of Statistics</em>, Vol. 4 (University of California Press); pp. 547–562.</div></li><li><div id="Sarbu2014">Sarbu, S. (2014). <a href="https://doi.org/10.1109/ICASSP.2014.6854688"><em>Rényi information transfer: Partial Rényi transfer entropy and partial Rényi mutual information</em></a>. In: <a href="https://doi.org/10.1109/ICASSP.2014.6854688"><em>2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em></a> (IEEE); pp. 5666–5670.</div></li><li><div id="Schmidt2018">Schmidt, C.; Huegle, J. and Uflacker, M. (2018). <a href="https://doi.org/10.1145/3221269.3221292"><em>Order-independent constraint-based causal structure learning for gaussian distribution models using GPUs</em></a>. In: <a href="https://doi.org/10.1145/3221269.3221292"><em>Proceedings of the 30th International Conference on Scientific and Statistical Database Management</em></a>; pp. 1–10.</div></li><li><div id="Schreiber2000">Schreiber, T. (2000). <a href="https://doi.org/10.1103/PhysRevLett.85.461"><em>Measuring information transfer</em></a>. <a href="https://doi.org/10.1103/PhysRevLett.85.461">Physical review letters <strong>85</strong>, 461</a>.</div></li><li><div id="Schurmann2004">Schuermann, T. (2004). <a href="https://doi.org/10.1088/0305-4470/37/27/L02"><em>Bias analysis in entropy estimation</em></a>. <a href="https://doi.org/10.1088/0305-4470/37/27/L02">Journal of Physics A: Mathematical and General <strong>37</strong>, L295</a>.</div></li><li><div id="Shannon1948">Shannon, C. E. (1948). <a href="https://doi.org/10.1002/j.1538-7305.1948.tb01338.x"><em>A mathematical theory of communication</em></a>. <a href="https://doi.org/10.1002/j.1538-7305.1948.tb01338.x">The Bell system technical journal <strong>27</strong>, 379–423</a>.</div></li><li><div id="Shi2022">Shi, H.; Drton, M. and Han, F. (2022). <em>On the power of Chatterjee’s rank correlation</em>. Biometrika <strong>109</strong>, 317–333.</div></li><li><div id="Singh2003">Singh, H.; Misra, N.; Hnizdo, V.; Fedorowicz, A. and Demchuk, E. (2003). <a href="https://api.semanticscholar.org/CorpusID:122506029"><em>Nearest Neighbor Estimates of Entropy</em></a>. American Journal of Mathematical and Management Sciences <strong>23</strong>, 301–321.</div></li><li><div id="Spirtes2000">Spirtes, P.; Glymour, C. N. and Scheines, R. (2000). <em>Causation, prediction, and search</em> (MIT press).</div></li><li><div id="Staniek2008">Staniek, M. and Lehnertz, K. (2008). <a href="https://link.aps.org/doi/10.1103/PhysRevLett.100.158101"><em>Symbolic Transfer Entropy</em></a>. <a href="https://doi.org/10.1103/PhysRevLett.100.158101">Phys. Rev. Lett. <strong>100</strong>, 158101</a>.</div></li><li><div id="Sugihara2012">Sugihara, G.; May, R. M.; Ye, H.; Hsieh, C.-h.; Deyle, E. R.; Fogarty, M. and Munch, S. B. (2012). <a href="https://doi.org/10.1126/science.1227079"><em>Detecting Causality in Complex Ecosystems</em></a>. <a href="https://doi.org/10.1126/science.1227079">Science <strong>338</strong>, 496–500</a>.</div></li><li><div id="Sun2015">Sun, J.; Taylor, D. and Bollt, E. M. (2015). <a href="https://doi.org/10.1137/140956166"><em>Causal Network Inference by Optimal Causation Entropy</em></a>. <a href="https://doi.org/10.1137/140956166">SIAM Journal on Applied Dynamical Systems <strong>14</strong>, 73–106</a>, <a href="https://arxiv.org/abs/https://doi.org/10.1137/140956166">arXiv:https://doi.org/10.1137/140956166</a>.</div></li><li><div id="Szekely2014">Székely, G. J. and Rizzo, M. L. (2014). <a href="https://doi.org/10.1214/14-AOS1255"><em>Partial distance correlation with methods for dissimilarities</em></a>. <a href="https://doi.org/10.1214/14-AOS1255">The Annals of Statistics <strong>42</strong>, 2382–2412</a>.</div></li><li><div id="Szekely2007">Székely, G. J.; Rizzo, M. L. and Bakirov, N. K. (2007). <a href="https://doi.org/10.1214/009053607000000505"><em>Measuring and testing dependence by correlation of distances</em></a>. <a href="https://doi.org/10.1214/009053607000000505">The Annals of Statistics <strong>35</strong>, 2769–2794</a>.</div></li><li><div id="Tsallis1988">Tsallis, C. (1988). <a href="https://doi.org/10.1007/BF01016429"><em>Possible generalization of Boltzmann-Gibbs statistics</em></a>. <a href="https://doi.org/10.1007/BF01016429">Journal of statistical physics <strong>52</strong>, 479–487</a>.</div></li><li><div id="Tsallis2009">Tsallis, C. (2009). <a href="https://link.springer.com/book/10.1007/978-0-387-85359-8"><em>Introduction to nonextensive statistical mechanics: approaching a complex world</em></a>. Vol. 1 no. 1 (Springer).</div></li><li><div id="Vasicek1976">Vasicek, O. (1976). <em>A test for normality based on sample entropy</em>. <a href="https://doi.org/10.1111/j.2517-6161.1976.tb01566.x">Journal of the Royal Statistical Society Series B: Statistical Methodology <strong>38</strong>, 54–59</a>.</div></li><li><div id="Vejmelka2008">Vejmelka, M. and Paluš, M. (2008). <a href="https://doi.org/10.1103/PHYSREVE.77.026214"><em>Inferring the directionality of coupling with conditional mutual information</em></a>. <a href="https://doi.org/10.1103/PHYSREVE.77.026214">Physical Review E <strong>77</strong>, 026214</a>.</div></li><li><div id="Wang2020">Wang, X.; Si, S. and Li, Y. (2020). <em>Multiscale diversity entropy: A novel dynamical measure for fault diagnosis of rotating machinery</em>. <a href="https://doi.org/10.1109/TII.2020.3022369">IEEE Transactions on Industrial Informatics <strong>17</strong>, 5419–5429</a>.</div></li><li><div id="Zahl1977">Zahl, S. (1977). <a href="https://doi.org/10.2307/1936227"><em>Jackknifing an index of diversity</em></a>. <a href="https://doi.org/10.2307/1936227">Ecology <strong>58</strong>, 907–913</a>.</div></li><li><div id="Zhao2016">Zhao, J.; Zhou, Y.; Zhang, X. and Chen, L. (2016). <a href="https://www.pnas.org/doi/pdf/10.1073/pnas.1522586113"><em>Part mutual information for quantifying direct associations in networks</em></a>. <a href="https://doi.org/10.1073/pnas.1522586113">Proceedings of the National Academy of Sciences <strong>113</strong>, 5130–5135</a>.</div></li><li><div id="Zhu2015">Zhu, J.; Bellanger, J.-J.; Shu, H. and Le Bouquin Jeannès, R. (2015). <a href="https://www.mdpi.com/1099-4300/17/6/4173"><em>Contribution to Transfer Entropy Estimation via the k-Nearest-Neighbors Approach</em></a>. <a href="https://doi.org/10.3390/e17064173">Entropy <strong>17</strong>, 4173–4201</a>.</div></li><li><div id="Zunino2017">Zunino, L.; Olivares, F.; Scholkmann, F. and Rosso, O. A. (2017). <a href="https://doi.org/10.1016/j.physleta.2017.03.052"><em>Permutation entropy based time series analysis: Equalities in the input signal can lead to false conclusions</em></a>. <a href="https://doi.org/10.1016/j.physleta.2017.03.052">Physics Letters A <strong>381</strong>, 1883–1892</a>.</div></li></ul></div></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../examples/examples_infer_graphs/">« Causal graph inference</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.5.0 on <span class="colophon-date" title="Thursday 1 August 2024 09:15">Thursday 1 August 2024</span>. Using Julia version 1.10.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
