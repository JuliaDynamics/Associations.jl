<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Transfer entropy ¬∑ CausalityTools.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="https://fonts.googleapis.com/css?family=Montserrat|Source+Code+Pro&amp;display=swap" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">CausalityTools.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Overview</a></li><li><a class="tocitem" href="../surrogate/">Surrogate data</a></li><li><span class="tocitem">Distance based</span><ul><li><a class="tocitem" href="../joint_distance_distribution/">Joint distance distribution</a></li><li><a class="tocitem" href="../s_measure/">S-measure</a></li><li><a class="tocitem" href="../cross_mapping/">Cross mapping</a></li><li><a class="tocitem" href="../pairwise_asymmetric_inference/">Pairwise asymmetric inference</a></li></ul></li><li><span class="tocitem">Information/entropy based</span><ul><li><a class="tocitem" href="../mutualinfo/">Mutual information</a></li><li class="is-active"><a class="tocitem" href>Transfer entropy</a><ul class="internal"><li><a class="tocitem" href="#Reproducing-Schreiber"><span>Reproducing Schreiber</span></a></li></ul></li><li><a class="tocitem" href="../predictive_asymmetry/">Predictive asymmetry</a></li><li><a class="tocitem" href="../generalized_entropy/">Generalized entropy</a></li><li><a class="tocitem" href="../info_estimators/">Estimators</a></li></ul></li><li><a class="tocitem" href="../example_systems/">Example systems</a></li><li><span class="tocitem">Utilities</span><ul><li><a class="tocitem" href="../invariant_measure/">Invariant measures and transfer operators</a></li><li><a class="tocitem" href="../dataset/">Multivariate <code>Dataset</code>s</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Information/entropy based</a></li><li class="is-active"><a href>Transfer entropy</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Transfer entropy</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaDynamics/CausalityTools.jl/blob/master/docs/src/TransferEntropy.md" title="Edit on GitHub"><span class="docs-icon fab">ÔÇõ</span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="[Transfer-entropy](@ref-transferentropy)"><a class="docs-heading-anchor" href="#[Transfer-entropy](@ref-transferentropy)"><a href="@ref transferentropy">Transfer entropy</a></a><a id="[Transfer-entropy](@ref-transferentropy)-1"></a><a class="docs-heading-anchor-permalink" href="#[Transfer-entropy](@ref-transferentropy)" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="TransferEntropy.transferentropy" href="#TransferEntropy.transferentropy"><code>TransferEntropy.transferentropy</code></a> ‚Äî <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">transferentropy(s, t, [c,] est; base = 2, q = 1, 
    œÑT = -1, œÑS = -1, Œ∑ùíØ = 1, dT = 1, dS = 1, dùíØ = 1, [œÑC = -1, dC = 1]
)</code></pre><p>Estimate transfer entropy<sup class="footnote-reference"><a id="citeref-Schreiber2000" href="#footnote-Schreiber2000">[Schreiber2000]</a></sup> from source <code>s</code> to target <code>t</code>, <span>$TE^{q}(s \to t)$</span>, using the  provided entropy/probability estimator <code>est</code> with logarithms to the given <code>base</code>. Optionally, condition  on <code>c</code> and estimate the conditional transfer entropy <span>$TE^{q}(s \to t | c)$</span>. The input series <code>s</code>, <code>t</code>, and <code>c</code> must be equal-length real-valued vectors.</p><p>Compute either Shannon transfer entropy (<code>q = 1</code>, which is the default) or the order-<code>q</code>  R√©nyi transfer entropy<sup class="footnote-reference"><a id="citeref-Jizba2012" href="#footnote-Jizba2012">[Jizba2012]</a></sup> by setting <code>q</code> different from 1.</p><p>All possible estimators that can be used are described in the online documentation.</p><p><strong>Keyword Arguments</strong></p><p>Keyword arguments tune the embedding that will be done to each of the timeseries (with more details following below). In short, the embedding lags <code>œÑT</code>, <code>œÑS</code>, <code>œÑC</code> must be zero or negative, the  prediction lag <code>Œ∑ùíØ</code> must be positive, and the embedding dimensions <code>dT</code>, <code>dS</code>, <code>dC</code>, <code>dùíØ</code>  must be greater than or equal to 1. Thus, the convention is to use negative lags to  indicate embedding delays for past state vectors (for the <span>$T$</span>, <span>$S$</span> and <span>$C$</span> marginals,  detailed below), and positive lags to indicate embedding delays for future state vectors  (for the <span>$\mathcal T$</span> marginal, also detailed below). </p><p>The default behaviour is to use scalar timeseries for past state vectors (in that case, the <code>œÑT</code>, <code>œÑS</code> or <code>œÑC</code> does not affect the analysis).</p><p><strong>Description</strong></p><p><strong>Transfer entropy on scalar time series</strong></p><p>Transfer entropy<sup class="footnote-reference"><a id="citeref-Schreiber2000" href="#footnote-Schreiber2000">[Schreiber2000]</a></sup> between two simultaneously measured scalar time series <span>$s(n)$</span> and <span>$t(n)$</span>,   <span>$s(n) = \{ s_1, s_2, \ldots, s_N \}$</span> and <span>$t(n) = \{ t_1, t_2, \ldots, t_N \}$</span>, is is defined as </p><p class="math-container">\[TE(s \to t) = \sum_i p(s_i, t_i, t_{i+\eta}) \log \left( \dfrac{p(t_{i+\eta} |¬†t_i, s_i)}{p(t_{i+\eta} |¬†t_i)} \right)\]</p><p><strong>Transfer entropy on generalized embeddings</strong></p><p>By defining the vector-valued time series, it is possible to include more than one  historical/future value for each marginal (see &#39;Uniform vs. non-uniform embeddings&#39; below for embedding details):</p><ul><li><span>$\mathcal{T}^{(d_{\mathcal T}, \eta_{\mathcal T})} = \{t_i^{(d_{\mathcal T}, \eta_{\mathcal T})} \}_{i=1}^{N}$</span>, </li><li><span>$T^{(d_T, \tau_T)} = \{t_i^{(d_T, \tau_T)} \}_{i=1}^{N}$</span>, </li><li><span>$S^{(d_S, \tau_S)} = \{s_i^{(d_T, \tau_T)} \}_{i=1}^{N}$</span>,  and </li><li><span>$C^{(d_C, \tau_C)} = \{s_i^{(d_C, \tau_C)} \}_{i=1}^{N}$</span>.</li></ul><p>The non-conditioned generalized and conditioned generalized forms of the transfer entropy are then</p><p class="math-container">\[TE(s \to t) = \sum_i p(S,T, \mathcal{T}) \log \left( \dfrac{p(\mathcal{T} |¬†T, S)}{p(\mathcal{T} |¬†T)} \right)\]</p><p class="math-container">\[TE(s \to t |¬†c) = \sum_i p(S,T, \mathcal{T}, C) \log \left( \dfrac{p(\mathcal{T} |¬†T, S, C)}{p(\mathcal{T} |¬†T, C)} \right)\]</p><p><strong>Uniform vs. non-uniform embeddings</strong></p><p>The <code>N</code> state vectors for each marginal are either </p><ul><li>uniform, of the form <span>$x_{i}^{(d, \omega)} = (x_i, x_{i+\omega}, x_{i+2\omega}, \ldots x_{i+(d - 1)\omega})$</span>,    with equally spaced state vector entries. <em>Note: When constructing marginals for <span>$T$</span>, <span>$S$</span> and <span>$C$</span>,    we need <span>$\omega \leq 0$</span> to get present/past values, while <span>$\omega &gt; 0$</span> is necessary to get future states    when constructing <span>$\mathcal{T}$</span>.</em></li><li>non-uniform, of the form <span>$x_{i}^{(d, \omega)} = (x_i, x_{i+\omega_1}, x_{i+\omega_2}, \ldots x_{i+\omega_{d}})$</span>,   with non-equally spaced state vector entries <span>$\omega_1, \omega_2, \ldots, \omega_{d}$</span>,   which can be freely chosen. <em>Note: When constructing marginals for <span>$T$</span>, <span>$S$</span> and <span>$C$</span>,    we need <span>$\omega_i \leq 0$</span> for all <span>$\omega_i$</span> to get present/past values, while <span>$\omega_i &gt; 0$</span> for all <span>$\omega_i$</span>    is necessary to get future states when constructing <span>$\mathcal{T}$</span>.</em></li></ul><p>In practice, the <code>dT</code>-dimensional, <code>dS</code>-dimensional and <code>dC</code>-dimensional state vectors  comprising <span>$T$</span>, <span>$S$</span> and <span>$C$</span> are constructed with embedding lags <code>œÑT</code>,  <code>œÑS</code>, and <code>œÑC</code>, respectively. The <code>dùíØ</code>-dimensional future states <span>$\mathcal{T}^{(d_{\mathcal T}, \eta_{\mathcal T})}$</span> are constructed with prediction lag <code>Œ∑ùíØ</code> (i.e. predictions go from present/past states to  future states spanning a maximum of <code>dùíØ*Œ∑ùíØ</code> time steps). <em>Note: in Schreiber&#39;s paper, only the historical states are defined as  potentially higher-dimensional, while the future states are always scalar.</em></p><p><strong>Estimation</strong></p><p>Transfer entropy is here estimated by rewriting the above expressions as a sum of marginal  entropies, and extending the definitions above to use R√©nyi generalized entropies of order  <code>q</code> as</p><p class="math-container">\[TE^{q}(s \to t) = H^{q}(\mathcal T, T) + H^{q}(T, S) - H^{q}(T) - H^{q}(\mathcal T, T, S),\]</p><p class="math-container">\[TE^{q}(s \to t | c) = H^{q}(\mathcal T, T, C) + H^{q}(T, S, C) - H^{q}(T, C) - H^{q}(\mathcal T, T, S, C),\]</p><p>where <span>$H^{q}(\cdot)$</span> is the generalized R√©nyi entropy of order <span>$q$</span>. This is equivalent to the R√©nyi transfer entropy implementation in Jizba et al. (2012)<sup class="footnote-reference"><a id="citeref-Jizba2012" href="#footnote-Jizba2012">[Jizba2012]</a></sup>.</p><p><strong>Examples</strong></p><p>Default estimation (scalar marginals): </p><pre><code class="language-julia hljs"># Symbolic estimator, motifs of length 4, uniform delay vectors with lag 1
est = SymbolicPermutation(m = 4, œÑ = 1) 

x, y = rand(100), rand(100)
transferentropy(x, y, est)</code></pre><p>Increasing the dimensionality of the <span>$T$</span> marginal (present/past states of the target  variable):</p><pre><code class="language-julia hljs"># Binning-based estimator
est = VisitationFrequency(RectangularBinning(4)) 
x, y = rand(100), rand(100)

# Uniform delay vectors when `œÑT` is an integer (see explanation above)
# Here t_{i}^{(dT, œÑT)} = (t_i, t_{i+œÑ}, t_{i+2œÑ}, \ldots t_{i+(dT-1)œÑ})
# = (t_i, t_{i-2}, t_{i-4}, \ldots t_{i-6œÑ}), so we need zero/negative values for `œÑT`.
transferentropy(x, y, est, dT = 4, œÑT = -2)

# Non-uniform delay vectors when `œÑT` is a vector of integers
# Here t_{i}^{(dT, œÑT)} = (t_i, t_{i+œÑ_{1}}, t_{i+œÑ_{2}}, \ldots t_{i+œÑ_{dT}})
# = (t_i, t_{i-7}, t_{i-25}), so we need zero/negative values for `œÑT`.
transferentropy(x, y, est, dT = 3, œÑT = [0, -7, -25])</code></pre><p>Logarithm bases and the order of the R√©nyi entropy can also be tuned:</p><pre><code class="language-julia hljs">x, y = rand(100), rand(100)
est = NaiveKernel(0.3)
transferentropy(x, y, est, base = MathConstants.e, q = 2) # TE in nats, order-2 R√©nyi entropy</code></pre></div></section></article><h2 id="Reproducing-Schreiber"><a class="docs-heading-anchor" href="#Reproducing-Schreiber">Reproducing Schreiber</a><a id="Reproducing-Schreiber-1"></a><a class="docs-heading-anchor-permalink" href="#Reproducing-Schreiber" title="Permalink"></a></h2><p>Let&#39;s try to reproduce the results from Schreiber&#39;s original paper<sup class="footnote-reference"><a id="citeref-Schreiber2000" href="#footnote-Schreiber2000">[Schreiber2000]</a></sup> on transfer entropy. We&#39;ll use a  visitation frequency estimator, which computes entropies by counting visits of the system&#39;s orbit to discrete portions  of its reconstructed state space.</p><pre><code class="language-julia hljs">using DynamicalSystems, CausalityTools, Plots, Random, StatsBase

Random.seed!(12234)

function ulam_system(dx, x, p, t)
    f(x) = 2 - x^2
    Œµ = p[1]
    dx[1] = f(Œµ*x[length(dx)] + (1-Œµ)*x[1])
    for i in 2:length(dx)
        dx[i] = f(Œµ*x[i-1] + (1-Œµ)*x[i])
    end
end

ds = DiscreteDynamicalSystem(ulam_system, rand(100) .- 0.5, [0.04])
trajectory(ds, 1000; Ttr = 1000)

Œµs = 0.02:0.02:1.0
te_x1x2 = zeros(length(Œµs)); te_x2x1 = zeros(length(Œµs))

for (i, Œµ) in enumerate(Œµs)
    set_parameter!(ds, 1, Œµ)
    tr = trajectory(ds, 2000; Ttr = 5000)
    X1 = tr[:, 1]; X2 = tr[:, 2]
    @assert !any(isnan, X1)
    @assert !any(isnan, X2)
    binning = RectangularBinning(0.2) # guess an appropriate bin width of 0.2
    te_x1x2[i] = transferentropy(X1, X2, VisitationFrequency(binning), base = 2)
    te_x2x1[i] = transferentropy(X2, X1, VisitationFrequency(binning), base = 2)
end

plot()
plot(Œµs, te_x1x2, label = &quot;X1 to X2&quot;, c = :black, lw = 1.5)
plot!(Œµs, te_x2x1, label = &quot;X2 to X1&quot;, c = :red)
xlabel!(&quot;epsilon&quot;)
ylabel!(&quot;Transfer entropy (bits)&quot;)</code></pre><p><img src="../ulam-te.svg" alt/></p><p>As expected, transfer entropy from <code>X1</code> to <code>X2</code> is higher than from <code>X2</code> to <code>X1</code> across parameter values for <code>Œµ</code>. But, by our definition of the <code>ulam</code> system, dynamical coupling only occurs from <code>X1</code> to <code>X2</code>. The results, however,  show nonzero transfer entropy in both directions. What does this mean? </p><p>Computing transfer entropy from finite time series introduces bias, and so does any particular choice of entropy estimator used to calculate it. To determine whether a transfer entropy estimate should be trusted, we can employ <em>surrogate testing</em>. We&#39;ll generate surrogate using <a href="https://github.com/JuliaDynamics/TimeseriesSurrogates.jl">TimeseriesSurrogates.jl</a>.</p><p>In the example below, we continue with the same time series generated above. However, at each value of <code>Œµ</code>, we also compute transfer entropy for <code>nsurr = 50</code> different randomly shuffled (permuted) versions of the source process.  If the original transfer entropy exceeds that of some percentile the transfer entropy estimates of the surrogate ensemble, we will take that as &quot;significant&quot; transfer entropy.</p><pre><code class="language-julia hljs">nsurr = 50
te_x1x2 = zeros(length(Œµs)); te_x2x1 = zeros(length(Œµs))
te_x1x2_surr = zeros(length(Œµs), nsurr); te_x2x1_surr = zeros(length(Œµs), nsurr)

for (i, Œµ) in enumerate(Œµs)
    set_parameter!(ds, 1, Œµ)
    tr = trajectory(ds, 1000; Ttr = 5000)
    X1 = tr[:, 1]; X2 = tr[:, 2]
    @assert !any(isnan, X1)
    @assert !any(isnan, X2)
    binning = RectangularBinning(0.2) # guess an appropriate bin width of 0.2
    est = VisitationFrequency(binning)
    te_x1x2[i] = transferentropy(X1, X2, est, base = 2)
    te_x2x1[i] = transferentropy(X2, X1, est, base = 2)
    s1 = surrogenerator(X1, RandomShuffle()); s2 = surrogenerator(X2, RandomShuffle())

    for j = 1:nsurr
        te_x1x2_surr[i, j] =  transferentropy(s1(), X2, est, base = 2)
        te_x2x1_surr[i, j] =  transferentropy(s2(), X1, est, base = 2)
    end
end

# Compute 95th percentiles of the surrogates for each Œµ
qs_x1x2 = [quantile(te_x1x2_surr[i, :], 0.95) for i = 1:length(Œµs)]
qs_x2x1 = [quantile(te_x2x1_surr[i, :], 0.95) for i = 1:length(Œµs)]

plot(xlabel = &quot;epsilon&quot;, ylabel = &quot;Transfer entropy (bits)&quot;, legend = :topleft)
plot!(Œµs, te_x1x2, label = &quot;X1 to X2&quot;, c = :black, lw = 1.5)
plot!(Œµs, qs_x1x2, label = &quot;&quot;, c = :black, ls = :dot, lw = 1.5)
plot!(Œµs, te_x2x1, label = &quot;X2 to X1&quot;, c = :red)
plot!(Œµs, qs_x2x1, label = &quot;&quot;, c = :red, ls = :dot)</code></pre><p><img src="../ulam-te-surr.svg" alt/></p><p>The plot above shows the original transfer entropies (solid lines) and the 95th percentile transfer entropies of the surrogate ensembles (dotted lines). As expected, using the surrogate test, the transfer entropies from <code>X1</code> to <code>X2</code> are mostly significant (solid black line is <em>above</em> dashed black line). The transfer entropies from <code>X2</code> to <code>X1</code>, on the other hand, are mostly not significant (red solid line is <em>below</em> red dotted line).</p><p><sup class="footnote-reference"><a id="citeref-Schreiber2000" href="#footnote-Schreiber2000">[Schreiber2000]</a></sup>(Schreiber, Thomas. &quot;Measuring information transfer.&quot; Physical review letters 85.2 (2000): 461.)</p><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-Schreiber2000"><a class="tag is-link" href="#citeref-Schreiber2000">Schreiber2000</a>Schreiber, T. (2000). Measuring information transfer. Physical review letters, 85(2), 461.</li><li class="footnote" id="footnote-Jizba2012"><a class="tag is-link" href="#citeref-Jizba2012">Jizba2012</a>Jizba, P., Kleinert, H., &amp; Shefaat, M. (2012). R√©nyi‚Äôs information transfer between financial time series. Physica A: Statistical Mechanics and its Applications, 391(10), 2971-2989.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../mutualinfo/">¬´ Mutual information</a><a class="docs-footer-nextpage" href="../predictive_asymmetry/">Predictive asymmetry ¬ª</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.10 on <span class="colophon-date" title="Sunday 28 November 2021 12:48">Sunday 28 November 2021</span>. Using Julia version 1.6.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
