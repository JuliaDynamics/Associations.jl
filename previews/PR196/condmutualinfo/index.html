<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Conditional mutual information · CausalityTools.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="https://fonts.googleapis.com/css?family=Montserrat|Source+Code+Pro&amp;display=swap" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="CausalityTools.jl logo"/></a><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Overview</a></li><li><a class="tocitem" href="../correlation_measures/">Correlation measures</a></li><li><span class="tocitem">Information measures</span><ul><li><a class="tocitem" href="../probabilities/">Probability mass functions</a></li><li><a class="tocitem" href="../entropy/">Entropy</a></li><li><a class="tocitem" href="../entropy_conditional/">Conditional entropy</a></li><li><a class="tocitem" href="../mutualinfo/">Mutual information</a></li><li class="is-active"><a class="tocitem" href>Conditional mutual information</a><ul class="internal"><li><a class="tocitem" href="#API"><span>API</span></a></li><li><a class="tocitem" href="#Definitions"><span>Definitions</span></a></li><li><a class="tocitem" href="#Dedicated-estimators"><span>Dedicated estimators</span></a></li><li><a class="tocitem" href="#Estimation-through-mutual-information"><span>Estimation through mutual information</span></a></li><li><a class="tocitem" href="#Discrete-CMI"><span>Discrete CMI</span></a></li><li><a class="tocitem" href="#Differential-CMI"><span>Differential CMI</span></a></li></ul></li><li><a class="tocitem" href="../transferentropy/">Transfer entropy</a></li></ul></li><li><a class="tocitem" href="../cross_mappings/">Cross mappings</a></li><li><a class="tocitem" href="../jdd/">Joint distance distribution</a></li><li><a class="tocitem" href="../independence/">Independence testing</a></li><li><span class="tocitem">Examples</span><ul><li><input class="collapse-toggle" id="menuitem-7-1" type="checkbox"/><label class="tocitem" for="menuitem-7-1"><span class="docs-label">Quickstart</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../quickstart/quickstart_mi/">Mutual information</a></li><li><a class="tocitem" href="../quickstart/quickstart_jdd/">Joint distance distribution</a></li><li><a class="tocitem" href="../quickstart/quickstart_independence/">Independence testing</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-7-2" type="checkbox"/><label class="tocitem" for="menuitem-7-2"><span class="docs-label">Longer examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../examples/examples_entropy/">Entropy</a></li><li><a class="tocitem" href="../examples/examples_conditional_entropy/">Conditional entropy</a></li><li><a class="tocitem" href="../examples/examples_mutualinfo/">Mutual information</a></li><li><a class="tocitem" href="../examples/examples_transferentropy/">Transfer entropy</a></li><li><a class="tocitem" href="../examples/examples_cross_mappings/">Cross mappings</a></li><li><a class="tocitem" href="../examples/examples_independence/">Independence testing</a></li></ul></li></ul></li><li><a class="tocitem" href="../experimental/">Experimental</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Information measures</a></li><li class="is-active"><a href>Conditional mutual information</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Conditional mutual information</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaDynamics/CausalityTools.jl/blob/master/docs/src/condmutualinfo.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Conditional-mutual-information-(CMI)"><a class="docs-heading-anchor" href="#Conditional-mutual-information-(CMI)">Conditional mutual information (CMI)</a><a id="Conditional-mutual-information-(CMI)-1"></a><a class="docs-heading-anchor-permalink" href="#Conditional-mutual-information-(CMI)" title="Permalink"></a></h1><h2 id="API"><a class="docs-heading-anchor" href="#API">API</a><a id="API-1"></a><a class="docs-heading-anchor-permalink" href="#API" title="Permalink"></a></h2><p>The condition mutual information API is defined by</p><ul><li><a href="#CausalityTools.ConditionalMutualInformation"><code>ConditionalMutualInformation</code></a>,</li><li><a href="../mutualinfo/#CausalityTools.mutualinfo-Tuple{MutualInformationEstimator, Any, Any}"><code>mutualinfo</code></a>,</li><li><a href="#CausalityTools.ConditionalMutualInformationEstimator"><code>ConditionalMutualInformationEstimator</code></a>.</li></ul><h2 id="Definitions"><a class="docs-heading-anchor" href="#Definitions">Definitions</a><a id="Definitions-1"></a><a class="docs-heading-anchor-permalink" href="#Definitions" title="Permalink"></a></h2><h3 id="Shannon-CMI"><a class="docs-heading-anchor" href="#Shannon-CMI">Shannon CMI</a><a id="Shannon-CMI-1"></a><a class="docs-heading-anchor-permalink" href="#Shannon-CMI" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="CausalityTools.ConditionalMutualInformation" href="#CausalityTools.ConditionalMutualInformation"><code>CausalityTools.ConditionalMutualInformation</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ConditionalMutualInformation &lt;: InformationMeasure
CMI # alias</code></pre><p>The supertype of all conditional mutual informations.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/CausalityTools.jl/blob/cb17a0f0315620a787a4aa575c7bc0e878960798/src/methods/infomeasures/condmutualinfo/condmutualinfo.jl#L6-L11">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalityTools.CMIShannon" href="#CausalityTools.CMIShannon"><code>CausalityTools.CMIShannon</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CMIShannon &lt;: ConditionalMutualInformation
CMIShannon(; base = 2)</code></pre><p>The Shannon conditional mutual information (CMI) <span>$I^S(X; Y | Z)$</span>.</p><p><strong>Supported definitions</strong></p><p>Consider random variables <span>$X \in \mathbb{R}^{d_X}$</span> and <span>$Y \in \mathbb{R}^{d_Y}$</span>, given <span>$Z \in \mathbb{R}^{d_Z}$</span>. The Shannon conditional mutual information is defined as</p><p class="math-container">\[\begin{align*}
I(X; Y | Z)
&amp;= H^S(X, Z) + H^S(Y, z) - H^S(X, Y, Z) - H^S(Z) \\
&amp;= I^S(X; Y, Z) + I^S(X; Y)
\end{align*},\]</p><p>where <span>$I^S(\cdot; \cdot)$</span> is the Shannon mutual information <a href="../mutualinfo/#CausalityTools.MIShannon"><code>MIShannon</code></a>, and <span>$H^S(\cdot)$</span> is the <a href="../entropy/#ComplexityMeasures.Shannon"><code>Shannon</code></a> entropy.</p><p>Differential Shannon CMI is obtained by replacing the entropies by differential entropies.</p><p>See also: <a href="#CausalityTools.condmutualinfo-Tuple{ConditionalMutualInformationEstimator, Any, Any, Any}"><code>condmutualinfo</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/CausalityTools.jl/blob/cb17a0f0315620a787a4aa575c7bc0e878960798/src/methods/infomeasures/condmutualinfo/CMIShannon.jl#L4-L31">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalityTools.CMIRenyiJizba" href="#CausalityTools.CMIRenyiJizba"><code>CausalityTools.CMIRenyiJizba</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CMIRenyiJizba &lt;: ConditionalMutualInformation</code></pre><p>The Rényi conditional mutual information <span>$I_q^{R_{J}}(X; Y | Z$</span> defined in Jizba et al. (2012)<sup class="footnote-reference"><a id="citeref-Jizba2012" href="#footnote-Jizba2012">[Jizba2012]</a></sup>.</p><p><strong>Definition</strong></p><p class="math-container">\[I_q^{R_{J}}(X; Y | Z) = I_q^{R_{J}}(X; Y, Z) - I_q^{R_{J}}(X; Z),\]</p><p>where <span>$I_q^{R_{J}}(X; Z)$</span> is the <a href="../mutualinfo/#CausalityTools.MIRenyiJizba"><code>MIRenyiJizba</code></a> mutual information.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/CausalityTools.jl/blob/cb17a0f0315620a787a4aa575c7bc0e878960798/src/methods/infomeasures/condmutualinfo/CMIRenyiJizba.jl#L2-L20">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalityTools.CMIRenyiPoczos" href="#CausalityTools.CMIRenyiPoczos"><code>CausalityTools.CMIRenyiPoczos</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CMIRenyiPoczos &lt;: ConditionalMutualInformation</code></pre><p>The differential Rényi conditional mutual information <span>$I_q^{R_{P}}(X; Y | Z)$</span> defined in (Póczos &amp; Schneider, 2012)<sup class="footnote-reference"><a id="citeref-Póczos2012" href="#footnote-Póczos2012">[Póczos2012]</a></sup>.</p><p><strong>Definition</strong></p><p class="math-container">\[\begin{align*}
I_q^{R_{P}}(X; Y | Z) = \dfrac{1}{q-1}
\int \int \int \dfrac{p_Z(z) p_{X, Y | Z}^q}{( p_{X|Z}(x|z) p_{Y|Z}(y|z) )^{q-1}} \\
\mathbb{E}_{X, Y, Z} \sim p_{X, Y, Z}
\left[ \dfrac{p_{X, Z}^{1-q}(X, Z) p_{Y, Z}^{1-q}(Y, Z) }{p_{X, Y, Z}^{1-q}(X, Y, Z) p_Z^{1-q}(Z)} \right]
\end{align*}\]</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/CausalityTools.jl/blob/cb17a0f0315620a787a4aa575c7bc0e878960798/src/methods/infomeasures/condmutualinfo/CMIRenyiPoczos.jl#L3-L24">source</a></section></article><h2 id="Dedicated-estimators"><a class="docs-heading-anchor" href="#Dedicated-estimators">Dedicated estimators</a><a id="Dedicated-estimators-1"></a><a class="docs-heading-anchor-permalink" href="#Dedicated-estimators" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="CausalityTools.condmutualinfo-Tuple{ConditionalMutualInformationEstimator, Any, Any, Any}" href="#CausalityTools.condmutualinfo-Tuple{ConditionalMutualInformationEstimator, Any, Any, Any}"><code>CausalityTools.condmutualinfo</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">condmutualinfo([measure::CMI], est::CMIEstimator, x, y, z) → cmi::Real</code></pre><p>Estimate a conditional mutual information (CMI) of some kind (specified by <code>measure</code>), between <code>x</code> and <code>y</code>, given <code>z</code>, using the given dedicated <a href="#CausalityTools.ConditionalMutualInformationEstimator"><code>ConditionalMutualInformationEstimator</code></a>, which may be discrete, continuous or mixed.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/CausalityTools.jl/blob/cb17a0f0315620a787a4aa575c7bc0e878960798/src/methods/infomeasures/condmutualinfo/condmutualinfo.jl#L31-L38">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalityTools.ConditionalMutualInformationEstimator" href="#CausalityTools.ConditionalMutualInformationEstimator"><code>CausalityTools.ConditionalMutualInformationEstimator</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ConditionalMutualInformationEstimator &lt;: InformationEstimator
CMIEstimator # alias</code></pre><p>The supertype of all conditional mutual information estimators.</p><p><strong>Subtypes</strong></p><ul><li><a href="#CausalityTools.FPVP"><code>FPVP</code></a>.</li><li><a href="#CausalityTools.PoczosSchneiderCMI"><code>PoczosSchneiderCMI</code></a>.</li><li><a href="#CausalityTools.Rahimzamani"><code>Rahimzamani</code></a>.</li><li><a href="#CausalityTools.MesnerShalisi"><code>MesnerShalisi</code></a>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/CausalityTools.jl/blob/cb17a0f0315620a787a4aa575c7bc0e878960798/src/methods/infomeasures/condmutualinfo/condmutualinfo.jl#L15-L27">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalityTools.FPVP" href="#CausalityTools.FPVP"><code>CausalityTools.FPVP</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">FPVP &lt;: ConditionalMutualInformationEstimator
FPVP(k = 1, w = 0)</code></pre><p>The Frenzel-Pompe-Vejmelka-Paluš (or <code>FPVP</code> for short) estimator is used to estimate the differential conditional mutual information using a <code>k</code>-th nearest neighbor approach that is analogous to that of the <a href="../mutualinfo/#CausalityTools.KraskovStögbauerGrassberger1"><code>KraskovStögbauerGrassberger1</code></a> mutual information estimator (Frenzel &amp; Pompe, 2007<sup class="footnote-reference"><a id="citeref-Frenzel2007" href="#footnote-Frenzel2007">[Frenzel2007]</a></sup>; Vejmelka &amp; Paluš, 2008<sup class="footnote-reference"><a id="citeref-Vejmelka2008" href="#footnote-Vejmelka2008">[Vejmelka2008]</a></sup>).</p><p><code>w</code> is the Theiler window, which controls the number of temporal neighbors that are excluded during neighbor searches.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/CausalityTools.jl/blob/cb17a0f0315620a787a4aa575c7bc0e878960798/src/methods/infomeasures/condmutualinfo/estimators/FPVP.jl#L8-L27">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalityTools.MesnerShalisi" href="#CausalityTools.MesnerShalisi"><code>CausalityTools.MesnerShalisi</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">MesnerShalisi &lt;: ConditionalMutualInformationEstimator
MesnerShalisi(k = 1, w = 0)</code></pre><p>The <code>MesnerShalisi</code> estimator is an estimator for conditional mutual information for data that can be mixtures of discrete and continuous data (Mesner &amp; Shalisi et al., 2020)<sup class="footnote-reference"><a id="citeref-MesnerShalisi2020" href="#footnote-MesnerShalisi2020">[MesnerShalisi2020]</a></sup>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/CausalityTools.jl/blob/cb17a0f0315620a787a4aa575c7bc0e878960798/src/methods/infomeasures/condmutualinfo/estimators/MesnerShalisi.jl#L3-L15">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalityTools.PoczosSchneiderCMI" href="#CausalityTools.PoczosSchneiderCMI"><code>CausalityTools.PoczosSchneiderCMI</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">PoczosSchneiderCMI &lt;: ConditionalMutualInformationEstimator
PoczosSchneiderCMI(k = 1, w = 0)</code></pre><p>The <code>PoczosSchneiderCMI</code> estimator computes various (differential) conditional mutual informations, using a <code>k</code>-th nearest neighbor approach (Póczos &amp; Schneider, 2012)<sup class="footnote-reference"><a id="citeref-Póczos2012" href="#footnote-Póczos2012">[Póczos2012]</a></sup>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/CausalityTools.jl/blob/cb17a0f0315620a787a4aa575c7bc0e878960798/src/methods/infomeasures/condmutualinfo/estimators/PoczosSchneiderCMI.jl#L5-L17">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalityTools.Rahimzamani" href="#CausalityTools.Rahimzamani"><code>CausalityTools.Rahimzamani</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Rahimzamani &lt;: ConditionalMutualInformationEstimator
Rahimzamani(k = 1, w = 0)</code></pre><p>The <code>Rahimzamani</code> estimator, short for Rahimzamani-Asnani-Viswanath-Kannan, is an estimator for Shannon conditional mutual information for data that can be mixtures of discrete and continuous data (Rahimzamani et al., 2018)<sup class="footnote-reference"><a id="citeref-Rahimzamani2018" href="#footnote-Rahimzamani2018">[Rahimzamani2018]</a></sup>.</p><p>This is very similar to the <a href="../mutualinfo/#CausalityTools.GaoKannanOhViswanath"><code>GaoKannanOhViswanath</code></a> mutual information estimator, but has been expanded to the conditional case.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/CausalityTools.jl/blob/cb17a0f0315620a787a4aa575c7bc0e878960798/src/methods/infomeasures/condmutualinfo/estimators/Rahimzamani.jl#L3-L18">source</a></section></article><h3 id="condmutualinfo_dedicated_estimators"><a class="docs-heading-anchor" href="#condmutualinfo_dedicated_estimators">Table of dedicated CMI estimators</a><a id="condmutualinfo_dedicated_estimators-1"></a><a class="docs-heading-anchor-permalink" href="#condmutualinfo_dedicated_estimators" title="Permalink"></a></h3><table><tr><th style="text-align: right">Estimator</th><th style="text-align: right">Principle</th><th style="text-align: center"><a href="#CausalityTools.CMIShannon"><code>CMIShannon</code></a></th><th style="text-align: center"><a href="#CausalityTools.CMIRenyiPoczos"><code>CMIRenyiPoczos</code></a></th></tr><tr><td style="text-align: right"><a href="#CausalityTools.FPVP"><code>FPVP</code></a></td><td style="text-align: right">Nearest neighbors</td><td style="text-align: center">✓</td><td style="text-align: center">x</td></tr><tr><td style="text-align: right"><a href="#CausalityTools.MesnerShalisi"><code>MesnerShalisi</code></a></td><td style="text-align: right">Nearest neighbors</td><td style="text-align: center">✓</td><td style="text-align: center">x</td></tr><tr><td style="text-align: right"><a href="#CausalityTools.Rahimzamani"><code>Rahimzamani</code></a></td><td style="text-align: right">Nearest neighbors</td><td style="text-align: center">✓</td><td style="text-align: center">x</td></tr><tr><td style="text-align: right"><a href="#CausalityTools.PoczosSchneiderCMI"><code>PoczosSchneiderCMI</code></a></td><td style="text-align: right">Nearest neighbors</td><td style="text-align: center">x</td><td style="text-align: center">✓</td></tr><tr><td style="text-align: right"><a href="@ref"><code>GaussianCMI</code></a></td><td style="text-align: right">Parametric</td><td style="text-align: center">✓</td><td style="text-align: center">x</td></tr></table><h2 id="Estimation-through-mutual-information"><a class="docs-heading-anchor" href="#Estimation-through-mutual-information">Estimation through mutual information</a><a id="Estimation-through-mutual-information-1"></a><a class="docs-heading-anchor-permalink" href="#Estimation-through-mutual-information" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="CausalityTools.condmutualinfo-Tuple{MutualInformationEstimator, Any, Any, Any}" href="#CausalityTools.condmutualinfo-Tuple{MutualInformationEstimator, Any, Any, Any}"><code>CausalityTools.condmutualinfo</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">condmutualinfo([measure::CMI], est::MutualInformationEstimator, x, y, z) → cmi::Real</code></pre><p>Estimate the conditional mutual information (CMI) <code>measure</code> between <code>x</code> and <code>y</code> using a difference of mutual information terms, without any bias correction, using the provided <a href="../mutualinfo/#CausalityTools.MutualInformationEstimator"><code>MutualInformationEstimator</code></a> <code>est</code>, which may be continuous/differential, discrete or mixed. If <code>measure</code> is not given, then the default is <code>CMIShannon()</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/CausalityTools.jl/blob/cb17a0f0315620a787a4aa575c7bc0e878960798/src/methods/infomeasures/condmutualinfo/condmutualinfo.jl#L79-L87">source</a></section></article><table><tr><th style="text-align: right">Estimator</th><th style="text-align: center">Type</th><th style="text-align: center">Principle</th><th style="text-align: center"><a href="#CausalityTools.CMIShannon"><code>CMIShannon</code></a></th></tr><tr><td style="text-align: right"><a href="../mutualinfo/#CausalityTools.KraskovStögbauerGrassberger1"><code>KraskovStögbauerGrassberger1</code></a></td><td style="text-align: center">Continuous</td><td style="text-align: center">Nearest neighbors</td><td style="text-align: center">✓</td></tr><tr><td style="text-align: right"><a href="../mutualinfo/#CausalityTools.KraskovStögbauerGrassberger2"><code>KraskovStögbauerGrassberger2</code></a></td><td style="text-align: center">Continuous</td><td style="text-align: center">Nearest neighbors</td><td style="text-align: center">✓</td></tr><tr><td style="text-align: right"><a href="../mutualinfo/#CausalityTools.GaoKannanOhViswanath"><code>GaoKannanOhViswanath</code></a></td><td style="text-align: center">Mixed</td><td style="text-align: center">Nearest neighbors</td><td style="text-align: center">✓</td></tr><tr><td style="text-align: right"><a href="../mutualinfo/#CausalityTools.GaoOhViswanath"><code>GaoOhViswanath</code></a></td><td style="text-align: center">Continuous</td><td style="text-align: center">Nearest neighbors</td><td style="text-align: center">✓</td></tr><tr><td style="text-align: right"><a href="@ref"><code>GaussianMI</code></a></td><td style="text-align: center"></td><td style="text-align: center">Parametric</td><td style="text-align: center">✓</td></tr></table><h2 id="Discrete-CMI"><a class="docs-heading-anchor" href="#Discrete-CMI">Discrete CMI</a><a id="Discrete-CMI-1"></a><a class="docs-heading-anchor-permalink" href="#Discrete-CMI" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="CausalityTools.condmutualinfo-Tuple{ProbabilitiesEstimator, Any, Any, Any}" href="#CausalityTools.condmutualinfo-Tuple{ProbabilitiesEstimator, Any, Any, Any}"><code>CausalityTools.condmutualinfo</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">condmutualinfo([measure::CMI], est::ProbabilitiesEstimator, x, y, z) → cmi::Real ∈ [0, a)</code></pre><p>Estimate the conditional mutual information (CMI) <code>measure</code> between <code>x</code> and <code>y</code> given <code>z</code> using a sum of entropy terms, without any bias correction, using the provided <a href="../probabilities/#ComplexityMeasures.ProbabilitiesEstimator"><code>ProbabilitiesEstimator</code></a> <code>est</code>. If <code>measure</code> is not given, then the default is <code>CMIShannon()</code>.</p><p>With a <a href="../probabilities/#ComplexityMeasures.ProbabilitiesEstimator"><code>ProbabilitiesEstimator</code></a>, the returned <code>cmi</code> is guaranteed to be non-negative.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/CausalityTools.jl/blob/cb17a0f0315620a787a4aa575c7bc0e878960798/src/methods/infomeasures/condmutualinfo/condmutualinfo.jl#L52-L62">source</a></section></article><h3 id="mutualinfo_overview"><a class="docs-heading-anchor" href="#mutualinfo_overview">Table of discrete mutual information estimators</a><a id="mutualinfo_overview-1"></a><a class="docs-heading-anchor-permalink" href="#mutualinfo_overview" title="Permalink"></a></h3><p>Here, we list the <a href="../probabilities/#ComplexityMeasures.ProbabilitiesEstimator"><code>ProbabilitiesEstimator</code></a>s that are compatible with <a href="#CausalityTools.condmutualinfo-Tuple{ConditionalMutualInformationEstimator, Any, Any, Any}"><code>condmutualinfo</code></a>, and which definitions they are valid for.</p><table><tr><th style="text-align: right">Estimator</th><th style="text-align: right">Principle</th><th style="text-align: center"><a href="#CausalityTools.CMIShannon"><code>CMIShannon</code></a></th><th style="text-align: center"><a href="@ref"><code>CMIRenyiSarbu</code></a></th></tr><tr><td style="text-align: right"><a href="../probabilities/#ComplexityMeasures.CountOccurrences"><code>CountOccurrences</code></a></td><td style="text-align: right">Frequencies</td><td style="text-align: center">✓</td><td style="text-align: center">✓</td></tr><tr><td style="text-align: right"><a href="../probabilities/#ComplexityMeasures.ValueHistogram"><code>ValueHistogram</code></a></td><td style="text-align: right">Binning (histogram)</td><td style="text-align: center">✓</td><td style="text-align: center">✓</td></tr><tr><td style="text-align: right"><a href="@ref"><code>SymbolicPermuation</code></a></td><td style="text-align: right">Ordinal patterns</td><td style="text-align: center">✓</td><td style="text-align: center">✓</td></tr><tr><td style="text-align: right"><a href="../probabilities/#ComplexityMeasures.Dispersion"><code>Dispersion</code></a></td><td style="text-align: right">Dispersion patterns</td><td style="text-align: center">✓</td><td style="text-align: center">✓</td></tr></table><h2 id="Differential-CMI"><a class="docs-heading-anchor" href="#Differential-CMI">Differential CMI</a><a id="Differential-CMI-1"></a><a class="docs-heading-anchor-permalink" href="#Differential-CMI" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="CausalityTools.condmutualinfo-Tuple{DifferentialEntropyEstimator, Any, Any, Any}" href="#CausalityTools.condmutualinfo-Tuple{DifferentialEntropyEstimator, Any, Any, Any}"><code>CausalityTools.condmutualinfo</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">condmutualinfo([measure::CMI], est::DifferentialEntropyEstimator, x, y, z) → cmi</code></pre><p>Estimate the conditional mutual information (CMI) <code>measure</code> between <code>x</code> and <code>y</code> using a sum of entropy terms, without any bias correction, using the provided <a href="../entropy/#ComplexityMeasures.DifferentialEntropyEstimator"><code>DifferentialEntropyEstimator</code></a> <code>est</code> (which must support multivariate data). If <code>measure</code> is not given, then the default is <code>CMIShannon()</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/CausalityTools.jl/blob/cb17a0f0315620a787a4aa575c7bc0e878960798/src/methods/infomeasures/condmutualinfo/condmutualinfo.jl#L67-L74">source</a></section></article><table><tr><th style="text-align: right">Estimator</th><th style="text-align: right">Principle</th><th style="text-align: right">Input data</th><th style="text-align: center"><a href="#CausalityTools.CMIShannon"><code>CMIShannon</code></a></th></tr><tr><td style="text-align: right"><a href="../entropy/#ComplexityMeasures.Kraskov"><code>Kraskov</code></a></td><td style="text-align: right">Nearest neighbors</td><td style="text-align: right"><code>Dataset</code></td><td style="text-align: center">✓</td></tr><tr><td style="text-align: right"><a href="../entropy/#ComplexityMeasures.Zhu"><code>Zhu</code></a></td><td style="text-align: right">Nearest neighbors</td><td style="text-align: right"><code>Dataset</code></td><td style="text-align: center">✓</td></tr><tr><td style="text-align: right"><a href="../entropy/#ComplexityMeasures.Gao"><code>Gao</code></a></td><td style="text-align: right">Nearest neighbors</td><td style="text-align: right"><code>Dataset</code></td><td style="text-align: center">✓</td></tr><tr><td style="text-align: right"><a href="../entropy/#ComplexityMeasures.Goria"><code>Goria</code></a></td><td style="text-align: right">Nearest neighbors</td><td style="text-align: right"><code>Dataset</code></td><td style="text-align: center">✓</td></tr><tr><td style="text-align: right"><a href="@ref"><code>Lord</code></a></td><td style="text-align: right">Nearest neighbors</td><td style="text-align: right"><code>Dataset</code></td><td style="text-align: center">✓</td></tr><tr><td style="text-align: right"><a href="@ref"><code>LeonenkoProzantoSavani</code></a></td><td style="text-align: right">Nearest neighbors</td><td style="text-align: right"><code>Dataset</code></td><td style="text-align: center">✓</td></tr></table><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-Jizba2012"><a class="tag is-link" href="#citeref-Jizba2012">Jizba2012</a>Jizba, P., Kleinert, H., &amp; Shefaat, M. (2012). Rényi’s information transfer between financial time series. Physica A: Statistical Mechanics and its Applications, 391(10), 2971-2989.</li><li class="footnote" id="footnote-Póczos2012"><a class="tag is-link" href="#citeref-Póczos2012">Póczos2012</a>Póczos, B., &amp; Schneider, J. (2012, March). Nonparametric estimation of conditional information and divergences. In Artificial Intelligence and Statistics (pp. 914-923). PMLR.</li><li class="footnote" id="footnote-Frenzel2007"><a class="tag is-link" href="#citeref-Frenzel2007">Frenzel2007</a>Frenzel, S., &amp; Pompe, B. (2007). Partial mutual information for coupling analysis of multivariate time series. Physical review letters, 99(20), 204101. <code>w</code> is the Theiler window.</li><li class="footnote" id="footnote-Vejmelka2008"><a class="tag is-link" href="#citeref-Vejmelka2008">Vejmelka2008</a>Vejmelka, M., &amp; Paluš, M. (2008). Inferring the directionality of coupling with conditional mutual information. Physical Review E, 77(2), 026214.</li><li class="footnote" id="footnote-MesnerShalisi2020"><a class="tag is-link" href="#citeref-MesnerShalisi2020">MesnerShalisi2020</a>Mesner, O. C., &amp; Shalizi, C. R. (2020). Conditional mutual information estimation for mixed, discrete and continuous data. IEEE Transactions on Information Theory, 67(1), 464-484.</li><li class="footnote" id="footnote-Póczos2012"><a class="tag is-link" href="#citeref-Póczos2012">Póczos2012</a>Póczos, B., &amp; Schneider, J. (2012, March). Nonparametric estimation of conditional information and divergences. In Artificial Intelligence and Statistics (pp. 914-923). PMLR.</li><li class="footnote" id="footnote-Rahimzamani2018"><a class="tag is-link" href="#citeref-Rahimzamani2018">Rahimzamani2018</a>Rahimzamani, A., Asnani, H., Viswanath, P., &amp; Kannan, S. (2018). Estimators for multivariate information measures in general probability spaces. Advances in Neural Information Processing Systems, 31.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../mutualinfo/">« Mutual information</a><a class="docs-footer-nextpage" href="../transferentropy/">Transfer entropy »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Monday 6 February 2023 03:17">Monday 6 February 2023</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
