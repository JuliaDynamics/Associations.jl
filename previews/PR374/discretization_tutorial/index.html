<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Encoding input datasets · CausalityTools.jl</title><meta name="title" content="Encoding input datasets · CausalityTools.jl"/><meta property="og:title" content="Encoding input datasets · CausalityTools.jl"/><meta property="twitter:title" content="Encoding input datasets · CausalityTools.jl"/><meta name="description" content="Documentation for CausalityTools.jl."/><meta property="og:description" content="Documentation for CausalityTools.jl."/><meta property="twitter:description" content="Documentation for CausalityTools.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="https://fonts.googleapis.com/css?family=Montserrat|Source+Code+Pro&amp;display=swap" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img class="docs-light-only" src="../assets/logo.png" alt="CausalityTools.jl logo"/><img class="docs-dark-only" src="../assets/logo-dark.png" alt="CausalityTools.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">CausalityTools.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">CausalityTools.jl</a></li><li><a class="tocitem" href="../associations/">Association measures</a></li><li><a class="tocitem" href="../independence/">Independence</a></li><li><a class="tocitem" href="../causal_graphs/">Network/graph inference</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../examples/examples_associations/">Association measures</a></li><li><a class="tocitem" href="../examples/examples_infer_graphs/">Graph inference</a></li><li><span class="tocitem">Extended examples</span><ul><li><a class="tocitem" href="../extended_examples/cross_mapping/"><code>ConvergentCrossMapping</code></a></li><li><a class="tocitem" href="../extended_examples/pairwise_asymmetric_inference/"><code>PairwiseAsymmetricInference</code></a></li><li><a class="tocitem" href="../extended_examples/mutual_information/"><code>MIShannon</code></a></li></ul></li></ul></li><li><span class="tocitem">Basics and tutorials</span><ul><li><a class="tocitem" href="../encoding_tutorial/">Encoding elements</a></li><li class="is-active"><a class="tocitem" href>Encoding input datasets</a><ul class="internal"><li><a class="tocitem" href="#tutorial_codify_points"><span>Encoding <em>rows</em> (one <em>point</em> at a time)</span></a></li><li><a class="tocitem" href="#Encoding-*columns*-(one-variable-at-a-time)"><span>Encoding <em>columns</em> (one variable at a time)</span></a></li><li><a class="tocitem" href="#Codify-API"><span>Codify API</span></a></li></ul></li><li><a class="tocitem" href="../probabilities_tutorial/">Counts and probabilities</a></li><li><a class="tocitem" href="../info_tutorial/">Information measures</a></li></ul></li><li><a class="tocitem" href="../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Basics and tutorials</a></li><li class="is-active"><a href>Encoding input datasets</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Encoding input datasets</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaDynamics/CausalityTools.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaDynamics/CausalityTools.jl/blob/main/docs/src/discretization_tutorial.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="discretization_tutorial"><a class="docs-heading-anchor" href="#discretization_tutorial">Discretization tutorial</a><a id="discretization_tutorial-1"></a><a class="docs-heading-anchor-permalink" href="#discretization_tutorial" title="Permalink"></a></h1><p>There are two main ways of discretizing data in CausalityTools. They are implemented as  the <a href="#CausalityTools.CodifyPoints"><code>CodifyPoints</code></a> and <a href="#CausalityTools.CodifyVariables"><code>CodifyVariables</code></a> types, which are used as  input to the <a href="#ComplexityMeasures.codify"><code>codify</code></a> function (extended from ComplexityMeasures.jl to multiple  variables).</p><h2 id="tutorial_codify_points"><a class="docs-heading-anchor" href="#tutorial_codify_points">Encoding <em>rows</em> (one <em>point</em> at a time)</a><a id="tutorial_codify_points-1"></a><a class="docs-heading-anchor-permalink" href="#tutorial_codify_points" title="Permalink"></a></h2><p>In some cases, it may be desireable to encode data on a row-wise basis. This  typically happens when working with pre-embedded time series. If we want to  apply something like <a href="../encoding_tutorial/#ComplexityMeasures.OrdinalPatternEncoding"><code>OrdinalPatternEncoding</code></a> to a pre-embedded  <a href="../#StateSpaceSets.StateSpaceSet"><code>StateSpaceSet</code></a>, then we must encode each <em>point</em> individually, respecting the fact that time ordering is already taken care of by the  embedding procedure. <a href="#CausalityTools.CodifyPoints"><code>CodifyPoints</code></a> ensures input data are encoded  on a point-by-point basis.</p><pre><code class="language-julia hljs">using CausalityTools
using StateSpaceSets
using Random; rng = Xoshiro(1234)

# The first variable is 2-dimensional and has 50 points
x = StateSpaceSet(rand(rng, 50, 2))
# The second variable is 3-dimensional and has 50 points
y = StateSpaceSet(rand(rng, 50, 3))
# The third variable is 4-dimensional and has 50 points
z = StateSpaceSet(rand(rng, 50, 4))

# One encoding scheme per input variable
# encode `x` using `ox` on a point-by-point basis (Vector{SVector{4}} → Vector{Int})
# encode `y` using `oy` on a point-by-point basis (Vector{SVector{3}} → Vector{Int})
# encode `z` using `oz` on a point-by-point basis (Vector{SVector{2}} → Vector{Int})
ox = OrdinalPatternEncoding(2)
oy = OrdinalPatternEncoding(3)
oz = OrdinalPatternEncoding(4)

# This given three column vectors of integers.
cx, cy, cz = codify(CodifyPoints(ox, oy, oz), x, y, z)

[cx cy cz]</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">50×3 Matrix{Int64}:
 2  1   9
 1  4   5
 2  6   2
 1  3  22
 1  1  23
 1  1  17
 2  2   2
 2  6   7
 2  4  20
 1  3  22
 ⋮     
 2  3  12
 1  6  19
 2  1  24
 1  4   5
 2  2   2
 2  6  11
 1  6  18
 1  3  21
 2  1   2</code></pre><p>Notice that the 2-dimensional <code>x</code> has been encoded into integer values <code>1</code> or <code>2</code>, because there are <code>2!</code> possible ordinal patterns for dimension <code>m = 2</code>. The 3-dimensional <code>y</code> has  been encoded into integers in the range <code>1</code> to <code>3! = 6</code>, while the 4-dimensional <code>z</code> is  encoded into an even larger range of integers, because the number of possible ordinal patterns is <code>4! = 24</code> for 4-dimensional embedding vectors.</p><h2 id="Encoding-*columns*-(one-variable-at-a-time)"><a class="docs-heading-anchor" href="#Encoding-*columns*-(one-variable-at-a-time)">Encoding <em>columns</em> (one variable at a time)</a><a id="Encoding-*columns*-(one-variable-at-a-time)-1"></a><a class="docs-heading-anchor-permalink" href="#Encoding-*columns*-(one-variable-at-a-time)" title="Permalink"></a></h2><p>Sometimes, it may be desireable to encode input data one variable/column at a time. This typically happens when the input are either a single or multiple timeseries.</p><p>To encode columns, we apply an <a href="../encoding_tutorial/#ComplexityMeasures.Encoding"><code>Encoding</code></a> using a sliding window across each input variable.  The width of the window is determined by the chosen encoding. For example, using <a href="#ComplexityMeasures.ValueBinning"><code>ValueBinning</code></a> will encode <code>N</code> value into <code>N</code> discretized values. <a href="#CausalityTools.CodifyVariables"><code>CodifyVariables</code></a> is used to enforce a sliding window encoding on a  per-variable basis.</p><pre><code class="language-julia hljs">using CausalityTools
using Random; rng = Xoshiro(1234)

x = rand(rng, 100)
o = ValueBinning(3)
cx = codify(CodifyVariables(o), x)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">100-element Vector{Int64}:
 2
 2
 3
 1
 2
 2
 3
 3
 3
 3
 ⋮
 1
 3
 1
 3
 2
 1
 3
 2
 3</code></pre><p>We can verify that <a href="#ComplexityMeasures.ValueBinning"><code>ValueBinning</code></a> preserves the cardinality of the input dataset.</p><pre><code class="language- hljs">length(x) == length(cx)</code></pre><p>Other outcome spaces such as <a href="#ComplexityMeasures.Dispersion"><code>Dispersion</code></a> or <a href="#ComplexityMeasures.OrdinalPatterns"><code>OrdinalPatterns</code></a> do not  preserve the cardinality of the input dataset, because when applied in a sliding window, they compress embedding vectors into single integers. This means that some points at the  end of each input variable are lost.</p><pre><code class="language-julia hljs">using CausalityTools
using Random; rng = Xoshiro(1234)

x = rand(rng, 100)
o = OrdinalPatterns(m = 3)
cx = codify(CodifyVariables(o), x)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">98-element Vector{Int64}:
 3
 5
 4
 1
 1
 1
 5
 6
 6
 6
 ⋮
 5
 3
 5
 4
 2
 6
 3
 2
 4</code></pre><p>We can also simultaneously encode each variable/column of a <a href="../#StateSpaceSets.StateSpaceSet"><code>StateSpaceSet</code></a>, as long  as we apply an encoding that results in the <em>same</em> number of encoded data points.</p><pre><code class="language-julia hljs">using CausalityTools
using Random; rng = Xoshiro(1234)

x = rand(rng, 100)
y = rand(rng, 100)
o = OrdinalPatterns(m = 3)
# Alternatively provide a tuple of input time series: codify(CodifyVariables(o), (x, y))
cx, cy = codify(CodifyVariables(o), StateSpaceSet(x, y))

[cx cy]</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">98×2 Matrix{Int64}:
 3  1
 5  5
 4  6
 1  4
 1  2
 1  3
 5  1
 6  5
 6  4
 6  1
 ⋮  
 5  5
 3  4
 5  1
 4  5
 2  3
 6  2
 3  4
 2  5
 4  4</code></pre><h2 id="Codify-API"><a class="docs-heading-anchor" href="#Codify-API">Codify API</a><a id="Codify-API-1"></a><a class="docs-heading-anchor-permalink" href="#Codify-API" title="Permalink"></a></h2><p>A fundamental operation when computing multivariate information measures from data is <em>discretization</em>.  The following functions and types are used by CausalityTools.jl to perform discretization of input data.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ComplexityMeasures.codify" href="#ComplexityMeasures.codify"><code>ComplexityMeasures.codify</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">codify(o::OutcomeSpace, x::Vector) → s::Vector{Int}
codify(o::OutcomeSpace, x::AbstractStateSpaceSet{D}) → s::NTuple{D, Vector{Int}</code></pre><p>Codify <code>x</code> according to the outcome space <code>o</code>. If <code>x</code> is a <code>Vector</code>, then a <code>Vector{&lt;:Integer}</code> is returned. If <code>x</code> is a <code>StateSpaceSet{D}</code>, then symbolization is done column-wise and an <code>NTuple{D, Vector{&lt;:Integer}}</code> is returned, where <code>D = dimension(x)</code>.</p><p><strong>Description</strong></p><p>The reason this function exists is that we don&#39;t always want to <a href="../encoding_tutorial/#ComplexityMeasures.encode"><code>encode</code></a> the entire input <code>x</code> at once. Sometimes, it is desirable to first apply some transformation to <code>x</code> first, then apply <a href="../encoding_tutorial/#ComplexityMeasures.Encoding"><code>Encoding</code></a>s in a point-wise manner in the transformed space. (the <a href="@ref"><code>OutcomeSpace</code></a> dictates this transformation). This is useful for encoding timeseries data.</p><p>The length of the returned <code>s</code> depends on the <a href="@ref"><code>OutcomeSpace</code></a>. Some outcome spaces preserve the input data length (e.g. <a href="#ComplexityMeasures.UniqueElements"><code>UniqueElements</code></a>), while some outcome spaces (e.g. <a href="#ComplexityMeasures.OrdinalPatterns"><code>OrdinalPatterns</code></a>) do e.g. delay embeddings before encoding, so that <code>length(s) &lt; length(x)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/v3.6.5/src/core/encodings.jl#L49-L71">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="CausalityTools.Discretization" href="#CausalityTools.Discretization"><code>CausalityTools.Discretization</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Discretization</code></pre><p>The supertype of all discretization schemes.</p><p><strong>Concrete implementations</strong></p><ul><li><a href="#CausalityTools.CodifyVariables"><code>CodifyVariables</code></a></li><li><a href="#CausalityTools.CodifyPoints"><code>CodifyPoints</code></a></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/CausalityTools.jl/blob/61736a8c95922f015eb7312a11a091487ecd52d1/src/methods/information/counts_and_probs/counts_and_probs.jl#L4-L13">source</a></section></article><h3 id="Encoding-per-variable/column"><a class="docs-heading-anchor" href="#Encoding-per-variable/column">Encoding per variable/column</a><a id="Encoding-per-variable/column-1"></a><a class="docs-heading-anchor-permalink" href="#Encoding-per-variable/column" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="CausalityTools.CodifyVariables" href="#CausalityTools.CodifyVariables"><code>CausalityTools.CodifyVariables</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CodifyVariables &lt;: Discretization
CodifyVariables(outcome_space::OutcomeSpace)</code></pre><p>The <code>CodifyVariables</code> discretization scheme quantises input data in a column-wise manner using the given <code>outcome_space</code>.</p><p><strong>Compatible outcome spaces</strong></p><ul><li><a href="#ComplexityMeasures.UniqueElements"><code>UniqueElements</code></a> (for when data are pre-discretized)</li><li><a href="#ComplexityMeasures.BubbleSortSwaps"><code>BubbleSortSwaps</code></a></li><li><a href="#ComplexityMeasures.CosineSimilarityBinning"><code>CosineSimilarityBinning</code></a></li><li><a href="#ComplexityMeasures.OrdinalPatterns"><code>OrdinalPatterns</code></a></li><li><a href="#ComplexityMeasures.Dispersion"><code>Dispersion</code></a></li></ul><p><strong>Description</strong></p><p>The main difference between <code>CodifyVariables</code> and [<code>CodifyPoints</code>] is that the former uses <a href="@ref"><code>OutcomeSpace</code></a>s for discretization. This usually means that some transformation is applied to the data before discretizing. For example, some outcome constructs a delay embedding from the input (and thus encodes sequential information) before encoding the data.</p><p>Specifically, given <code>x::AbstractStateSpaceSet...</code>, where the <code>i</code>-th dataset <code>x[i]</code>  is assumed to represent a single series of measurements, <code>CodifyVariables</code> encodes  <code>x[i]</code> by <a href="#ComplexityMeasures.codify"><code>codify</code></a>-ing into a series of integers  using an appropriate  <a href="@ref"><code>OutcomeSpace</code></a>. This is typically done by first  sequentially transforming the data and then running sliding window (the width of  the window is controlled by <code>outcome_space</code>) across the data, and then encoding the  values within each window to an integer.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using CausalityTools
x, y = rand(100), rand(100)
d = CodifyVariables(OrdinalPatterns(m=2))
cx, cy = codify(d, x, y)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/CausalityTools.jl/blob/61736a8c95922f015eb7312a11a091487ecd52d1/src/methods/information/counts_and_probs/encoding/codify_variables.jl#L12-L51">source</a></section></article><p>The sliding-window discretization is formally done by applying some <a href="@ref"><code>OutcomeSpace</code></a> to each variable/column. Pick between the following outcome spaces</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ComplexityMeasures.UniqueElements" href="#ComplexityMeasures.UniqueElements"><code>ComplexityMeasures.UniqueElements</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">UniqueElements()</code></pre><p>An <a href="@ref"><code>OutcomeSpace</code></a> based on straight-forward counting of distinct elements in a univariate time series or multivariate dataset. This is the same as giving no estimator to <a href="../probabilities_tutorial/#ComplexityMeasures.probabilities-Tuple{OutcomeSpace}"><code>probabilities</code></a>.</p><p><strong>Outcome space</strong></p><p>The outcome space is the unique sorted values of the input. Hence, input <code>x</code> is needed for a well-defined <a href="@ref"><code>outcome_space</code></a>.</p><p><strong>Implements</strong></p><ul><li><a href="#ComplexityMeasures.codify"><code>codify</code></a>. Used for encoding inputs where ordering matters (e.g. time series).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/v3.6.5/src/outcome_spaces/unique_elements.jl#L3-L18">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ComplexityMeasures.CosineSimilarityBinning" href="#ComplexityMeasures.CosineSimilarityBinning"><code>ComplexityMeasures.CosineSimilarityBinning</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CosineSimilarityBinning(; m::Int, τ::Int, nbins::Int)</code></pre><p>A <a href="@ref"><code>OutcomeSpace</code></a> based on the cosine similarity (<a href="../references/#Wang2020">Wang <em>et al.</em>, 2020</a>).</p><p>It can be used with <a href="@ref"><code>information</code></a> to compute the &quot;diversity entropy&quot; of an input timeseries (<a href="../references/#Wang2020">Wang <em>et al.</em>, 2020</a>).</p><p>The implementation here allows for <code>τ != 1</code>, which was not considered in the original paper.</p><p><strong>Description</strong></p><p>CosineSimilarityBinning probabilities are computed as follows.</p><ol><li>From the input time series <code>x</code>, using embedding lag <code>τ</code> and embedding dimension <code>m</code>,  construct the embedding  <span>$Y = \{\bf x_i \} = \{(x_{i}, x_{i+\tau}, x_{i+2\tau}, \ldots, x_{i+m\tau - 1}\}_{i = 1}^{N-mτ}$</span>.</li><li>Compute <span>$D = \{d(\bf x_t, \bf x_{t+1}) \}_{t=1}^{N-mτ-1}$</span>,  where <span>$d(\cdot, \cdot)$</span> is the cosine similarity between two <code>m</code>-dimensional  vectors in the embedding.</li><li>Divide the interval <code>[-1, 1]</code> into <code>nbins</code> equally sized subintervals (including the value <code>+1</code>).</li><li>Construct a histogram of cosine similarities <span>$d \in D$</span> over those subintervals.</li><li>Sum-normalize the histogram to obtain probabilities.</li></ol><p><strong>Outcome space</strong></p><p>The outcome space for <code>CosineSimilarityBinning</code> is the bins of the <code>[-1, 1]</code> interval, and the return configuration is the same as in <a href="#ComplexityMeasures.ValueBinning"><code>ValueBinning</code></a> (left bin edge).</p><p><strong>Implements</strong></p><ul><li><a href="#ComplexityMeasures.codify"><code>codify</code></a>. Used for encoding inputs where ordering matters (e.g. time series).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/v3.6.5/src/outcome_spaces/cosine_similarity_binning.jl#L5-L38">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ComplexityMeasures.Dispersion" href="#ComplexityMeasures.Dispersion"><code>ComplexityMeasures.Dispersion</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Dispersion(; c = 5, m = 2, τ = 1, check_unique = true)</code></pre><p>An <a href="@ref"><code>OutcomeSpace</code></a> based on dispersion patterns, originally used by <a href="../references/#Rostaghi2016">Rostaghi and Azami (2016)</a> to compute the &quot;dispersion entropy&quot;, which characterizes the complexity and irregularity of a time series.</p><p>Recommended parameter values (<a href="../references/#Li2018">Li <em>et al.</em>, 2019</a>) are <code>m ∈ [2, 3]</code>, <code>τ = 1</code> for the embedding, and <code>c ∈ [3, 4, …, 8]</code> categories for the Gaussian symbol mapping.</p><p><strong>Description</strong></p><p>Assume we have a univariate time series <span>$X = \{x_i\}_{i=1}^N$</span>. First, this time series is encoded into a symbol timeseries <span>$S$</span> using the Gaussian encoding <a href="../encoding_tutorial/#ComplexityMeasures.GaussianCDFEncoding"><code>GaussianCDFEncoding</code></a> with empirical mean <code>μ</code> and empirical standard deviation <code>σ</code> (both determined from <span>$X$</span>), and <code>c</code> as given to <code>Dispersion</code>.</p><p>Then, <span>$S$</span> is embedded into an <span>$m$</span>-dimensional time series, using an embedding lag of <span>$\tau$</span>, which yields a total of <span>$N - (m - 1)\tau$</span> delay vectors <span>$z_i$</span>, or &quot;dispersion patterns&quot;. Since each element of <span>$z_i$</span> can take on <code>c</code> different values, and each delay vector has <code>m</code> entries, there are <code>c^m</code> possible dispersion patterns. This number is used for normalization when computing dispersion entropy.</p><p>The returned probabilities are simply the frequencies of the unique dispersion patterns present in <span>$S$</span> (i.e., the <a href="#ComplexityMeasures.UniqueElements"><code>UniqueElements</code></a> of <span>$S$</span>).</p><p><strong>Outcome space</strong></p><p>The outcome space for <code>Dispersion</code> is the unique delay vectors whose elements are the the symbols (integers) encoded by the Gaussian CDF, i.e., the unique elements of <span>$S$</span>.</p><p><strong>Data requirements and parameters</strong></p><p>The input must have more than one unique element for the Gaussian mapping to be well-defined. <a href="../references/#Li2018">Li <em>et al.</em> (2019)</a> recommends that <code>x</code> has at least 1000 data points.</p><p>If <code>check_unique == true</code> (default), then it is checked that the input has more than one unique value. If <code>check_unique == false</code> and the input only has one unique element, then a <code>InexactError</code> is thrown when trying to compute probabilities.</p><div class="admonition is-info"><header class="admonition-header">Why &#39;dispersion patterns&#39;?</header><div class="admonition-body"><p>Each embedding vector is called a &quot;dispersion pattern&quot;. Why? Let&#39;s consider the case when <span>$m = 5$</span> and <span>$c = 3$</span>, and use some very imprecise terminology for illustration:</p><p>When <span>$c = 3$</span>, values clustering far below mean are in one group, values clustered around the mean are in one group, and values clustering far above the mean are in a third group. Then the embedding vector <span>$[2, 2, 2, 2, 2]$</span> consists of values that are close together (close to the mean), so it represents a set of numbers that are not very spread out (less dispersed). The embedding vector <span>$[1, 1, 2, 3, 3]$</span>, however, represents numbers that are much more spread out (more dispersed), because the categories representing &quot;outliers&quot; both above and below the mean are represented, not only values close to the mean.</p></div></div><p>For a version of this estimator that can be used on high-dimensional arrays, see <a href="@ref"><code>SpatialDispersion</code></a>.</p><p><strong>Implements</strong></p><ul><li><a href="#ComplexityMeasures.codify"><code>codify</code></a>. Used for encoding inputs where ordering matters (e.g. time series).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/v3.6.5/src/outcome_spaces/dispersion.jl#L5-L64">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ComplexityMeasures.OrdinalPatterns" href="#ComplexityMeasures.OrdinalPatterns"><code>ComplexityMeasures.OrdinalPatterns</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">OrdinalPatterns &lt;: OutcomeSpace
OrdinalPatterns{m}(τ = 1, lt::Function = ComplexityMeasures.isless_rand)</code></pre><p>An <a href="@ref"><code>OutcomeSpace</code></a> based on lengh-<code>m</code> ordinal permutation patterns, originally introduced in <a href="../references/#BandtPompe2002">Bandt and Pompe (2002)</a>&#39;s paper on permutation entropy. Note that <code>m</code> is given as a type parameter, so that when it is a literal integer there are performance accelerations.</p><p>When passed to <a href="../probabilities_tutorial/#ComplexityMeasures.probabilities-Tuple{OutcomeSpace}"><code>probabilities</code></a> the output depends on the input data type:</p><ul><li><strong>Univariate data</strong>. If applied to a univariate timeseries (<code>AbstractVector</code>), then the timeseries   is first embedded using embedding delay <code>τ</code> and dimension <code>m</code>, resulting in embedding   vectors <span>$\{ \bf{x}_i \}_{i=1}^{N-(m-1)\tau}$</span>. Then, for each <span>$\bf{x}_i$</span>,   we find its permutation pattern <span>$\pi_{i}$</span>. Probabilities are then   estimated as the frequencies of the encoded permutation symbols   by using <a href="#ComplexityMeasures.UniqueElements"><code>UniqueElements</code></a>. When giving the resulting probabilities to   <a href="@ref"><code>information</code></a>, the original permutation entropy is computed (<a href="../references/#BandtPompe2002">Bandt and Pompe, 2002</a>).</li><li><strong>Multivariate data</strong>. If applied to a an <code>D</code>-dimensional <code>StateSpaceSet</code>,   then no embedding is constructed, <code>m</code> must be equal to <code>D</code> and <code>τ</code> is ignored.   Each vector <span>$\bf{x}_i$</span> of the dataset is mapped   directly to its permutation pattern <span>$\pi_{i}$</span> by comparing the   relative magnitudes of the elements of <span>$\bf{x}_i$</span>.   Like above, probabilities are estimated as the frequencies of the permutation symbols.   The resulting probabilities can be used to compute multivariate permutation   entropy (<a href="../references/#He2016">He <em>et al.</em>, 2016</a>), although here we don&#39;t perform any further subdivision   of the permutation patterns (as in Figure 3 of <a href="../references/#He2016">He <em>et al.</em> (2016)</a>).</li></ul><p>Internally, <a href="#ComplexityMeasures.OrdinalPatterns"><code>OrdinalPatterns</code></a> uses the <a href="../encoding_tutorial/#ComplexityMeasures.OrdinalPatternEncoding"><code>OrdinalPatternEncoding</code></a> to represent ordinal patterns as integers for efficient computations.</p><p>See <a href="@ref"><code>WeightedOrdinalPatterns</code></a> and <a href="@ref"><code>AmplitudeAwareOrdinalPatterns</code></a> for estimators that not only consider ordinal (sorting) patterns, but also incorporate information about within-state-vector amplitudes. For a version of this estimator that can be used on spatial data, see <a href="@ref"><code>SpatialOrdinalPatterns</code></a>.</p><div class="admonition is-info"><header class="admonition-header">Handling equal values in ordinal patterns</header><div class="admonition-body"><p>In <a href="../references/#BandtPompe2002">Bandt and Pompe (2002)</a>, equal values are ordered after their order of appearance, but this can lead to erroneous temporal correlations, especially for data with low amplitude resolution (<a href="../references/#Zunino2017">Zunino <em>et al.</em>, 2017</a>). Here, by default, if two values are equal, then one of the is randomly assigned as &quot;the largest&quot;, using <code>lt = ComplexityMeasures.isless_rand</code>. To get the behaviour from <a href="../references/#BandtPompe2002">Bandt and Pompe (2002)</a>, use <code>lt = Base.isless</code>.</p></div></div><p><strong>Outcome space</strong></p><p>The outcome space <code>Ω</code> for <code>OrdinalPatterns</code> is the set of length-<code>m</code> ordinal patterns (i.e. permutations) that can be formed by the integers <code>1, 2, …, m</code>. There are <code>factorial(m)</code> such patterns.</p><p>For example, the outcome <code>[2, 3, 1]</code> corresponds to the ordinal pattern of having the smallest value in the second position, the next smallest value in the third position, and the next smallest, i.e. the largest value in the first position. See also <a href="../encoding_tutorial/#ComplexityMeasures.OrdinalPatternEncoding"><code>OrdinalPatternEncoding</code></a>.</p><p><strong>In-place symbolization</strong></p><p><code>OrdinalPatterns</code> also implements the in-place <a href="@ref"><code>probabilities!</code></a> for <code>StateSpaceSet</code> input (or embedded vector input) for reducing allocations in looping scenarios. The length of the pre-allocated symbol vector must be the length of the dataset. For example</p><pre><code class="language-julia hljs">using ComplexityMeasures
m, N = 2, 100
est = OrdinalPatterns{m}(τ)
x = StateSpaceSet(rand(N, m)) # some input dataset
πs_ts = zeros(Int, N) # length must match length of `x`
p = probabilities!(πs_ts, est, x)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/v3.6.5/src/outcome_spaces/ordinal_patterns.jl#L24-L96">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ComplexityMeasures.BubbleSortSwaps" href="#ComplexityMeasures.BubbleSortSwaps"><code>ComplexityMeasures.BubbleSortSwaps</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">BubbleSortSwaps &lt;: CountBasedOutcomeSpace
BubbleSortSwaps(; m = 3, τ = 1)</code></pre><p>The <code>BubbleSortSwaps</code> outcome space is based on <a href="../references/#Manis2017">Manis <em>et al.</em> (2017)</a>&#39;s  paper on &quot;bubble entropy&quot;. </p><p><strong>Description</strong></p><p><code>BubbleSortSwaps</code> does the following:</p><ul><li>Embeds the input data using embedding dimension <code>m</code> and  embedding lag <code>τ</code></li><li>For each state vector in the embedding, counting how many swaps are necessary for   the bubble sort algorithm to sort state vectors.</li></ul><p>For <a href="@ref"><code>counts_and_outcomes</code></a>, we then define a distribution over the number of  necessary swaps. This distribution can then be used to estimate probabilities using  <a href="@ref"><code>probabilities_and_outcomes</code></a>, which again can be used to estimate any  <a href="@ref"><code>InformationMeasure</code></a>. An example of how to compute the &quot;Shannon bubble entropy&quot; is given below.</p><p><strong>Outcome space</strong></p><p>The <a href="@ref"><code>outcome_space</code></a> for <code>BubbleSortSwaps</code> are the integers <code>0:N</code>, where <code>N = (m * (m - 1)) / 2 + 1</code> (the worst-case number of swaps). Hence, the number of <a href="@ref"><code>total_outcomes</code></a> is <code>N + 1</code>.</p><p><strong>Implements</strong></p><ul><li><a href="#ComplexityMeasures.codify"><code>codify</code></a>. Returns the number of swaps required for each embedded state vector.</li></ul><p><strong>Examples</strong></p><p>With the <code>BubbleSortSwaps</code> outcome space, we can easily compute a &quot;bubble entropy&quot; inspired by (<a href="../references/#Manis2017">Manis <em>et al.</em>, 2017</a>). Note: this is not actually a new entropy - it is just  a new way of discretizing the input data. To reproduce the bubble entropy complexity measure from (<a href="../references/#Manis2017">Manis <em>et al.</em>, 2017</a>), see <a href="@ref"><code>BubbleEntropy</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using ComplexityMeasures
x = rand(100000)
o = BubbleSortSwaps(; m = 5) # 5-dimensional embedding vectors
information(Shannon(; base = 2), o, x)

# We can also compute any other &quot;bubble quantity&quot;, for example the 
# &quot;Tsallis bubble extropy&quot;, with arbitrary probabilities estimators:
information(TsallisExtropy(), BayesianRegularization(), o, x)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/v3.6.5/src/outcome_spaces/bubble_sort_swaps.jl#L3-L53">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ComplexityMeasures.ValueBinning" href="#ComplexityMeasures.ValueBinning"><code>ComplexityMeasures.ValueBinning</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ValueBinning(b::AbstractBinning) &lt;: OutcomeSpace</code></pre><p>An <a href="@ref"><code>OutcomeSpace</code></a> based on binning the values of the data as dictated by the binning scheme <code>b</code> and formally computing their histogram, i.e., the frequencies of points in the bins. An alias to this is <code>VisitationFrequency</code>. Available binnings are subtypes of <a href="@ref"><code>AbstractBinning</code></a>.</p><p>The <code>ValueBinning</code> estimator has a linearithmic time complexity (<code>n log(n)</code> for <code>n = length(x)</code>) and a linear space complexity (<code>l</code> for <code>l = dimension(x)</code>). This allows computation of probabilities (histograms) of high-dimensional datasets and with small box sizes <code>ε</code> without memory overflow and with maximum performance. For performance reasons, the probabilities returned never contain 0s and are arbitrarily ordered.</p><pre><code class="nohighlight hljs">ValueBinning(ϵ::Union{Real,Vector})</code></pre><p>A convenience method that accepts same input as <a href="#ComplexityMeasures.RectangularBinning"><code>RectangularBinning</code></a> and initializes this binning directly.</p><p><strong>Outcomes</strong></p><p>The outcome space for <code>ValueBinning</code> is the unique bins constructed from <code>b</code>. Each bin is identified by its left (lowest-value) corner, because bins are always left-closed-right-open intervals <code>[a, b)</code>. The bins are in data units, not integer (cartesian indices units), and are returned as <code>SVector</code>s, i.e., same type as input data.</p><p>For convenience, <a href="@ref"><code>outcome_space</code></a> returns the outcomes in the same array format as the underlying binning (e.g., <code>Matrix</code> for 2D input).</p><p>For <a href="#ComplexityMeasures.FixedRectangularBinning"><code>FixedRectangularBinning</code></a> the <a href="@ref"><code>outcome_space</code></a> is well-defined from the binning, but for <a href="#ComplexityMeasures.RectangularBinning"><code>RectangularBinning</code></a> input <code>x</code> is needed as well.</p><p><strong>Implements</strong></p><ul><li><a href="#ComplexityMeasures.codify"><code>codify</code></a>. Used for encoding inputs where ordering matters (e.g. time series).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/v3.6.5/src/outcome_spaces/value_binning.jl#L4-L42">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ComplexityMeasures.RectangularBinning" href="#ComplexityMeasures.RectangularBinning"><code>ComplexityMeasures.RectangularBinning</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">RectangularBinning(ϵ, precise = false) &lt;: AbstractBinning</code></pre><p>Rectangular box partition of state space using the scheme <code>ϵ</code>, deducing the histogram extent and bin width from the input data.</p><p><code>RectangularBinning</code> is a convenience struct. It is re-cast into <a href="#ComplexityMeasures.FixedRectangularBinning"><code>FixedRectangularBinning</code></a> once the data are provided, so see that docstring for info on the bin calculation and the meaning of <code>precise</code>.</p><p>Binning instructions are deduced from the type of <code>ϵ</code> as follows:</p><ol><li><code>ϵ::Int</code> divides each coordinate axis into <code>ϵ</code> equal-length intervals  that cover all data.</li><li><code>ϵ::Float64</code> divides each coordinate axis into intervals of fixed size <code>ϵ</code>, starting  from the axis minima until the data is completely covered by boxes.</li><li><code>ϵ::Vector{Int}</code> divides the i-th coordinate axis into <code>ϵ[i]</code> equal-length  intervals that cover all data.</li><li><code>ϵ::Vector{Float64}</code> divides the i-th coordinate axis into intervals of fixed size  <code>ϵ[i]</code>, starting from the axis minima until the data is completely covered by boxes.</li></ol><p><code>RectangularBinning</code> ensures all input data are covered by extending the created ranges if need be.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/v3.6.5/src/encoding_implementations/rectangular_binning.jl#L18-L42">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="ComplexityMeasures.FixedRectangularBinning" href="#ComplexityMeasures.FixedRectangularBinning"><code>ComplexityMeasures.FixedRectangularBinning</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">FixedRectangularBinning &lt;: AbstractBinning
FixedRectangularBinning(ranges::Tuple{&lt;:AbstractRange...}, precise = false)</code></pre><p>Rectangular box partition of state space where the partition along each dimension is explicitly given by each range <code>ranges</code>, which is a tuple of <code>AbstractRange</code> subtypes. Typically, each range is the output of the <code>range</code> Base function, e.g., <code>ranges = (0:0.1:1, range(0, 1; length = 101), range(2.1, 3.2; step = 0.33))</code>. All ranges must be sorted.</p><p>The optional second argument <code>precise</code> dictates whether Julia Base&#39;s <code>TwicePrecision</code> is used for when searching where a point falls into the range. Useful for edge cases of points being almost exactly on the bin edges, but it is exactly four times as slow, so by default it is <code>false</code>.</p><p>Points falling outside the partition do not contribute to probabilities. Bins are always left-closed-right-open: <code>[a, b)</code>. <strong>This means that the last value of each of the ranges dictates the last right-closing value.</strong> This value does <em>not</em> belong to the histogram! E.g., if given a range <code>r = range(0, 1; length = 11)</code>, with <code>r[end] = 1</code>, the value <code>1</code> is outside the partition and would not attribute any increase of the probability corresponding to the last bin (here <code>[0.9, 1)</code>)!</p><p><strong>Equivalently, the size of the histogram is <code>histsize = map(r -&gt; length(r)-1, ranges)</code>!</strong></p><p><code>FixedRectangularBinning</code> leads to a well-defined outcome space without knowledge of input data, see <a href="#ComplexityMeasures.ValueBinning"><code>ValueBinning</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/ComplexityMeasures.jl/blob/v3.6.5/src/encoding_implementations/rectangular_binning.jl#L49-L78">source</a></section></article><h3 id="Encoding-per-sample/row"><a class="docs-heading-anchor" href="#Encoding-per-sample/row">Encoding per sample/row</a><a id="Encoding-per-sample/row-1"></a><a class="docs-heading-anchor-permalink" href="#Encoding-per-sample/row" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="CausalityTools.CodifyPoints" href="#CausalityTools.CodifyPoints"><code>CausalityTools.CodifyPoints</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CodifyPoints{N}
CodifyPoints(encodings::NTuple{N, Encoding})</code></pre><p><code>CodifyPoints</code> points is a <a href="#CausalityTools.Discretization"><code>Discretization</code></a> scheme that encodes input data points <em>without</em> applying any sequential transformation to the input (as opposed to  <a href="#CausalityTools.CodifyVariables"><code>CodifyVariables</code></a>, which may apply some transformation before encoding).</p><p><strong>Usage</strong></p><ul><li>Use with <a href="#ComplexityMeasures.codify"><code>codify</code></a>` to encode/discretize input variable on a point-by-point basis.</li></ul><p><strong>Compatible encodings</strong></p><ul><li><a href="../encoding_tutorial/#ComplexityMeasures.GaussianCDFEncoding"><code>GaussianCDFEncoding</code></a></li><li><a href="../encoding_tutorial/#ComplexityMeasures.OrdinalPatternEncoding"><code>OrdinalPatternEncoding</code></a></li><li><a href="../encoding_tutorial/#ComplexityMeasures.RelativeMeanEncoding"><code>RelativeMeanEncoding</code></a></li><li><a href="../encoding_tutorial/#ComplexityMeasures.RelativeFirstDifferenceEncoding"><code>RelativeFirstDifferenceEncoding</code></a></li><li><a href="../encoding_tutorial/#ComplexityMeasures.UniqueElementsEncoding"><code>UniqueElementsEncoding</code></a></li><li><a href="../encoding_tutorial/#ComplexityMeasures.RectangularBinEncoding"><code>RectangularBinEncoding</code></a></li><li><a href="../encoding_tutorial/#ComplexityMeasures.CombinationEncoding"><code>CombinationEncoding</code></a></li></ul><p><strong>Description</strong></p><p>Given <code>x::AbstractStateSpaceSet...</code>, where the <code>i</code>-th dataset is assumed to represent a single series of measurements, <code>CodifyPoints</code> encodes each point <code>pₖ ∈ x[i]</code>  using some <a href="../encoding_tutorial/#ComplexityMeasures.Encoding"><code>Encoding</code></a>(s), <em>without</em> applying any (sequential) transformation to the <code>x[i]</code> first. This behaviour is different to <a href="#CausalityTools.CodifyVariables"><code>CodifyVariables</code></a>, which <em>does</em> apply a transformation to <code>x[i]</code> before encoding.</p><p>If <code>length(x) == N</code> (i.e. there are <code>N</code> input dataset), then <code>encodings</code> must be a tuple of <code>N</code> <a href="../encoding_tutorial/#ComplexityMeasures.Encoding"><code>Encoding</code></a>. Alternatively, if <code>encodings</code> is a single <a href="../encoding_tutorial/#ComplexityMeasures.Encoding"><code>Encoding</code></a>, then that same encoding is applied to every <code>x[i]</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using CausalityTools

# The same encoding on two input datasets
x = StateSpaceSet(rand(100, 3))
y = StateSpaceSet(rand(100, 3))
encoding_ord = OrdinalPatternEncoding(3)
cx, cy = codify(CodifyPoints(encoding_ord), x, y)

# Different encodings on multiple datasets
z = StateSpaceSet(rand(100, 2))
encoding_bin = RectangularBinEncoding(RectangularBinning(3), z)
d = CodifyPoints(encoding_ord, encoding_ord, encoding_bin)
cx, cy, cz = codify(d, x, y, z)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaDynamics/CausalityTools.jl/blob/61736a8c95922f015eb7312a11a091487ecd52d1/src/methods/information/counts_and_probs/encoding/codify_points.jl#L8-L59">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../encoding_tutorial/">« Encoding elements</a><a class="docs-footer-nextpage" href="../probabilities_tutorial/">Counts and probabilities »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.5.0 on <span class="colophon-date" title="Wednesday 24 July 2024 01:54">Wednesday 24 July 2024</span>. Using Julia version 1.10.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
